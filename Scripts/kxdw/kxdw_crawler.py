#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¼€å¿ƒç”µç©æ‰‹æ¸¸æ•°æ®æŠ“å–å·¥å…·
ä½¿ç”¨ Chrome DevTools Protocol æŠ“å–æ‰‹æ¸¸åˆ†ç±»ä¸‹çš„æ‰‹æ¸¸èµ„æ–™

ä½¿ç”¨å‰å‡†å¤‡:
    1. å®‰è£…ä¾èµ–: pip3 install pychrome requests websocket-client
    2. å¯åŠ¨ Chrome (å¼€å¯è°ƒè¯•ç«¯å£):
       Mac: /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222
       Windows: chrome.exe --remote-debugging-port=9222
       
ç”¨æ³•:
    python3 kxdw_crawler.py
    python3 kxdw_crawler.py -o games.csv
    python3 kxdw_crawler.py -p 9222
"""

import argparse
import csv
import re
import time
import platform
from pathlib import Path
from urllib.parse import urljoin, urlparse
from typing import List, Dict, Optional

try:
    import pychrome
except ImportError:
    pychrome = None

try:
    import requests
except ImportError:
    requests = None


class KXDWCrawler:
    """å¼€å¿ƒç”µç©æ‰‹æ¸¸æ•°æ®æŠ“å–å·¥å…·"""
    
    def __init__(self, debug_url: str = "http://127.0.0.1:9222"):
        self.debug_url = debug_url
        self.browser = None
        self.tab = None
        self.base_url = "https://www.kxdw.com"
        self.target_url = "https://www.kxdw.com/android/gf.html"
        self.games = []
        
    def connect(self) -> bool:
        """è¿æ¥åˆ° Chrome è°ƒè¯•ç«¯å£"""
        if not pychrome:
            print("âŒ è¯·å…ˆå®‰è£… pychrome: pip3 install pychrome")
            return False
            
        try:
            self.browser = pychrome.Browser(url=self.debug_url)
            print(f"âœ… å·²è¿æ¥åˆ° Chrome: {self.debug_url}")
            return True
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ° Chrome è°ƒè¯•ç«¯å£: {e}")
            print("\nè¯·å…ˆå¯åŠ¨ Chrome å¹¶å¼€å¯è°ƒè¯•ç«¯å£:")
            self._print_chrome_launch_command()
            return False
    
    def _print_chrome_launch_command(self):
        """æ‰“å°å¯åŠ¨ Chrome çš„å‘½ä»¤"""
        system = platform.system()
        if system == "Darwin":  # macOS
            print('   /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222')
        elif system == "Windows":
            print('   chrome.exe --remote-debugging-port=9222')
        else:  # Linux
            print('   google-chrome --remote-debugging-port=9222')
    
    def new_tab(self, url: str = None):
        """åˆ›å»ºæˆ–è·å–æ ‡ç­¾é¡µ"""
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                tabs = self.browser.list_tab()
                if tabs:
                    self.tab = tabs[0]
                    print(f"ğŸ“‘ ä½¿ç”¨ç°æœ‰æ ‡ç­¾é¡µ")
                else:
                    self.tab = self.browser.new_tab()
                    print(f"ğŸ“‘ åˆ›å»ºæ–°æ ‡ç­¾é¡µ")
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"â³ é‡è¯•è¿æ¥... ({attempt + 1}/{max_retries})")
                    time.sleep(2)
                else:
                    raise e
        
        # å¯ç”¨å¿…è¦çš„åŸŸ
        self.tab.start()
        self.tab.Network.enable()
        self.tab.Page.enable()
        self.tab.DOM.enable()
        self.tab.Runtime.enable()
        
        if url:
            self.navigate(url)
    
    def navigate(self, url: str, wait_time: float = 3.0):
        """å¯¼èˆªåˆ°æŒ‡å®šURL"""
        print(f"ğŸŒ æ­£åœ¨è®¿é—®: {url}")
        self.tab.Page.navigate(url=url)
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        time.sleep(wait_time)
        
        # ç­‰å¾… load äº‹ä»¶
        try:
            self.tab.wait(timeout=10)
        except:
            pass
    
    def get_game_list(self, max_pages: int = 100) -> List[Dict]:
        """è·å–æ¸¸æˆåˆ—è¡¨"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ è·å–æ¸¸æˆåˆ—è¡¨")
        print("=" * 60)
        
        # æ»šåŠ¨é¡µé¢ä»¥åŠ è½½æ›´å¤šå†…å®¹
        print("ğŸ“œ æ»šåŠ¨é¡µé¢åŠ è½½æ‰€æœ‰æ¸¸æˆ...")
        self._scroll_to_load_all()
        
        # è·å–å½“å‰é¡µé¢URLï¼Œæå–åˆ†é¡µæ¨¡å¼
        current_url_result = self.tab.Runtime.evaluate(expression="window.location.href")
        current_url = current_url_result.get("result", {}).get("value", "")
        
        # ä»å½“å‰URLæå–åŸºç¡€è·¯å¾„
        url_parts = current_url.rsplit('/', 1)
        base_path = url_parts[0] if len(url_parts) == 2 else current_url.rsplit('/', 2)[0]
        
        # æ£€æµ‹åˆ†é¡µæ¨¡å¼ï¼šgf.html, gf_2.html, gf_3.html æˆ– azyx_60.html ç­‰
        url_prefix = None
        start_page_num = 1
        page_file_pattern = None
        
        # ä¼˜å…ˆæ£€æµ‹ gf_æ•°å­—.html æ ¼å¼ï¼ˆå¦‚ gf_6.htmlï¼‰
        page_match = re.search(r'gf_(\d+)\.html', current_url)
        if page_match:
            start_page_num = int(page_match.group(1))  # 6
            url_prefix = "gf"
            page_file_pattern = "gf_{page_num}.html"
            print(f"   ğŸ“„ æ£€æµ‹åˆ°åˆ†é¡µæ¨¡å¼: gf_æ•°å­—.htmlï¼Œå½“å‰é¡µ: {start_page_num}")
        else:
            # æ£€æµ‹ gf.htmlï¼ˆç¬¬ä¸€é¡µï¼‰
            if 'gf.html' in current_url and '_' not in current_url:
                start_page_num = 1
                url_prefix = "gf"
                page_file_pattern = "gf_{page_num}.html"
                print(f"   ğŸ“„ æ£€æµ‹åˆ°åˆ†é¡µæ¨¡å¼: gf.htmlï¼ˆç¬¬ä¸€é¡µï¼‰ï¼Œå°†ä½¿ç”¨ gf_2.html, gf_3.html...")
            else:
                # æ£€æµ‹å…¶ä»–æ ¼å¼ï¼ˆå¦‚ azyx_60.htmlï¼‰
                page_match = re.search(r'([a-z]+)_(\d+)\.html', current_url)
                if page_match:
                    url_prefix = page_match.group(1)  # azyx
                    start_page_num = int(page_match.group(2))  # 60
                    page_file_pattern = f"{url_prefix}_{{page_num}}.html"
                    print(f"   ğŸ“„ æ£€æµ‹åˆ°åˆ†é¡µæ¨¡å¼: {url_prefix}_æ•°å­—.htmlï¼Œå½“å‰é¡µ: {start_page_num}")
                else:
                    # é»˜è®¤ä½¿ç”¨ gf.html æ ¼å¼
                    url_prefix = "gf"
                    start_page_num = 1
                    page_file_pattern = "gf_{page_num}.html"
                    print(f"   ğŸ“„ ä½¿ç”¨é»˜è®¤åˆ†é¡µæ¨¡å¼: gf.html, gf_2.html, gf_3.html...")
        
        # å¤„ç†åˆ†é¡µï¼ˆå¦‚æœæœ‰ï¼‰
        all_games = []
        # å§‹ç»ˆä»ç¬¬1é¡µå¼€å§‹æŠ“å–ï¼ˆgf.htmlï¼‰
        current_page_num = 1
        target_start_page = 1
        
        # å¦‚æœå½“å‰ä¸åœ¨ç¬¬1é¡µï¼Œå…ˆå¯¼èˆªåˆ°ç¬¬1é¡µ
        if start_page_num > 1 or ('gf.html' not in current_url and 'gf_' not in current_url):
            print(f"   ğŸ“ å¯¼èˆªåˆ°ç¬¬1é¡µ (gf.html)...")
            first_page_url = f"{base_path}/gf.html"
            self.navigate(first_page_url, wait_time=2)
            time.sleep(1)
            # æ»šåŠ¨åŠ è½½ç¬¬ä¸€é¡µå†…å®¹
            self._scroll_to_load_all()
        
        while current_page_num <= target_start_page + max_pages - 1:
            print(f"\nğŸ“„ å¤„ç†ç¬¬ {current_page_num} é¡µ...")
            
            # æå–å½“å‰é¡µçš„æ¸¸æˆé“¾æ¥
            extract_games_js = """
            (function() {
                const games = [];
                const seenUrls = new Set();
                
                // æŸ¥æ‰¾æ‰€æœ‰æ¸¸æˆé“¾æ¥
                const allLinks = document.querySelectorAll('a[href]');
                
                for (let link of allLinks) {
                    let href = link.href || link.getAttribute('href') || '';
                    const text = (link.textContent || link.innerText || '').trim();
                    
                    // è½¬æ¢ä¸ºå®Œæ•´URL
                    if (href && !href.startsWith('http')) {
                        if (href.startsWith('/')) {
                            href = window.location.origin + href;
                        } else {
                            href = window.location.origin + '/' + href;
                        }
                    }
                    
                    // è¿‡æ»¤æ‰æ— æ•ˆé“¾æ¥
                    if (!href || href === '#' || href === 'javascript:void(0)') continue;
                    if (href.includes('gf.html')) continue;  // æ’é™¤åˆ—è¡¨é¡µæœ¬èº«
                    if (seenUrls.has(href)) continue;
                    
                    // æ£€æŸ¥æ˜¯å¦æ˜¯æ¸¸æˆè¯¦æƒ…é¡µé“¾æ¥
                    // æ ¼å¼: https://www.kxdw.com/android/xxxxx.html
                    if (href.includes('/android/') && 
                        href.endsWith('.html') && 
                        !href.includes('gf.html') &&
                        !href.includes('index.html')) {
                        seenUrls.add(href);
                        games.push({
                            name: text || 'æœªçŸ¥æ¸¸æˆ',
                            url: href
                        });
                    }
                }
                
                return games;
            })();
            """
            
            result = self.tab.Runtime.evaluate(expression=extract_games_js, returnByValue=True)
            page_games = result.get("result", {}).get("value", [])
            
            if not page_games:
                print(f"   âš ï¸  ç¬¬ {current_page_num} é¡µæ²¡æœ‰æ‰¾åˆ°æ¸¸æˆï¼Œå¯èƒ½å·²åˆ°æœ€åä¸€é¡µ")
                break
            
            # å»é‡ï¼ˆä¸å·²æœ‰æ¸¸æˆæ¯”è¾ƒï¼‰
            new_games = []
            existing_urls = {g['url'] for g in all_games}
            for game in page_games:
                if game['url'] not in existing_urls:
                    new_games.append(game)
                    all_games.append(game)
            
            print(f"   âœ… ç¬¬ {current_page_num} é¡µæ‰¾åˆ° {len(page_games)} ä¸ªæ¸¸æˆï¼ˆæ–°å¢ {len(new_games)} ä¸ªï¼‰")
            
            # å‡†å¤‡ä¸‹ä¸€é¡µ
            current_page_num += 1
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§é¡µæ•°
            if current_page_num > target_start_page + max_pages:
                print(f"   âœ… å·²è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶ ({max_pages} é¡µ)")
                break
            
            # æ„é€ ä¸‹ä¸€é¡µæ–‡ä»¶å
            # ç¬¬ä¸€é¡µæ˜¯ gf.htmlï¼Œä»ç¬¬äºŒé¡µå¼€å§‹æ˜¯ gf_2.html, gf_3.html ç­‰
            if current_page_num == 1:
                next_page_file = "gf.html"
            else:
                # ä»ç¬¬äºŒé¡µå¼€å§‹ä½¿ç”¨ gf_2.html, gf_3.html ç­‰æ ¼å¼
                if url_prefix:
                    next_page_file = f"{url_prefix}_{current_page_num}.html"
                else:
                    next_page_file = f"gf_{current_page_num}.html"
            
            # æ„é€ å®Œæ•´URL
            next_url = f"{base_path}/{next_page_file}"
            
            print(f"   â­ï¸  å¯¼èˆªåˆ°ç¬¬ {current_page_num} é¡µ: {next_page_file}")
            self.navigate(next_url, wait_time=2)
            time.sleep(1)  # ç­‰å¾…é¡µé¢åŠ è½½
        
        print(f"\nâœ… å…±æ‰¾åˆ° {len(all_games)} ä¸ªæ¸¸æˆ")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªä½œä¸ºé¢„è§ˆ
        if all_games:
            print("\nğŸ“‹ å‰5ä¸ªæ¸¸æˆé¢„è§ˆ:")
            for i, game in enumerate(all_games[:5], 1):
                print(f"   {i}. {game.get('name', 'æœªçŸ¥')} - {game.get('url', '')[:60]}...")
        
        return all_games
    
    def _scroll_to_load_all(self):
        """æ»šåŠ¨é¡µé¢ä»¥åŠ è½½æ‰€æœ‰å†…å®¹"""
        scroll_js = """
        (function() {
            let lastHeight = 0;
            let currentHeight = document.body.scrollHeight;
            let scrollCount = 0;
            const maxScrolls = 50; // æœ€å¤šæ»šåŠ¨50æ¬¡
            
            while (currentHeight !== lastHeight && scrollCount < maxScrolls) {
                lastHeight = currentHeight;
                window.scrollTo(0, document.body.scrollHeight);
                // ç­‰å¾…å†…å®¹åŠ è½½
                setTimeout(() => {}, 500);
                currentHeight = document.body.scrollHeight;
                scrollCount++;
            }
            
            return {scrollCount: scrollCount, finalHeight: currentHeight};
        })();
        """
        
        # åˆ†æ­¥æ»šåŠ¨
        for i in range(10):  # æ»šåŠ¨10æ¬¡
            self.tab.Runtime.evaluate(expression=f"window.scrollTo(0, {i * 500})")
            time.sleep(0.5)
        
        # æ»šåŠ¨åˆ°åº•éƒ¨
        self.tab.Runtime.evaluate(expression="window.scrollTo(0, document.body.scrollHeight)")
        time.sleep(2)
        
        # æ»šåŠ¨å›é¡¶éƒ¨
        self.tab.Runtime.evaluate(expression="window.scrollTo(0, 0)")
        time.sleep(1)
    
    def parse_game_detail(self, game_url: str) -> Optional[Dict]:
        """è§£ææ¸¸æˆè¯¦æƒ…é¡µï¼Œæå–åç§°ã€å¤§å°ã€ä¸‹è½½åœ°å€"""
        try:
            print(f"   ğŸ” è§£æ: {game_url[:60]}...")
            
            # å¯¼èˆªåˆ°è¯¦æƒ…é¡µ
            self.tab.Page.navigate(url=game_url)
            time.sleep(2)
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            try:
                self.tab.wait(timeout=5)
            except:
                pass
            
            # æå–æ¸¸æˆä¿¡æ¯
            extract_info_js = """
            (function() {
                const info = {
                    name: '',
                    size: '',
                    download_url: ''
                };
                
                // æå–æ¸¸æˆåç§°
                const nameSelectors = [
                    'h1',
                    '.game-title',
                    '.title',
                    '[class*="title"]',
                    'h2'
                ];
                
                for (let selector of nameSelectors) {
                    const el = document.querySelector(selector);
                    if (el) {
                        const text = (el.textContent || el.innerText || '').trim();
                        if (text && text.length > 0 && text.length < 100) {
                            info.name = text;
                            break;
                        }
                    }
                }
                
                // æå–æ–‡ä»¶å¤§å°
                const sizePatterns = [
                    /(\\d+\\.?\\d*)\\s*([MG]B)/i,
                    /å¤§å°[ï¼š:]\\s*(\\d+\\.?\\d*)\\s*([MG]B)/i,
                    /æ–‡ä»¶å¤§å°[ï¼š:]\\s*(\\d+\\.?\\d*)\\s*([MG]B)/i
                ];
                
                const allText = document.body.innerText || document.body.textContent || '';
                for (let pattern of sizePatterns) {
                    const match = allText.match(pattern);
                    if (match) {
                        info.size = match[0];
                        break;
                    }
                }
                
                // å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«"MB"æˆ–"GB"çš„å…ƒç´ 
                if (!info.size) {
                    const sizeElements = document.querySelectorAll('*');
                    for (let el of sizeElements) {
                        const text = (el.textContent || el.innerText || '').trim();
                        if (/\\d+\\.?\\d*\\s*[MG]B/i.test(text)) {
                            const match = text.match(/(\\d+\\.?\\d*\\s*[MG]B)/i);
                            if (match) {
                                info.size = match[1];
                                break;
                            }
                        }
                    }
                }
                
                // æå–ä¸‹è½½åœ°å€
                const allLinks = document.querySelectorAll('a[href]');
                const downloadKeywords = ['ä¸‹è½½', 'download', 'ç«‹å³ä¸‹è½½', 'å®‰å“ç‰ˆä¸‹è½½', 'é«˜é€Ÿä¸‹è½½'];
                
                for (let link of allLinks) {
                    let href = link.href || link.getAttribute('href') || '';
                    const text = (link.textContent || link.innerText || '').trim().toLowerCase();
                    
                    // è½¬æ¢ä¸ºå®Œæ•´URL
                    if (href && !href.startsWith('http')) {
                        if (href.startsWith('/')) {
                            href = window.location.origin + href;
                        } else {
                            href = window.location.origin + '/' + href;
                        }
                    }
                    
                    // æ£€æŸ¥æ˜¯å¦æ˜¯ä¸‹è½½é“¾æ¥
                    const isDownloadLink = 
                        href.includes('.apk') ||
                        href.includes('download') ||
                        href.includes('down') ||
                        (downloadKeywords.some(kw => text.includes(kw)) && href && !href.includes('#'));
                    
                    if (isDownloadLink && !href.includes('javascript:')) {
                        info.download_url = href;
                        break;
                    }
                }
                
                // å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»é¡µé¢HTMLä¸­æå–
                if (!info.download_url) {
                    const html = document.documentElement.outerHTML;
                    const apkPattern = /(https?:\\/\\/[^\\s"']+\\.apk)/i;
                    const match = html.match(apkPattern);
                    if (match) {
                        info.download_url = match[1];
                    }
                }
                
                return info;
            })();
            """
            
            result = self.tab.Runtime.evaluate(expression=extract_info_js, returnByValue=True)
            info = result.get("result", {}).get("value", {})
            
            # å¦‚æœåç§°ä¸ºç©ºï¼Œä½¿ç”¨URLä¸­çš„ä¿¡æ¯
            if not info.get('name') or info.get('name') == 'æœªçŸ¥æ¸¸æˆ':
                # å°è¯•ä»é¡µé¢æ ‡é¢˜è·å–
                title_result = self.tab.Runtime.evaluate(expression="document.title")
                title = title_result.get("result", {}).get("value", "")
                if title:
                    info['name'] = title.split('_')[0].split('-')[0].strip()
            
            return info
            
        except Exception as e:
            print(f"   âŒ è§£æå¤±è´¥: {e}")
            return None
    
    def convert_size_to_mb(self, size_str: str) -> float:
        """å°†å¤§å°å­—ç¬¦ä¸²è½¬æ¢ä¸ºMBæ•°å€¼"""
        if not size_str:
            return 0.0
        
        size_str = size_str.strip().upper()
        
        # åŒ¹é…æ•°å­—å’Œå•ä½
        match = re.match(r'(\d+\.?\d*)\s*([MG]B?)', size_str)
        if not match:
            return 0.0
        
        value = float(match.group(1))
        unit = match.group(2) or 'M'
        
        # è½¬æ¢ä¸ºMB
        if 'G' in unit:
            value = value * 1024
        
        return value
    
    def crawl_all_games(self, max_pages: int = 100) -> List[Dict]:
        """æŠ“å–æ‰€æœ‰æ¸¸æˆæ•°æ®"""
        print("\n" + "=" * 60)
        print("ğŸš€ å¼€å§‹æŠ“å–æ¸¸æˆæ•°æ®")
        print("=" * 60)
        print(f"ğŸ“„ æœ€å¤§é¡µæ•°é™åˆ¶: {max_pages} é¡µ")
        
        # 1. è®¿é—®ç›®æ ‡é¡µé¢
        self.navigate(self.target_url, wait_time=3)
        
        # 2. è·å–æ¸¸æˆåˆ—è¡¨
        game_list = self.get_game_list(max_pages=max_pages)
        
        if not game_list:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ¸¸æˆ")
            return []
        
        # 3. æ•´ç†æ¸¸æˆæ•°æ®ï¼ˆä¸éœ€è¦è§£æè¯¦æƒ…é¡µï¼‰
        print("\n" + "=" * 60)
        print("ğŸ“‹ æ•´ç†æ¸¸æˆæ•°æ®")
        print("=" * 60)
        
        all_games = []
        total = len(game_list)
        
        for i, game in enumerate(game_list, 1):
            game_url = game.get('url', '')
            game_name = game.get('name', 'æœªçŸ¥æ¸¸æˆ')
            
            if not game_url:
                continue
            
            game_data = {
                'name': game_name,
                'detail_url': game_url,
                'downloaded': 'å¦'
            }
            
            all_games.append(game_data)
            
            if i % 50 == 0:
                print(f"   å·²å¤„ç† {i}/{total} ä¸ªæ¸¸æˆ...")
        
        print(f"\nâœ… å…±æŠ“å– {len(all_games)} ä¸ªæ¸¸æˆ")
        
        return all_games
    
    def save_to_csv(self, games: List[Dict], output_file: str = "kxdw_games.csv"):
        """ä¿å­˜åˆ°CSVæ–‡ä»¶"""
        if not games:
            print("âŒ æ²¡æœ‰æ¸¸æˆæ•°æ®å¯ä¿å­˜")
            return
        
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        try:
            with open(output_path, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                
                # å†™å…¥è¡¨å¤´ï¼šæ¸¸æˆåç§°ã€è¯¦æƒ…é¡µé“¾æ¥ã€æ˜¯å¦å·²ä¸‹è½½
                writer.writerow(['æ¸¸æˆåç§°', 'è¯¦æƒ…é¡µé“¾æ¥', 'æ˜¯å¦å·²ä¸‹è½½'])
                
                # å†™å…¥æ•°æ®
                for game in games:
                    writer.writerow([
                        game.get('name', ''),
                        game.get('detail_url', ''),
                        game.get('downloaded', 'å¦')
                    ])
            
            print(f"\nâœ… æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")
            print(f"   å…± {len(games)} æ¡è®°å½•")
            return str(output_path)
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            return None
    
    def close(self):
        """å…³é—­æ ‡ç­¾é¡µ"""
        if self.tab:
            try:
                self.tab.stop()
                if self.browser:
                    self.browser.close_tab(self.tab)
            except:
                pass


def main():
    parser = argparse.ArgumentParser(
        description="å¼€å¿ƒç”µç©æ‰‹æ¸¸æ•°æ®æŠ“å–å·¥å…· - ä½¿ç”¨ Chrome DevTools Protocol",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨å‰å‡†å¤‡:
  1. pip3 install pychrome requests websocket-client
  2. å¯åŠ¨ Chrome (Mac):
     /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222

ç¤ºä¾‹:
  python3 kxdw_crawler.py
  python3 kxdw_crawler.py -o games.csv
  python3 kxdw_crawler.py -p 9222
        """
    )
    
    parser.add_argument("-o", "--output", default="kxdw_games.csv", help="CSVè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: kxdw_games.csvï¼‰")
    parser.add_argument("-p", "--port", default="9222", help="Chrome è°ƒè¯•ç«¯å£ (é»˜è®¤ 9222)")
    parser.add_argument("--max-pages", type=int, default=100, help="æœ€å¤§å¤„ç†é¡µæ•° (é»˜è®¤ 100)")
    
    args = parser.parse_args()
    
    if not pychrome:
        print("âŒ è¯·å…ˆå®‰è£…ä¾èµ–")
        print("\nğŸ’¡ æ¨èä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ:")
        print("   1. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ:")
        print("      source venv/bin/activate  # Mac/Linux")
        print("      æˆ–")
        print("      ./activate.sh  # ä½¿ç”¨ä¾¿æ·è„šæœ¬")
        print("   2. å¦‚æœä¾èµ–æœªå®‰è£…ï¼Œè¿è¡Œ:")
        print("      pip install -r requirements.txt")
        print("\næˆ–è€…ç›´æ¥å®‰è£…åˆ°ç³»ç»Ÿ:")
        print("   pip3 install pychrome requests websocket-client")
        return 1
    
    debug_url = f"http://127.0.0.1:{args.port}"
    crawler = KXDWCrawler(debug_url=debug_url)
    
    if not crawler.connect():
        return 1
    
    try:
        crawler.new_tab()
        
        # æŠ“å–æ‰€æœ‰æ¸¸æˆ
        games = crawler.crawl_all_games(max_pages=args.max_pages)
        
        # ä¿å­˜åˆ°CSV
        if games:
            crawler.save_to_csv(games, args.output)
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        crawler.close()
    
    return 0


if __name__ == "__main__":
    exit(main())

