#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¼€å¿ƒç”µç©æ¸¸æˆä¸‹è½½å·¥å…·
æ ¹æ®CSVæ–‡ä»¶ä¸‹è½½æ¸¸æˆAPK

ç”¨æ³•:
    python3 kxdw_downloader.py games_50_pages.csv
    python3 kxdw_downloader.py games_50_pages.csv --start 10 --limit 5
    python3 kxdw_downloader.py games_50_pages.csv --chrome
"""

import argparse
import csv
import os
import zipfile
import re
import time
import random
import sys
import threading
from pathlib import Path
from urllib.parse import urlparse
from typing import Optional, Dict, List, Tuple
from datetime import datetime

# å°è¯•å¯¼å…¥urllib3çš„IncompleteReadå¼‚å¸¸ï¼ˆå¦‚æœå¯ç”¨ï¼‰
try:
    from urllib3.exceptions import IncompleteRead
except ImportError:
    # å¦‚æœurllib3ä¸å¯ç”¨ï¼Œåˆ›å»ºä¸€ä¸ªå ä½ç¬¦ç±»
    class IncompleteRead(Exception):
        pass

# è®¾ç½®çº¿ç¨‹å¼‚å¸¸å¤„ç†ï¼Œå¿½ç•¥pychromeåå°çº¿ç¨‹çš„JSONè§£æé”™è¯¯
def handle_thread_exception(args):
    """å¤„ç†çº¿ç¨‹å¼‚å¸¸ï¼Œå¿½ç•¥pychromeåå°çº¿ç¨‹çš„JSONè§£æé”™è¯¯"""
    exc_type = args.exc_type
    exc_value = args.exc_value
    exc_traceback = args.exc_traceback
    
    # å¦‚æœæ˜¯pychromeçš„JSONè§£æé”™è¯¯ï¼Œå¿½ç•¥å®ƒï¼ˆè¿™æ˜¯åå°çº¿ç¨‹çš„é”™è¯¯ï¼Œä¸å½±å“ä¸»ç¨‹åºï¼‰
    if exc_type:
        exc_type_name = exc_type.__name__ if hasattr(exc_type, '__name__') else str(exc_type)
        if 'JSONDecodeError' in exc_type_name or 'JSON' in exc_type_name:
            return  # å¿½ç•¥JSONè§£æé”™è¯¯
    
    if exc_value:
        exc_value_str = str(exc_value)
        if 'JSON' in exc_value_str or 'Expecting value' in exc_value_str or 'json.decoder' in exc_value_str:
            return  # å¿½ç•¥JSONç›¸å…³é”™è¯¯
    
    # æ£€æŸ¥æ˜¯å¦æ¥è‡ªpychromeçš„_recv_loopçº¿ç¨‹
    if exc_traceback:
        import traceback
        tb_str = ''.join(traceback.format_exception(exc_type, exc_value, exc_traceback))
        if '_recv_loop' in tb_str and 'json.loads' in tb_str:
            return  # å¿½ç•¥pychromeæ¥æ”¶å¾ªç¯çš„JSONé”™è¯¯
    
    # å…¶ä»–é”™è¯¯æ­£å¸¸æ˜¾ç¤º
    if exc_type and exc_value and exc_traceback:
        sys.__excepthook__(exc_type, exc_value, exc_traceback)

# è®¾ç½®å…¨å±€çº¿ç¨‹å¼‚å¸¸å¤„ç†ï¼ˆPython 3.8+ï¼‰
if hasattr(threading, 'excepthook'):
    threading.excepthook = handle_thread_exception

try:
    import pychrome
except ImportError:
    pychrome = None

try:
    import requests
except ImportError:
    requests = None

# å¯¼å…¥ç™¾åº¦å»ºè®®è¯åŠŸèƒ½
try:
    import sys
    # å°è¯•ä»ç›¸å¯¹è·¯å¾„å¯¼å…¥
    baidu_suggestion_path = Path(__file__).parent.parent / 'web_download_for_duduo' / 'baidu_suggestion.py'
    if baidu_suggestion_path.exists():
        sys.path.insert(0, str(baidu_suggestion_path.parent))
        from baidu_suggestion import get_baidu_suggestions
    else:
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•ç›´æ¥å¯¼å…¥ï¼ˆå¦‚æœå·²å®‰è£…ï¼‰
        from baidu_suggestion import get_baidu_suggestions
except ImportError:
    print("âš ï¸  æ— æ³•å¯¼å…¥ baidu_suggestionï¼Œå°†ä½¿ç”¨æ¸¸æˆåç§°ä½œä¸ºæ–‡ä»¶å¤¹å")
    get_baidu_suggestions = None


class KXDWDownloader:
    """å¼€å¿ƒç”µç©æ¸¸æˆä¸‹è½½å·¥å…·"""
    
    # å¸¸ç”¨User-Agentåˆ—è¡¨ï¼Œæ¨¡æ‹Ÿä¸åŒæµè§ˆå™¨å’Œæ“ä½œç³»ç»Ÿ
    USER_AGENTS = [
        # Chrome on Windows
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
        # Chrome on macOS
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_5_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
        # Chrome on Linux
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        # Firefox on Windows
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0',
        # Firefox on macOS
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:120.0) Gecko/20100101 Firefox/120.0',
        # Safari on macOS
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15',
        # Edge on Windows
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0',
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0',
    ]
    
    def __init__(self, csv_file: str, download_base_dir: str = "./downloads", 
                 use_chrome: bool = False, chrome_debug_url: str = "http://127.0.0.1:9222",
                 proxy_file: str = None, proxy: str = None):
        self.csv_file = Path(csv_file)
        self.download_base_dir = Path(download_base_dir)
        self.download_base_dir.mkdir(parents=True, exist_ok=True)
        
        # Chromeç›¸å…³
        self.use_chrome = use_chrome and pychrome is not None
        self.chrome_debug_url = chrome_debug_url
        self.browser = None
        self.tab = None
        self._last_real_download_url = None  # ä¿å­˜æœ€åè·å–çš„çœŸå®ä¸‹è½½åœ°å€ï¼Œä¾›requestsä¸‹è½½ä½¿ç”¨
        
        # ä»£ç†ç›¸å…³
        self.proxies = []
        self.current_proxy_index = 0
        self._load_proxies(proxy_file, proxy)
        
        # åæ£€æµ‹ç›¸å…³ï¼šè®°å½•ä¸Šæ¬¡è¯·æ±‚æ—¶é—´ï¼Œç”¨äºæ§åˆ¶è¯·æ±‚é¢‘ç‡
        self.last_request_time = 0
        self.request_count = 0
        
        # è¯»å–CSVæ•°æ®
        self.games = []
        self._load_csv()
        
        if self.use_chrome:
            self._connect_chrome()
    
    def _connect_chrome(self):
        """è¿æ¥åˆ°Chromeè°ƒè¯•ç«¯å£"""
        if not pychrome:
            print("âš ï¸  pychromeæœªå®‰è£…ï¼Œå°†ä½¿ç”¨requestsæ–¹å¼")
            self.use_chrome = False
            return False
        
        try:
            # Chromeæœ¬åœ°è¿æ¥ä¸ä½¿ç”¨ä»£ç†ï¼ˆä¸´æ—¶å–æ¶ˆä»£ç†ç¯å¢ƒå˜é‡ï¼‰
            import os
            old_proxy_env = {}
            proxy_env_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']
            for var in proxy_env_vars:
                if var in os.environ:
                    old_proxy_env[var] = os.environ[var]
                    del os.environ[var]
            
            try:
                self.browser = pychrome.Browser(url=self.chrome_debug_url)
                print(f"âœ… å·²è¿æ¥åˆ° Chrome: {self.chrome_debug_url}")
                return True
            finally:
                # æ¢å¤ä»£ç†ç¯å¢ƒå˜é‡
                for var, value in old_proxy_env.items():
                    os.environ[var] = value
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è¿æ¥åˆ° Chrome è°ƒè¯•ç«¯å£: {self.chrome_debug_url}")
            print(f"   å°†ä½¿ç”¨requestsæ–¹å¼ï¼ˆå¯èƒ½è¢«æ‹¦æˆªï¼‰")
            self.use_chrome = False
            return False
    
    def _get_chrome_tab(self):
        """è·å–æˆ–åˆ›å»ºChromeæ ‡ç­¾é¡µ"""
        if not self.use_chrome or not self.browser:
            return None
        
        # ä¸´æ—¶å–æ¶ˆä»£ç†ç¯å¢ƒå˜é‡ï¼ˆChromeæœ¬åœ°è¿æ¥ä¸ä½¿ç”¨ä»£ç†ï¼‰
        import os
        old_proxy_env = {}
        proxy_env_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']
        for var in proxy_env_vars:
            if var in os.environ:
                old_proxy_env[var] = os.environ[var]
                del os.environ[var]
        
        # è®¾ç½®NO_PROXYï¼Œæ’é™¤æœ¬åœ°åœ°å€
        old_no_proxy = os.environ.get('NO_PROXY', '')
        os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0'
        
        try:
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    if self.tab:
                        try:
                            # æµ‹è¯•æ ‡ç­¾é¡µæ˜¯å¦ä»ç„¶æœ‰æ•ˆ
                            self.tab.Runtime.evaluate(expression="1")
                            return self.tab
                        except Exception as e:
                            # æ ‡ç­¾é¡µå·²å¤±æ•ˆï¼Œé‡ç½®
                            self.tab = None
                            if attempt < max_retries - 1:
                                print(f"   âš ï¸  æ ‡ç­¾é¡µè¿æ¥æ–­å¼€ï¼Œé‡æ–°è¿æ¥... ({attempt + 1}/{max_retries})")
                                time.sleep(1)
                    
                    # é‡æ–°è·å–æˆ–åˆ›å»ºæ ‡ç­¾é¡µ
                    tabs = self.browser.list_tab()
                    if tabs:
                        self.tab = tabs[0]
                    else:
                        self.tab = self.browser.new_tab()
                    
                    self.tab.start()
                    self.tab.Network.enable()
                    self.tab.Page.enable()
                    self.tab.Runtime.evaluate(expression="1")  # æµ‹è¯•è¿æ¥
                    
                    return self.tab
                except Exception as e:
                    error_msg = str(e)
                    if "websocket" in error_msg.lower() or "connection" in error_msg.lower():
                        if attempt < max_retries - 1:
                            print(f"   âš ï¸  WebSocketè¿æ¥å¼‚å¸¸ï¼Œé‡è¯•... ({attempt + 1}/{max_retries})")
                            # é‡ç½®æ ‡ç­¾é¡µå’Œæµè§ˆå™¨è¿æ¥
                            self.tab = None
                            time.sleep(2 + attempt)  # é€’å¢ç­‰å¾…æ—¶é—´ï¼š2ç§’ã€3ç§’ã€4ç§’
                            # å°è¯•é‡æ–°è¿æ¥æµè§ˆå™¨ï¼ˆä»£ç†ç¯å¢ƒå˜é‡å·²å–æ¶ˆï¼‰
                            try:
                                self.browser = pychrome.Browser(url=self.chrome_debug_url)
                            except Exception as browser_error:
                                print(f"   âš ï¸  é‡æ–°è¿æ¥æµè§ˆå™¨å¤±è´¥: {browser_error}")
                                # å¦‚æœæµè§ˆå™¨è¿æ¥å¤±è´¥ï¼Œå¯èƒ½æ˜¯Chromeæ²¡æœ‰è¿è¡Œ
                                if attempt == max_retries - 2:  # æœ€åä¸€æ¬¡é‡è¯•å‰
                                    print(f"   ğŸ’¡ æç¤º: è¯·ç¡®ä¿Chromeå·²å¯åŠ¨å¹¶å¯ç”¨è¿œç¨‹è°ƒè¯•ç«¯å£ {self.chrome_debug_url}")
                            continue
                    print(f"âš ï¸  è·å–Chromeæ ‡ç­¾é¡µå¤±è´¥: {e}")
                    if attempt == max_retries - 1:
                        return None
            
            return None
        finally:
            # æ¢å¤ä»£ç†ç¯å¢ƒå˜é‡
            for var, value in old_proxy_env.items():
                os.environ[var] = value
            # æ¢å¤NO_PROXY
            if old_no_proxy:
                os.environ['NO_PROXY'] = old_no_proxy
            elif 'NO_PROXY' in os.environ:
                del os.environ['NO_PROXY']
    
    def _load_csv(self):
        """åŠ è½½CSVæ–‡ä»¶"""
        if not self.csv_file.exists():
            raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {self.csv_file}")
        
        with open(self.csv_file, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # å¦‚æœæ–°åˆ—ä¸å­˜åœ¨ï¼Œæ·»åŠ é»˜è®¤å€¼"å¦"
                if 'æ˜¯å¦æœ‰å®‰å“ä¸‹è½½é“¾æ¥' not in row:
                    row['æ˜¯å¦æœ‰å®‰å“ä¸‹è½½é“¾æ¥'] = 'å¦'
                self.games.append(row)
        
        print(f"âœ… å·²åŠ è½½ {len(self.games)} ä¸ªæ¸¸æˆ")
    
    def _load_proxies(self, proxy_file: str = None, proxy: str = None):
        """åŠ è½½ä»£ç†åˆ—è¡¨"""
        # å¦‚æœæŒ‡å®šäº†å•ä¸ªä»£ç†
        if proxy:
            self.proxies.append(proxy)
            print(f"âœ… å·²åŠ è½½ä»£ç†: {proxy}")
            return
        
        # å¦‚æœæŒ‡å®šäº†ä»£ç†æ–‡ä»¶
        if proxy_file:
            proxy_path = Path(proxy_file)
            if proxy_path.exists():
                with open(proxy_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            self.proxies.append(line)
                print(f"âœ… å·²ä»æ–‡ä»¶åŠ è½½ {len(self.proxies)} ä¸ªä»£ç†")
            else:
                print(f"âš ï¸  ä»£ç†æ–‡ä»¶ä¸å­˜åœ¨: {proxy_file}")
                return
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šä»£ç†ï¼Œå…ˆå°è¯•æ£€æµ‹æœ¬åœ°VPNä»£ç†
        if not self.proxies:
            print(f"ğŸ” æœªæŒ‡å®šä»£ç†ï¼Œå…ˆæ£€æµ‹æœ¬åœ°VPNä»£ç†ï¼ˆShadowrocket/Clashç­‰ï¼‰...")
            local_proxies = self._detect_local_vpn_proxy()
            if local_proxies:
                self.proxies = local_proxies
                print(f"âœ… æ£€æµ‹åˆ°æœ¬åœ°VPNä»£ç†: {self.proxies[0]}")
            else:
                print(f"âš ï¸  æœªæ£€æµ‹åˆ°æœ¬åœ°VPNä»£ç†")
                print(f"")
                print(f"ğŸ’¡ Shadowrocketç”¨æˆ·è¯·æ‰‹åŠ¨é…ç½®:")
                print(f"   1. æŸ¥çœ‹Shadowrocketè®¾ç½®ä¸­çš„HTTPä»£ç†ç«¯å£ï¼ˆé€šå¸¸æ˜¯7890ï¼‰")
                print(f"   2. ä½¿ç”¨å‘½ä»¤: --proxy http://127.0.0.1:7890")
                print(f"   3. æˆ–åˆ›å»ºproxies.txtæ–‡ä»¶: echo 'http://127.0.0.1:7890' > proxies.txt")
                print(f"")
                print(f"âš ï¸  è·³è¿‡å…è´¹ä»£ç†è·å–ï¼ˆå¯ç”¨æ€§è¾ƒä½ï¼‰ï¼Œå°†ä¸ä½¿ç”¨ä»£ç†")
                print(f"   å¦‚æœé‡åˆ°IPé™åˆ¶ï¼Œè¯·æ‰‹åŠ¨é…ç½®VPNä»£ç†")
    
    def _detect_local_vpn_proxy(self) -> List[str]:
        """æ£€æµ‹æœ¬åœ°VPNä»£ç†ç«¯å£"""
        if not requests:
            return []
        
        # å¸¸è§VPNä»£ç†ç«¯å£ï¼ˆä¼˜å…ˆHTTPï¼Œå› ä¸ºä¸éœ€è¦é¢å¤–ä¾èµ–ï¼‰
        common_proxies = [
            # Shadowrocket / Clash HTTPï¼ˆæœ€å¸¸è§ï¼‰
            ('http://127.0.0.1:7890', 'Shadowrocket/Clash HTTP'),
            ('http://127.0.0.1:1082', 'Shadowrocket HTTP (1082)'),
            ('http://127.0.0.1:8080', 'é€šç”¨HTTPä»£ç†'),
            ('http://127.0.0.1:8888', 'é€šç”¨HTTPä»£ç†'),
            ('http://127.0.0.1:6152', 'Surge HTTP'),
            # SOCKS5ï¼ˆéœ€è¦pysocksï¼‰
            ('socks5://127.0.0.1:1080', 'V2Ray/Shadowsocks SOCKS5'),
            ('socks5://127.0.0.1:7891', 'Clash SOCKS5'),
            ('socks5://127.0.0.1:6153', 'Surge SOCKS5'),
        ]
        
        for proxy_url, name in common_proxies:
            try:
                # å…ˆæ£€æŸ¥ç«¯å£æ˜¯å¦å¼€æ”¾ï¼ˆå¿«é€Ÿæ£€æµ‹ï¼‰
                import socket
                port = int(proxy_url.split(':')[-1].split('/')[0])
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.settimeout(0.5)
                result = sock.connect_ex(('127.0.0.1', port))
                sock.close()
                
                if result != 0:
                    continue  # ç«¯å£æœªå¼€æ”¾ï¼Œè·³è¿‡
                
                # ç«¯å£å¼€æ”¾ï¼Œæµ‹è¯•ä»£ç†æ˜¯å¦å¯ç”¨
                proxy_dict = self._format_proxy_for_requests(proxy_url)
                if not proxy_dict:
                    continue
                
                # å¿«é€Ÿæµ‹è¯•ï¼ˆä½¿ç”¨ç®€å•çš„æµ‹è¯•URLï¼‰
                test_response = requests.get(
                    'https://httpbin.org/ip',
                    proxies=proxy_dict,
                    timeout=3
                )
                if test_response.status_code == 200:
                    ip_info = test_response.json()
                    print(f"   âœ… æ£€æµ‹åˆ° {name}: {proxy_url}")
                    print(f"      å½“å‰IP: {ip_info.get('origin', 'N/A')}")
                    return [proxy_url]
            except Exception as e:
                continue
        
        return []
    
    def _fetch_free_proxies(self) -> List[str]:
        """è‡ªåŠ¨è·å–å…è´¹ä»£ç†åˆ—è¡¨"""
        if not requests:
            return []
        
        proxies = []
        
        # ä»å…è´¹ä»£ç†APIè·å–
        print(f"   ğŸ“¡ ä»å…è´¹ä»£ç†æœåŠ¡è·å–ä»£ç†åˆ—è¡¨...")
        
        # å°è¯•å¤šä¸ªå…è´¹ä»£ç†APIæº
        proxy_sources = [
            # ProxyScrape API (è¿”å› ip:port æ ¼å¼)
            ("https://api.proxyscrape.com/v2/?request=get&protocol=http&timeout=10000&country=all&ssl=all&anonymity=all", "ip:port"),
            # GitHubä»£ç†åˆ—è¡¨
            ("https://raw.githubusercontent.com/TheSpeedX/PROXY-List/master/http.txt", "ip:port"),
            ("https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/http.txt", "ip:port"),
            ("https://raw.githubusercontent.com/mmpx12/proxy-list/master/http.txt", "ip:port"),
        ]
        
        for source_url, format_type in proxy_sources:
            try:
                print(f"   ğŸ” å°è¯•ä»ä»£ç†æºè·å–...")
                response = requests.get(source_url, timeout=15, headers={
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
                })
                if response.status_code == 200:
                    lines = response.text.strip().split('\n')
                    for line in lines:
                        line = line.strip()
                        if line and ':' in line and not line.startswith('#'):
                            # æ ¼å¼åŒ–ä¸º http://ip:port
                            if not line.startswith('http'):
                                proxy = f"http://{line}"
                            else:
                                proxy = line
                            # å»é‡
                            if proxy not in proxies:
                                proxies.append(proxy)
                    
                    if proxies:
                        print(f"   âœ… è·å–åˆ° {len(proxies)} ä¸ªä»£ç†å€™é€‰")
                        break
            except Exception as e:
                continue
        
        # æµ‹è¯•ä»£ç†å¯ç”¨æ€§ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼Œæ‰¾åˆ°3-5ä¸ªå¯ç”¨å³å¯ï¼‰
        if proxies:
            print(f"   ğŸ§ª å¿«é€Ÿæµ‹è¯•ä»£ç†å¯ç”¨æ€§ï¼ˆæµ‹è¯•å‰50ä¸ªï¼Œæ‰¾åˆ°3ä¸ªå³åœæ­¢ï¼‰...")
            tested_proxies = []
            # ä½¿ç”¨ç®€å•çš„æµ‹è¯•URL
            test_url = "https://httpbin.org/ip"
            
            for i, proxy in enumerate(proxies[:50], 1):  # åªæµ‹è¯•å‰50ä¸ª
                if len(tested_proxies) >= 3:  # æ‰¾åˆ°3ä¸ªå¯ç”¨ä»£ç†å°±å¤Ÿäº†
                    print(f"   âœ… å·²æ‰¾åˆ°è¶³å¤Ÿçš„å¯ç”¨ä»£ç†ï¼Œåœæ­¢æµ‹è¯•")
                    break
                
                try:
                    proxy_dict = self._format_proxy_for_requests(proxy)
                    if not proxy_dict:
                        continue
                    
                    # å¿«é€Ÿæµ‹è¯•ï¼ˆè¶…æ—¶æ—¶é—´çŸ­ï¼‰
                    test_response = requests.get(
                        test_url, 
                        proxies=proxy_dict, 
                        timeout=3,  # ç¼©çŸ­è¶…æ—¶æ—¶é—´
                        headers={
                            'User-Agent': 'Mozilla/5.0'
                        }
                    )
                    if test_response.status_code == 200:
                        tested_proxies.append(proxy)
                        ip_info = test_response.json()
                        print(f"   âœ… [{i}] ä»£ç†å¯ç”¨: {proxy} (IP: {ip_info.get('origin', 'N/A')[:20]})")
                    
                except:
                    # é™é»˜å¤±è´¥ï¼Œç»§ç»­æµ‹è¯•ä¸‹ä¸€ä¸ª
                    continue
            
            if tested_proxies:
                print(f"   âœ… æ€»å…±æ‰¾åˆ° {len(tested_proxies)} ä¸ªå¯ç”¨ä»£ç†")
                return tested_proxies
            else:
                print(f"   âš ï¸  æµ‹è¯•äº†50ä¸ªä»£ç†ï¼Œéƒ½ä¸å¯ç”¨")
                print(f"   ğŸ’¡ æç¤º: å…è´¹ä»£ç†å¯ç”¨æ€§è¾ƒä½")
                print(f"   ğŸ’¡ å»ºè®®: ä½¿ç”¨VPNä»£ç†æˆ–ä»˜è´¹ä»£ç†æœåŠ¡")
        else:
            print(f"   âš ï¸  æœªèƒ½ä»ä»£ç†æºè·å–åˆ°ä»£ç†åˆ—è¡¨")
        
        return []
    
    def _get_next_proxy(self) -> Optional[str]:
        """è·å–ä¸‹ä¸€ä¸ªä»£ç†ï¼ˆè½®æ¢ï¼‰"""
        if not self.proxies:
            return None
        
        proxy = self.proxies[self.current_proxy_index]
        self.current_proxy_index = (self.current_proxy_index + 1) % len(self.proxies)
        return proxy
    
    def _get_random_user_agent(self) -> str:
        """éšæœºè·å–ä¸€ä¸ªUser-Agent"""
        return random.choice(self.USER_AGENTS)
    
    def _get_browser_headers(self, referer: str = None, is_download: bool = False) -> dict:
        """ç”Ÿæˆå®Œæ•´çš„æµè§ˆå™¨è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨"""
        user_agent = self._get_random_user_agent()
        
        # æ ¹æ®User-Agentåˆ¤æ–­æ“ä½œç³»ç»Ÿï¼Œè®¾ç½®ç›¸åº”çš„Accept-Language
        if 'Windows' in user_agent:
            accept_language = random.choice([
                'zh-CN,zh;q=0.9,en;q=0.8',
                'zh-CN,zh;q=0.9',
                'en-US,en;q=0.9,zh-CN;q=0.8'
            ])
        elif 'Macintosh' in user_agent:
            accept_language = random.choice([
                'zh-CN,zh;q=0.9,en;q=0.8',
                'zh-CN,zh;q=0.9',
                'en-US,en;q=0.9,zh-CN;q=0.8'
            ])
        else:
            accept_language = 'zh-CN,zh;q=0.9,en;q=0.8'
        
        # åŸºç¡€è¯·æ±‚å¤´
        headers = {
            'User-Agent': user_agent,
            'Accept-Language': accept_language,
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': random.choice(['max-age=0', 'no-cache', 'no-store']),
        }
        
        # æ ¹æ®è¯·æ±‚ç±»å‹è®¾ç½®ä¸åŒçš„Acceptå¤´
        if is_download:
            headers['Accept'] = '*/*'
        else:
            headers['Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7'
        
        # æ·»åŠ Sec-Fetch-* å¤´ï¼ˆç°ä»£æµè§ˆå™¨çš„ç‰¹å¾ï¼‰
        if not is_download:
            headers['Sec-Fetch-Dest'] = 'document'
            headers['Sec-Fetch-Mode'] = 'navigate'
            headers['Sec-Fetch-Site'] = random.choice(['none', 'same-origin', 'same-site'])
            headers['Sec-Fetch-User'] = '?1'
        else:
            headers['Sec-Fetch-Dest'] = 'empty'
            headers['Sec-Fetch-Mode'] = 'no-cors'
            headers['Sec-Fetch-Site'] = random.choice(['same-origin', 'cross-site'])
        
        # æ·»åŠ Referer
        if referer:
            headers['Referer'] = referer
        elif not is_download:
            headers['Referer'] = 'https://www.kxdw.com/'
        
        # éšæœºæ·»åŠ ä¸€äº›é¢å¤–çš„æµè§ˆå™¨ç‰¹å¾å¤´
        if random.random() > 0.5:  # 50%æ¦‚ç‡æ·»åŠ 
            headers['DNT'] = random.choice(['1', '0'])  # Do Not Track
        
        return headers
    
    def _random_delay(self, min_seconds: float = 0.5, max_seconds: float = 2.0):
        """éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸ºï¼Œå¹¶æ§åˆ¶è¯·æ±‚é¢‘ç‡"""
        # è®¡ç®—è·ç¦»ä¸Šæ¬¡è¯·æ±‚çš„æ—¶é—´
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        # å¦‚æœè·ç¦»ä¸Šæ¬¡è¯·æ±‚æ—¶é—´å¤ªçŸ­ï¼Œå¢åŠ å»¶è¿Ÿ
        min_interval = random.uniform(1.0, 3.0)  # æœ€å°è¯·æ±‚é—´éš”1-3ç§’
        if time_since_last < min_interval:
            wait_time = min_interval - time_since_last + random.uniform(min_seconds, max_seconds)
        else:
            wait_time = random.uniform(min_seconds, max_seconds)
        
        if wait_time > 0:
            time.sleep(wait_time)
        
        self.last_request_time = time.time()
        self.request_count += 1
    
    def _format_proxy_for_requests(self, proxy: Optional[str]) -> dict:
        """å°†ä»£ç†å­—ç¬¦ä¸²æ ¼å¼åŒ–ä¸ºrequestsåº“éœ€è¦çš„æ ¼å¼"""
        if not proxy:
            return {}
        
        # æ”¯æŒ http, https, socks5
        if proxy.startswith('http://') or proxy.startswith('https://'):
            return {
                'http': proxy,
                'https': proxy
            }
        elif proxy.startswith('socks5://'):
            # éœ€è¦å®‰è£… requests[socks] æˆ– PySocks
            try:
                import socks
                return {
                    'http': proxy,
                    'https': proxy
                }
            except ImportError:
                print(f"   âš ï¸  ä½¿ç”¨SOCKS5ä»£ç†éœ€è¦å®‰è£…PySocks: pip install pysocks")
                return {}
        else:
            # é»˜è®¤å½“ä½œHTTPä»£ç†
            if not proxy.startswith('http://'):
                proxy = 'http://' + proxy
            return {
                'http': proxy,
                'https': proxy
            }
    
    def _save_csv(self):
        """ä¿å­˜CSVæ–‡ä»¶"""
        with open(self.csv_file, 'w', newline='', encoding='utf-8-sig') as f:
            if not self.games:
                return
            
            fieldnames = ['æ¸¸æˆåç§°', 'è¯¦æƒ…é¡µé“¾æ¥', 'æ˜¯å¦å·²ä¸‹è½½', 'æ˜¯å¦æœ‰å®‰å“ä¸‹è½½é“¾æ¥']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(self.games)
    
    def _calculate_similarity(self, query: str, suggestion: str) -> float:
        """è®¡ç®—æŸ¥è¯¢è¯ä¸å»ºè®®è¯ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼ˆ0-1ä¹‹é—´ï¼‰
        
        é‡‡ç”¨å¤šç§ç­–ç•¥è®¡ç®—ç›¸ä¼¼åº¦ï¼š
        1. å®Œå…¨åŒ¹é…å¾—åˆ†æœ€é«˜
        2. åŒ…å«å…³ç³»å¾—åˆ†æ¬¡é«˜
        3. å…¬å…±å­—ç¬¦æ¯”ä¾‹ä½œä¸ºåŸºç¡€å¾—åˆ†
        """
        # æ ‡å‡†åŒ–ï¼šè½¬å°å†™ï¼Œç§»é™¤ç©ºæ ¼å’Œå¸¸è§æ ‡ç‚¹
        def normalize(s):
            s = s.lower()
            # ç§»é™¤ç©ºæ ¼ã€æ‹¬å·ã€å†’å·ç­‰å¸¸è§ç¬¦å·
            s = re.sub(r'[\s\(\)\[\]ã€ã€‘ï¼ˆï¼‰:ï¼š\-_]', '', s)
            return s
        
        query_norm = normalize(query)
        suggestion_norm = normalize(suggestion)
        
        if not query_norm or not suggestion_norm:
            return 0.0
        
        # å®Œå…¨åŒ¹é…
        if query_norm == suggestion_norm:
            return 1.0
        
        # åŒ…å«å…³ç³»ï¼ˆæŸ¥è¯¢è¯åŒ…å«åœ¨å»ºè®®è¯ä¸­ï¼‰
        if query_norm in suggestion_norm:
            # æŸ¥è¯¢è¯è¶Šé•¿å å»ºè®®è¯æ¯”ä¾‹è¶Šå¤§ï¼Œå¾—åˆ†è¶Šé«˜
            return 0.85 + 0.15 * (len(query_norm) / len(suggestion_norm))
        
        # åŒ…å«å…³ç³»ï¼ˆå»ºè®®è¯åŒ…å«åœ¨æŸ¥è¯¢è¯ä¸­ï¼‰
        if suggestion_norm in query_norm:
            return 0.75 + 0.15 * (len(suggestion_norm) / len(query_norm))
        
        # è®¡ç®—æœ€é•¿å…¬å…±å­ä¸²æ¯”ä¾‹
        def longest_common_substring(s1, s2):
            m, n = len(s1), len(s2)
            dp = [[0] * (n + 1) for _ in range(m + 1)]
            max_len = 0
            for i in range(1, m + 1):
                for j in range(1, n + 1):
                    if s1[i-1] == s2[j-1]:
                        dp[i][j] = dp[i-1][j-1] + 1
                        max_len = max(max_len, dp[i][j])
            return max_len
        
        lcs_len = longest_common_substring(query_norm, suggestion_norm)
        lcs_ratio = lcs_len / max(len(query_norm), len(suggestion_norm))
        
        # è®¡ç®—å…¬å…±å­—ç¬¦æ¯”ä¾‹ï¼ˆJaccardç›¸ä¼¼åº¦ï¼‰
        query_chars = set(query_norm)
        suggestion_chars = set(suggestion_norm)
        common_chars = query_chars & suggestion_chars
        jaccard = len(common_chars) / len(query_chars | suggestion_chars) if (query_chars | suggestion_chars) else 0
        
        # ç»¼åˆå¾—åˆ†ï¼šæœ€é•¿å…¬å…±å­ä¸²æ¯”ä¾‹æƒé‡0.6ï¼ŒJaccardç›¸ä¼¼åº¦æƒé‡0.4
        similarity = lcs_ratio * 0.6 + jaccard * 0.4
        
        return similarity
    
    def _get_folder_name(self, game_name: str) -> str:
        """ä½¿ç”¨ç™¾åº¦å»ºè®®è¯è·å–æ–‡ä»¶å¤¹åï¼Œé€‰æ‹©å…³è”æ€§æœ€å¤§çš„å»ºè®®è¯
        
        ç­–ç•¥ï¼š
        1. è·å–æ‰€æœ‰ç™¾åº¦å»ºè®®è¯
        2. è®¡ç®—æ¯ä¸ªå»ºè®®è¯ä¸æ¸¸æˆåçš„ç›¸ä¼¼åº¦
        3. é€‰æ‹©ç›¸ä¼¼åº¦æœ€é«˜ä¸”è¶…è¿‡é˜ˆå€¼çš„å»ºè®®è¯
        4. å¦‚æœæ²¡æœ‰æ»¡è¶³æ¡ä»¶çš„å»ºè®®è¯ï¼Œä½¿ç”¨åŸå§‹æ¸¸æˆå
        """
        if get_baidu_suggestions:
            try:
                suggestions = get_baidu_suggestions(game_name)
                if suggestions:
                    # è®¡ç®—æ¯ä¸ªå»ºè®®è¯ä¸æ¸¸æˆåçš„ç›¸ä¼¼åº¦
                    best_suggestion = None
                    best_similarity = 0.0
                    min_similarity_threshold = 0.3  # æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼
                    
                    print(f"   ğŸ“‹ ç™¾åº¦å»ºè®®è¯åˆ—è¡¨:")
                    for i, suggestion in enumerate(suggestions[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
                        similarity = self._calculate_similarity(game_name, suggestion)
                        print(f"      {i}. {suggestion} (ç›¸ä¼¼åº¦: {similarity:.2f})")
                        if similarity > best_similarity:
                            best_similarity = similarity
                            best_suggestion = suggestion
                    
                    # å¦‚æœæœ€ä½³ç›¸ä¼¼åº¦é«˜äºé˜ˆå€¼ï¼Œä½¿ç”¨å»ºè®®è¯ï¼›å¦åˆ™ä½¿ç”¨åŸå§‹æ¸¸æˆå
                    if best_suggestion and best_similarity >= min_similarity_threshold:
                        folder_name = best_suggestion
                        print(f"   âœ… é€‰æ‹©å»ºè®®è¯: {folder_name} (ç›¸ä¼¼åº¦: {best_similarity:.2f})")
                    else:
                        folder_name = game_name
                        print(f"   âš ï¸  æœªæ‰¾åˆ°é«˜ç›¸ä¼¼åº¦å»ºè®®è¯ (æœ€é«˜: {best_similarity:.2f} < {min_similarity_threshold})")
                        print(f"   ğŸ“ ä½¿ç”¨åŸå§‹åç§°: {folder_name}")
                    
                    folder_name = re.sub(r'[<>:"/\\|?*]', '_', folder_name)
                    return folder_name
            except Exception as e:
                print(f"âš ï¸  è·å–å»ºè®®è¯å¤±è´¥: {e}ï¼Œä½¿ç”¨æ¸¸æˆåç§°")
        
        # å¦‚æœæ²¡æœ‰å»ºè®®è¯ï¼Œä½¿ç”¨æ¸¸æˆåç§°
        folder_name = re.sub(r'[<>:"/\\|?*]', '_', game_name)
        return folder_name
    
    def _parse_size_to_mb(self, size_str: str) -> float:
        """å°†å¤§å°å­—ç¬¦ä¸²è½¬æ¢ä¸ºMBæ•°å€¼"""
        if not size_str:
            return 0.0
        
        size_str = size_str.strip().upper()
        
        # åŒ¹é…æ•°å­—å’Œå•ä½
        match = re.match(r'(\d+\.?\d*)\s*([MG]B?)', size_str)
        if not match:
            return 0.0
        
        value = float(match.group(1))
        unit = match.group(2) or 'M'
        
        # è½¬æ¢ä¸ºMB
        if 'G' in unit:
            value = value * 1024
        
        return value
    
    def _parse_game_detail(self, page_url: str) -> Optional[Dict]:
        """è§£ææ¸¸æˆè¯¦æƒ…é¡µï¼Œæå–æ–‡ä»¶å¤§å°å’Œä¸‹è½½åœ°å€"""
        if self.use_chrome:
            return self._parse_with_chrome(page_url)
        else:
            print(f"   âš ï¸  ä½¿ç”¨requestsæ¨¡å¼ï¼Œå¯èƒ½è¢«æœåŠ¡å™¨æ£€æµ‹")
            print(f"   ğŸ’¡ å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå»ºè®®ä½¿ç”¨Chromeæ¨¡å¼: --chrome")
            return self._parse_with_requests(page_url)
    
    def _parse_with_chrome(self, page_url: str) -> Optional[Dict]:
        """ä½¿ç”¨Chromeè§£æè¯¦æƒ…é¡µ"""
        tab = self._get_chrome_tab()
        if not tab:
            return self._parse_with_requests(page_url)
        
        try:
            print(f"   ğŸŒ ä½¿ç”¨Chromeè®¿é—®è¯¦æƒ…é¡µ...")
            
            # ä½¿ç”¨é‡è¯•æœºåˆ¶å¤„ç† websocket å¼‚å¸¸
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    tab.Page.navigate(url=page_url)
                    break
                except Exception as e:
                    error_msg = str(e)
                    if "websocket" in error_msg.lower() and attempt < max_retries - 1:
                        print(f"   âš ï¸  WebSocketå¼‚å¸¸ï¼Œé‡æ–°è·å–æ ‡ç­¾é¡µ... ({attempt + 1}/{max_retries})")
                        time.sleep(1)
                        # é‡æ–°è·å–æ ‡ç­¾é¡µ
                        tab = self._get_chrome_tab()
                        if not tab:
                            return self._parse_with_requests(page_url)
                        continue
                    else:
                        raise e
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            wait_time = random.uniform(2, 4)
            time.sleep(wait_time)
            
            try:
                tab.Page.loadEventFired()
                time.sleep(1)
            except:
                pass
            
            # æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨ï¼Œç¡®ä¿"æœ¬åœ°ä¸‹è½½åœ°å€"èŠ‚ç‚¹åŠ è½½å‡ºæ¥
            print(f"   ğŸ“œ æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨...")
            # æ¸è¿›å¼æ»šåŠ¨ï¼Œç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½åŠ è½½ï¼Œæ¯æ¬¡æ»šåŠ¨åéšæœºåœç•™
            scroll_to_bottom_js = """
            (function() {
                let lastHeight = 0;
                let currentHeight = document.body.scrollHeight;
                let scrollCount = 0;
                const maxScrolls = 20; // æœ€å¤šæ»šåŠ¨20æ¬¡
                
                // æ¸è¿›å¼æ»šåŠ¨åˆ°åº•éƒ¨
                while (currentHeight !== lastHeight && scrollCount < maxScrolls) {
                    lastHeight = currentHeight;
                    window.scrollTo(0, currentHeight);
                    // éšæœºç­‰å¾…æ—¶é—´ï¼ˆ500-2000msï¼‰ï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º
                    const waitTime = Math.floor(Math.random() * 1500) + 500;
                    const startTime = Date.now();
                    while (Date.now() - startTime < waitTime) {
                        // ç­‰å¾…
                    }
                    currentHeight = document.body.scrollHeight;
                    scrollCount++;
                }
                
                // æœ€åå†æ»šåŠ¨ä¸€æ¬¡ç¡®ä¿åˆ°åº•
                window.scrollTo(0, document.body.scrollHeight);
                
                return {
                    finalHeight: document.body.scrollHeight,
                    scrollCount: scrollCount
                };
            })();
            """
            
            # ä½¿ç”¨é‡è¯•æœºåˆ¶å¤„ç†æ»šåŠ¨æ“ä½œ
            try:
                scroll_result = tab.Runtime.evaluate(expression=scroll_to_bottom_js, returnByValue=True)
                scroll_info = scroll_result.get("result", {}).get("value", {})
                print(f"   âœ… æ»šåŠ¨å®Œæˆï¼Œé¡µé¢é«˜åº¦: {scroll_info.get('finalHeight', 0)}pxï¼Œæ»šåŠ¨æ¬¡æ•°: {scroll_info.get('scrollCount', 0)}")
            except Exception as e:
                error_msg = str(e)
                if "websocket" in error_msg.lower():
                    print(f"   âš ï¸  æ»šåŠ¨æ—¶WebSocketå¼‚å¸¸ï¼Œåˆ‡æ¢åˆ°requestsæ¨¡å¼")
                    return self._parse_with_requests(page_url)
                raise e
            
            # æ»šåŠ¨å®Œæˆåéšæœºåœç•™ï¼ˆ1-3ç§’ï¼‰ï¼Œæ¨¡æ‹Ÿäººç±»é˜…è¯»è¡Œä¸º
            wait_after_scroll = random.uniform(1.0, 3.0)
            print(f"   â³ æ»šåŠ¨åéšæœºåœç•™ {wait_after_scroll:.1f} ç§’...")
            time.sleep(wait_after_scroll)
            
            # å†æ¬¡æ£€æŸ¥å¹¶æ»šåŠ¨ï¼Œç¡®ä¿"æœ¬åœ°ä¸‹è½½åœ°å€"èŠ‚ç‚¹å·²åŠ è½½
            try:
                check_and_scroll_js = """
                (function() {
                    const hasLocalDownload = document.body.innerText.includes('æœ¬åœ°ä¸‹è½½åœ°å€');
                    if (!hasLocalDownload) {
                        // å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå†æ»šåŠ¨ä¸€æ¬¡
                        window.scrollTo(0, document.body.scrollHeight);
                        // éšæœºç­‰å¾…æ—¶é—´ï¼ˆ800-1500msï¼‰ï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º
                        const waitTime = Math.floor(Math.random() * 700) + 800;
                        const startTime = Date.now();
                        while (Date.now() - startTime < waitTime) {
                            // ç­‰å¾…
                        }
                        return false;
                    }
                    return true;
                })();
                """
                check_result = tab.Runtime.evaluate(expression=check_and_scroll_js, returnByValue=True)
                if not check_result.get("result", {}).get("value", True):
                    print(f"   â³ ç­‰å¾…'æœ¬åœ°ä¸‹è½½åœ°å€'èŠ‚ç‚¹åŠ è½½...")
                    # éšæœºç­‰å¾…æ—¶é—´ï¼ˆ1.5-3ç§’ï¼‰ï¼Œæ¨¡æ‹Ÿäººç±»é˜…è¯»è¡Œä¸º
                    wait_time = random.uniform(1.5, 3.0)
                    print(f"   â³ éšæœºåœç•™ {wait_time:.1f} ç§’...")
                    time.sleep(wait_time)
            except Exception as e:
                error_msg = str(e)
                if "websocket" in error_msg.lower():
                    print(f"   âš ï¸  æ£€æŸ¥æ—¶WebSocketå¼‚å¸¸ï¼Œç»§ç»­å°è¯•è§£æ")
                else:
                    pass  # å¿½ç•¥å…¶ä»–å¼‚å¸¸ï¼Œç»§ç»­æ‰§è¡Œ
            
            # æå–æ¸¸æˆä¿¡æ¯
            extract_info_js = """
            (function() {
                const info = {
                    size: '',
                    download_url: ''
                };
                
                // æå–æ–‡ä»¶å¤§å° - ä¸“é—¨ä» ul.azgm_txtList çš„ li æ ‡ç­¾ä¸­æå–
                const ul = document.querySelector('ul.azgm_txtList');
                if (ul) {
                    const lis = ul.querySelectorAll('li');
                    for (let li of lis) {
                        const text = (li.textContent || li.innerText || '').trim();
                        // æŸ¥æ‰¾åŒ…å«å¤§å°ä¿¡æ¯çš„liï¼ˆé€šå¸¸åŒ…å«"MB"æˆ–"GB"ï¼‰
                        if (text.includes('MB') || text.includes('GB') || text.includes('Mb') || text.includes('Gb')) {
                            // æå–å¤§å°ä¿¡æ¯ï¼ˆåŒ¹é… "å¤§å°ï¼š87.52M" æˆ– "87.52MB" ç­‰æ ¼å¼ï¼‰
                            const sizeMatch = text.match(/(?:å¤§å°[ï¼š:]?\\s*)?(\\d+\\.?\\d*)\\s*([MG]B?)/i);
                            if (sizeMatch) {
                                info.size = sizeMatch[1] + sizeMatch[2].toUpperCase();
                                if (!info.size.includes('B')) {
                                    info.size += 'B';  // å¦‚æœåªæœ‰Mæˆ–Gï¼Œæ·»åŠ B
                                }
                                break;
                            }
                        }
                    }
                }
                
                // å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•åœ¨æ•´ä¸ªé¡µé¢ä¸­æŸ¥æ‰¾ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
                if (!info.size) {
                    const sizePatterns = [
                        /å¤§å°[ï¼š:]\\s*(\\d+\\.?\\d*)\\s*([MG]B?)/i,
                        /æ–‡ä»¶å¤§å°[ï¼š:]\\s*(\\d+\\.?\\d*)\\s*([MG]B?)/i,
                        /(\\d+\\.?\\d*)\\s*([MG]B)/i
                    ];
                    
                    const allText = document.body.innerText || document.body.textContent || '';
                    for (let pattern of sizePatterns) {
                        const match = allText.match(pattern);
                        if (match) {
                            info.size = match[1] + (match[2] || 'MB').toUpperCase();
                            if (!info.size.includes('B')) {
                                info.size += 'B';
                            }
                            break;
                        }
                    }
                }
                
                // æå–ä¸‹è½½åœ°å€ - ä¸“é—¨æŸ¥æ‰¾dtæ ‡ç­¾ï¼ˆåŒ…å«"æœ¬åœ°ä¸‹è½½åœ°å€"ï¼‰ä¸‹çš„aæ ‡ç­¾
                function findDownloadLink() {
                    const debug = {
                        dtTagsFound: 0,
                        matchingDtTags: [],
                        linksFound: [],
                        rejectedLinks: []
                    };
                    
                    // æ–¹æ³•1: æŸ¥æ‰¾æ‰€æœ‰dtæ ‡ç­¾ï¼Œæ‰¾åˆ°åŒ…å«"æœ¬åœ°ä¸‹è½½åœ°å€"çš„dtæ ‡ç­¾
                    const allDtTags = document.querySelectorAll('dt');
                    debug.dtTagsFound = allDtTags.length;
                    
                    for (let dt of allDtTags) {
                        const text = dt.textContent || dt.innerText || '';
                        if (text.includes('æœ¬åœ°ä¸‹è½½åœ°å€ï¼š') || text.includes('æœ¬åœ°ä¸‹è½½åœ°å€')) {
                            debug.matchingDtTags.push({
                                text: text.trim().substring(0, 50),
                                hasNextSibling: !!dt.nextElementSibling,
                                nextSiblingTag: dt.nextElementSibling ? dt.nextElementSibling.tagName : null
                            });
                            
                            // æŸ¥æ‰¾dtæ ‡ç­¾çš„ä¸‹ä¸€ä¸ªå…„å¼ŸèŠ‚ç‚¹ï¼ˆé€šå¸¸æ˜¯ddæ ‡ç­¾ï¼‰
                            let nextSibling = dt.nextElementSibling;
                            if (nextSibling) {
                                // åœ¨ddæ ‡ç­¾ä¸­æŸ¥æ‰¾aæ ‡ç­¾
                                const links = nextSibling.querySelectorAll('a[href]');
                                for (let link of links) {
                                    let href = link.href || link.getAttribute('href') || '';
                                    const linkText = (link.textContent || link.innerText || '').trim();
                                    
                                    if (href) {
                                        // è½¬æ¢ä¸ºå®Œæ•´URL
                                        if (!href.startsWith('http')) {
                                            if (href.startsWith('/')) {
                                                href = window.location.origin + href;
                                            } else {
                                                href = window.location.origin + '/' + href;
                                            }
                                        }
                                        
                                        // åˆ¤æ–­æ˜¯å¦ä¸ºHTMLé¡µé¢
                                        const isHtml = href.endsWith('.html') || 
                                                      href.endsWith('.htm') || 
                                                      href.includes('kxdw.com/android/') ||
                                                      href.includes('javascript:') ||
                                                      href.includes('#');
                                        
                                        if (isHtml) {
                                            debug.rejectedLinks.push({
                                                href: href.substring(0, 100),
                                                reason: href.endsWith('.html') ? 'ä»¥.htmlç»“å°¾' :
                                                        href.endsWith('.htm') ? 'ä»¥.htmç»“å°¾' :
                                                        href.includes('kxdw.com/android/') ? 'åŒ…å«è¯¦æƒ…é¡µè·¯å¾„' :
                                                        href.includes('javascript:') ? 'javascripté“¾æ¥' : 'åŒ…å«#é”šç‚¹'
                                            });
                                            continue;
                                        }
                                        
                                        debug.linksFound.push({
                                            href: href.substring(0, 100),
                                            text: linkText.substring(0, 30),
                                            source: 'dtæ ‡ç­¾çš„ddå…„å¼ŸèŠ‚ç‚¹'
                                        });
                                        
                                        if (!href.includes('javascript:') && !href.includes('#')) {
                                            return {url: href, debug: debug};
                                        }
                                    }
                                }
                            }
                            
                            // å¦‚æœddæ ‡ç­¾ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œåœ¨dtæ ‡ç­¾çš„çˆ¶å…ƒç´ ä¸­æŸ¥æ‰¾
                            let parent = dt.parentElement;
                            if (parent) {
                                const links = parent.querySelectorAll('a[href]');
                                for (let link of links) {
                                    let href = link.href || link.getAttribute('href') || '';
                                    const linkText = (link.textContent || link.innerText || '').trim();
                                    
                                    if (href) {
                                        if (!href.startsWith('http')) {
                                            if (href.startsWith('/')) {
                                                href = window.location.origin + href;
                                            } else {
                                                href = window.location.origin + '/' + href;
                                            }
                                        }
                                        
                                        // åˆ¤æ–­æ˜¯å¦ä¸ºHTMLé¡µé¢
                                        const isHtml = href.endsWith('.html') || 
                                                      href.endsWith('.htm') || 
                                                      href.includes('kxdw.com/android/') ||
                                                      href.includes('javascript:') ||
                                                      href.includes('#');
                                        
                                        if (isHtml) {
                                            debug.rejectedLinks.push({
                                                href: href.substring(0, 100),
                                                reason: href.endsWith('.html') ? 'ä»¥.htmlç»“å°¾' :
                                                        href.endsWith('.htm') ? 'ä»¥.htmç»“å°¾' :
                                                        href.includes('kxdw.com/android/') ? 'åŒ…å«è¯¦æƒ…é¡µè·¯å¾„' :
                                                        href.includes('javascript:') ? 'javascripté“¾æ¥' : 'åŒ…å«#é”šç‚¹'
                                            });
                                            continue;
                                        }
                                        
                                        debug.linksFound.push({
                                            href: href.substring(0, 100),
                                            text: linkText.substring(0, 30),
                                            source: 'dtæ ‡ç­¾çš„çˆ¶å…ƒç´ '
                                        });
                                        
                                        if (!href.includes('javascript:') && !href.includes('#')) {
                                            return {url: href, debug: debug};
                                        }
                                    }
                                }
                            }
                        }
                    }
                    
                    // æ–¹æ³•2: å¦‚æœæ²¡æ‰¾åˆ°dtæ ‡ç­¾ï¼Œä½¿ç”¨é€šç”¨æ–¹æ³•æŸ¥æ‰¾
                    const allElements = document.querySelectorAll('*');
                    for (let el of allElements) {
                        const text = el.textContent || el.innerText || '';
                        if (text.includes('æœ¬åœ°ä¸‹è½½åœ°å€')) {
                            // æŸ¥æ‰¾ä¸‹ä¸€ä¸ªå…„å¼ŸèŠ‚ç‚¹
                            let nextSibling = el.nextElementSibling;
                            if (nextSibling) {
                                const links = nextSibling.querySelectorAll('a[href]');
                                for (let link of links) {
                                    let href = link.href || link.getAttribute('href') || '';
                                    const linkText = (link.textContent || link.innerText || '').trim();
                                    
                                    if (href) {
                                        if (!href.startsWith('http')) {
                                            if (href.startsWith('/')) {
                                                href = window.location.origin + href;
                                            } else {
                                                href = window.location.origin + '/' + href;
                                            }
                                        }
                                        
                                        // åˆ¤æ–­æ˜¯å¦ä¸ºHTMLé¡µé¢
                                        const isHtml = href.endsWith('.html') || 
                                                      href.endsWith('.htm') || 
                                                      href.includes('kxdw.com/android/') ||
                                                      href.includes('javascript:') ||
                                                      href.includes('#');
                                        
                                        if (isHtml) {
                                            debug.rejectedLinks.push({
                                                href: href.substring(0, 100),
                                                reason: href.endsWith('.html') ? 'ä»¥.htmlç»“å°¾' :
                                                        href.endsWith('.htm') ? 'ä»¥.htmç»“å°¾' :
                                                        href.includes('kxdw.com/android/') ? 'åŒ…å«è¯¦æƒ…é¡µè·¯å¾„' :
                                                        href.includes('javascript:') ? 'javascripté“¾æ¥' : 'åŒ…å«#é”šç‚¹'
                                            });
                                            continue;
                                        }
                                        
                                        debug.linksFound.push({
                                            href: href.substring(0, 100),
                                            text: linkText.substring(0, 30),
                                            source: 'é€šç”¨æ–¹æ³•-å…„å¼ŸèŠ‚ç‚¹'
                                        });
                                        
                                        if (!href.includes('javascript:') && !href.includes('#')) {
                                            return {url: href, debug: debug};
                                        }
                                    }
                                }
                            }
                            
                            // åœ¨çˆ¶å…ƒç´ ä¸­æŸ¥æ‰¾
                            let parent = el.parentElement;
                            if (parent) {
                                const links = parent.querySelectorAll('a[href]');
                                for (let link of links) {
                                    let href = link.href || link.getAttribute('href') || '';
                                    const linkText = (link.textContent || link.innerText || '').trim();
                                    
                                    if (href) {
                                        if (!href.startsWith('http')) {
                                            if (href.startsWith('/')) {
                                                href = window.location.origin + href;
                                            } else {
                                                href = window.location.origin + '/' + href;
                                            }
                                        }
                                        
                                        // åˆ¤æ–­æ˜¯å¦ä¸ºHTMLé¡µé¢
                                        const isHtml = href.endsWith('.html') || 
                                                      href.endsWith('.htm') || 
                                                      href.includes('kxdw.com/android/') ||
                                                      href.includes('javascript:') ||
                                                      href.includes('#');
                                        
                                        if (isHtml) {
                                            debug.rejectedLinks.push({
                                                href: href.substring(0, 100),
                                                reason: href.endsWith('.html') ? 'ä»¥.htmlç»“å°¾' :
                                                        href.endsWith('.htm') ? 'ä»¥.htmç»“å°¾' :
                                                        href.includes('kxdw.com/android/') ? 'åŒ…å«è¯¦æƒ…é¡µè·¯å¾„' :
                                                        href.includes('javascript:') ? 'javascripté“¾æ¥' : 'åŒ…å«#é”šç‚¹'
                                            });
                                            continue;
                                        }
                                        
                                        debug.linksFound.push({
                                            href: href.substring(0, 100),
                                            text: linkText.substring(0, 30),
                                            source: 'é€šç”¨æ–¹æ³•-çˆ¶å…ƒç´ '
                                        });
                                        
                                        if (!href.includes('javascript:') && !href.includes('#')) {
                                            return {url: href, debug: debug};
                                        }
                                    }
                                }
                            }
                        }
                    }
                    
                    return {url: null, debug: debug};
                }
                
                const result = findDownloadLink();
                if (result && result.url) {
                    info.download_url = result.url;
                    info.debug = result.debug;
                } else if (result && result.debug) {
                    info.debug = result.debug;
                }
                
                // 3. å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«ä¸‹è½½ç›¸å…³å…³é”®è¯çš„é“¾æ¥ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
                if (!info.download_url) {
                    const allLinks = document.querySelectorAll('a[href]');
                    const downloadKeywords = ['ä¸‹è½½', 'download', 'down', 'apk'];
                    for (let link of allLinks) {
                        let href = link.href || link.getAttribute('href') || '';
                        const text = (link.textContent || link.innerText || '').toLowerCase();
                        
                        if (href && !href.startsWith('http')) {
                            if (href.startsWith('/')) {
                                href = window.location.origin + href;
                            } else {
                                href = window.location.origin + '/' + href;
                            }
                        }
                        
                        // æ£€æŸ¥é“¾æ¥æˆ–æ–‡æœ¬ä¸­æ˜¯å¦åŒ…å«ä¸‹è½½ç›¸å…³å…³é”®è¯ï¼Œä¸”ä¸æ˜¯HTMLé¡µé¢
                        const hasKeyword = downloadKeywords.some(kw => 
                            href.toLowerCase().includes(kw) || text.includes(kw)
                        );
                        
                        if (href && hasKeyword && !href.includes('javascript:') && 
                            !href.endsWith('.html') && !href.endsWith('.htm') &&
                            !href.includes('kxdw.com/android/')) {
                            info.download_url = href;
                            break;
                        }
                    }
                }
                
                return info;
            })();
            """
            
            # ä½¿ç”¨é‡è¯•æœºåˆ¶å¤„ç†è§£ææ“ä½œ
            try:
                result = tab.Runtime.evaluate(expression=extract_info_js, returnByValue=True)
                info = result.get("result", {}).get("value", {})
            except Exception as e:
                error_msg = str(e)
                if "websocket" in error_msg.lower():
                    print(f"   âš ï¸  è§£ææ—¶WebSocketå¼‚å¸¸ï¼Œåˆ‡æ¢åˆ°requestsæ¨¡å¼")
                    return self._parse_with_requests(page_url)
                raise e
            
            # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
            debug_info = info.get('debug', {})
            if debug_info:
                print(f"   ğŸ“Š è°ƒè¯•ä¿¡æ¯:")
                print(f"      - æ‰¾åˆ° {debug_info.get('dtTagsFound', 0)} ä¸ªdtæ ‡ç­¾")
                print(f"      - åŒ¹é…çš„dtæ ‡ç­¾: {len(debug_info.get('matchingDtTags', []))} ä¸ª")
                if debug_info.get('matchingDtTags'):
                    for i, dt in enumerate(debug_info['matchingDtTags'], 1):
                        print(f"        {i}. æ–‡æœ¬: {dt.get('text', '')}")
                        print(f"           ä¸‹ä¸€ä¸ªå…„å¼ŸèŠ‚ç‚¹: {dt.get('nextSiblingTag', 'æ— ')}")
                print(f"      - æ‰¾åˆ°çš„å€™é€‰é“¾æ¥: {len(debug_info.get('linksFound', []))} ä¸ª")
                if debug_info.get('linksFound'):
                    for i, link in enumerate(debug_info['linksFound'], 1):
                        print(f"        {i}. {link.get('href', '')[:80]}...")
                        print(f"           æ¥æº: {link.get('source', '')}, æ–‡æœ¬: {link.get('text', '')}")
                print(f"      - è¢«æ‹’ç»çš„é“¾æ¥: {len(debug_info.get('rejectedLinks', []))} ä¸ª")
                if debug_info.get('rejectedLinks'):
                    for i, link in enumerate(debug_info['rejectedLinks'], 1):
                        print(f"        {i}. {link.get('href', '')[:80]}...")
                        print(f"           åŸå› : {link.get('reason', 'æœªçŸ¥')}")
            
            # è°ƒè¯•ä¿¡æ¯ï¼šå¦‚æœæ²¡æ‰¾åˆ°ä¸‹è½½é“¾æ¥ï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯
            if not info.get('download_url'):
                debug_js = """
                (function() {
                    const debug = {
                        foundLocalDownloadText: false,
                        foundLinks: []
                    };
                    
                    // æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°"æœ¬åœ°ä¸‹è½½åœ°å€"æ–‡æœ¬
                    const allText = document.body.innerText || document.body.textContent || '';
                    debug.foundLocalDownloadText = allText.includes('æœ¬åœ°ä¸‹è½½åœ°å€');
                    
                    // æŸ¥æ‰¾æ‰€æœ‰åŒ…å«"æœ¬åœ°ä¸‹è½½åœ°å€"çš„å…ƒç´ 
                    const allElements = document.querySelectorAll('*');
                    for (let el of allElements) {
                        const text = el.textContent || el.innerText || '';
                        if (text.includes('æœ¬åœ°ä¸‹è½½åœ°å€')) {
                            const links = el.querySelectorAll('a[href]');
                            debug.foundLinks.push({
                                element: el.tagName,
                                className: el.className,
                                linksCount: links.length,
                                links: Array.from(links).map(l => l.href || l.getAttribute('href')).slice(0, 3)
                            });
                        }
                    }
                    
                    return debug;
                })();
                """
                try:
                    debug_result = tab.Runtime.evaluate(expression=debug_js, returnByValue=True)
                    debug_info = debug_result.get("result", {}).get("value", {})
                    if debug_info.get('foundLocalDownloadText'):
                        print(f"   âš ï¸  æ‰¾åˆ°'æœ¬åœ°ä¸‹è½½åœ°å€'æ–‡æœ¬ï¼Œä½†æœªæ‰¾åˆ°ä¸‹è½½é“¾æ¥")
                        if debug_info.get('foundLinks'):
                            print(f"   ğŸ“‹ æ‰¾åˆ° {len(debug_info['foundLinks'])} ä¸ªåŒ…å«è¯¥æ–‡æœ¬çš„å…ƒç´ ")
                    else:
                        print(f"   âš ï¸  æœªæ‰¾åˆ°'æœ¬åœ°ä¸‹è½½åœ°å€'æ–‡æœ¬")
                except:
                    pass  # å¿½ç•¥è°ƒè¯•ä¿¡æ¯çš„å¼‚å¸¸
            
            return info
            
        except Exception as e:
            error_msg = str(e)
            if "websocket" in error_msg.lower():
                print(f"   âš ï¸  Chrome WebSocketå¼‚å¸¸: {e}ï¼Œåˆ‡æ¢åˆ°requestsæ¨¡å¼")
            else:
                print(f"   âš ï¸  Chromeè§£æå¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨requests")
            return self._parse_with_requests(page_url)
    
    def _parse_with_requests(self, page_url: str) -> Optional[Dict]:
        """ä½¿ç”¨requestsè§£æè¯¦æƒ…é¡µ"""
        if not requests:
            return None
        
        try:
            # ä½¿ç”¨Sessionä¿æŒCookieå’Œè¿æ¥
            session = requests.Session()
            
            # è·å–ä»£ç†
            proxy = self._get_next_proxy()
            proxies = self._format_proxy_for_requests(proxy)
            if proxies:
                print(f"   ğŸŒ ä½¿ç”¨ä»£ç†: {list(proxies.values())[0]}")
            
            # åæ£€æµ‹æªæ–½ï¼šå…ˆè®¿é—®é¦–é¡µè·å–Cookieï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
            print(f"   ğŸ” å…ˆè®¿é—®é¦–é¡µè·å–Cookieï¼ˆåæ£€æµ‹æªæ–½ï¼‰...")
            try:
                # ä½¿ç”¨éšæœºUser-Agentå’Œå®Œæ•´è¯·æ±‚å¤´
                home_headers = self._get_browser_headers()
                home_response = session.get('https://www.kxdw.com/', headers=home_headers, proxies=proxies, timeout=15, allow_redirects=True)
                # éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»è¡Œä¸º
                self._random_delay(1.0, 3.0)
            except Exception as e:
                print(f"   âš ï¸  è®¿é—®é¦–é¡µå¤±è´¥: {e}ï¼Œç»§ç»­å°è¯•è®¿é—®è¯¦æƒ…é¡µ")
            
            # éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»æµè§ˆè¡Œä¸º
            self._random_delay(0.5, 1.5)
            
            # ä½¿ç”¨æ–°çš„éšæœºUser-Agentå’Œå®Œæ•´è¯·æ±‚å¤´è®¿é—®è¯¦æƒ…é¡µ
            headers = self._get_browser_headers(referer='https://www.kxdw.com/')
            response = session.get(page_url, headers=headers, proxies=proxies, timeout=30, allow_redirects=True)
            response.raise_for_status()
            
            # æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘åˆ°127.0.0.1æˆ–localhost
            final_url = response.url
            if '127.0.0.1' in final_url or 'localhost' in final_url:
                print(f"   âŒ æ£€æµ‹åˆ°é‡å®šå‘åˆ°æœ¬åœ°åœ°å€: {final_url}")
                print(f"   âš ï¸  ç½‘ç«™æ£€æµ‹åˆ°çˆ¬è™«è¡Œä¸ºï¼Œrequestsæ¨¡å¼æ— æ³•ç»•è¿‡")
                print(f"   ğŸ’¡ å¼ºçƒˆå»ºè®®ä½¿ç”¨Chromeæ¨¡å¼: python3 kxdw_downloader.py games_50_pages.csv --chrome")
                return None
            
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
            if len(response.text) < 100:
                print(f"   âš ï¸  å“åº”å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½æ˜¯é”™è¯¯é¡µé¢")
                print(f"   å“åº”å†…å®¹: {response.text[:200]}")
                return None
            
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦ä¸º"error"ï¼ˆIPé™åˆ¶çš„æƒ…å†µï¼‰
            if response.text.strip().lower() == 'error' or response.text.strip().startswith('error'):
                print(f"   âŒ æœåŠ¡å™¨è¿”å›'error'ï¼Œå¯èƒ½æ˜¯IPåœ°å€è¢«é™åˆ¶")
                print(f"   ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
                print(f"      1. åˆ‡æ¢ç½‘ç»œï¼ˆå¦‚ä½¿ç”¨5G/ç§»åŠ¨ç½‘ç»œï¼‰")
                print(f"      2. ä½¿ç”¨VPNæˆ–ä»£ç†æœåŠ¡å™¨")
                print(f"      3. æ›´æ¢ç½‘ç»œç¯å¢ƒåé‡è¯•")
                return None
            
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦åŒ…å«åçˆ¬è™«æç¤º
            if '127.0.0.1' in response.text or 'localhost' in response.text or 'access denied' in response.text.lower():
                print(f"   âŒ å“åº”å†…å®¹åŒ…å«åçˆ¬è™«æç¤º")
                print(f"   ğŸ’¡ å»ºè®®ä½¿ç”¨Chromeæ¨¡å¼: python3 kxdw_downloader.py games_50_pages.csv --chrome")
                return None
            
            info = {
                'size': '',
                'download_url': '',
                'debug': {
                    'dtTagsFound': 0,
                    'linksFound': [],
                    'rejectedLinks': []
                }
            }
            
            # æå–æ–‡ä»¶å¤§å° - ä¸“é—¨ä» ul.azgm_txtList çš„ li æ ‡ç­¾ä¸­æå–
            # é¦–å…ˆæŸ¥æ‰¾ ul class="azgm_txtList"
            ul_pattern = r'<ul[^>]*class=["\']azgm_txtList["\'][^>]*>(.*?)</ul>'
            ul_match = re.search(ul_pattern, response.text, re.DOTALL | re.IGNORECASE)
            if ul_match:
                ul_content = ul_match.group(1)
                # æŸ¥æ‰¾æ‰€æœ‰liæ ‡ç­¾
                li_pattern = r'<li[^>]*>(.*?)</li>'
                li_matches = re.findall(li_pattern, ul_content, re.DOTALL | re.IGNORECASE)
                for li_content in li_matches:
                    # ç§»é™¤HTMLæ ‡ç­¾ï¼Œåªä¿ç•™æ–‡æœ¬
                    text = re.sub(r'<[^>]+>', '', li_content).strip()
                    # æŸ¥æ‰¾åŒ…å«å¤§å°ä¿¡æ¯çš„æ–‡æœ¬ï¼ˆåŒ¹é… "å¤§å°ï¼š87.52M" æˆ– "87.52MB" ç­‰æ ¼å¼ï¼‰
                    if 'MB' in text.upper() or 'GB' in text.upper() or 'M' in text.upper() or 'G' in text.upper():
                        # ä¼˜å…ˆåŒ¹é… "å¤§å°ï¼š87.52M" æ ¼å¼
                        size_match = re.search(r'(?:å¤§å°[ï¼š:]?\s*)?(\d+\.?\d*)\s*([MG]B?)', text, re.IGNORECASE)
                        if size_match:
                            value = size_match.group(1)
                            unit = size_match.group(2).upper() if size_match.group(2) else 'MB'
                            if not unit.endswith('B'):
                                unit += 'B'
                            info['size'] = value + unit
                            break
            
            # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•åœ¨æ•´ä¸ªé¡µé¢ä¸­æŸ¥æ‰¾ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
            if not info.get('size'):
                size_patterns = [
                    r'å¤§å°[ï¼š:]\s*(\d+\.?\d*)\s*([MG]B?)',
                    r'æ–‡ä»¶å¤§å°[ï¼š:]\s*(\d+\.?\d*)\s*([MG]B?)',
                    r'(\d+\.?\d*)\s*([MG]B)'
                ]
                
                for pattern in size_patterns:
                    match = re.search(pattern, response.text, re.IGNORECASE)
                    if match:
                        value = match.group(1)
                        unit = (match.group(2) or 'MB').upper()
                        if not unit.endswith('B'):
                            unit += 'B'
                        info['size'] = value + unit
                        break
            
            # æå–ä¸‹è½½åœ°å€ - ä¸“é—¨æŸ¥æ‰¾dtæ ‡ç­¾ï¼ˆåŒ…å«"æœ¬åœ°ä¸‹è½½åœ°å€"ï¼‰ä¸‹çš„aæ ‡ç­¾
            # 1. æŸ¥æ‰¾dtæ ‡ç­¾ä¸­åŒ…å«"æœ¬åœ°ä¸‹è½½åœ°å€"çš„ï¼Œç„¶ååœ¨å…¶ä¸‹ä¸€ä¸ªå…„å¼ŸèŠ‚ç‚¹ï¼ˆé€šå¸¸æ˜¯ddï¼‰ä¸­æŸ¥æ‰¾aæ ‡ç­¾
            dt_pattern = r'<dt[^>]*>.*?æœ¬åœ°ä¸‹è½½åœ°å€.*?</dt>'
            dt_matches = re.findall(dt_pattern, response.text, re.IGNORECASE | re.DOTALL)
            info['debug']['dtTagsFound'] = len(dt_matches)
            
            if dt_matches:
                dt_match = re.search(dt_pattern, response.text, re.IGNORECASE | re.DOTALL)
                # æ‰¾åˆ°dtæ ‡ç­¾åï¼ŒæŸ¥æ‰¾å…¶åçš„ddæ ‡ç­¾ä¸­çš„aæ ‡ç­¾
                dt_end = dt_match.end()
                # åœ¨dtæ ‡ç­¾åæŸ¥æ‰¾ddæ ‡ç­¾ï¼ˆæœ€å¤š500å­—ç¬¦å†…ï¼‰
                search_text = response.text[dt_end:dt_end + 500]
                dd_pattern = r'<dd[^>]*>.*?<a[^>]+href=["\']([^"\']+)["\']'
                dd_match = re.search(dd_pattern, search_text, re.IGNORECASE | re.DOTALL)
                if dd_match:
                    url = dd_match.group(1)
                    if not url.startswith('http'):
                        base_url = '/'.join(page_url.split('/')[:3])
                        if url.startswith('/'):
                            url = base_url + url
                        else:
                            url = base_url + '/' + url
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºHTMLé¡µé¢
                    is_html = url.endswith('.html') or url.endswith('.htm') or 'javascript:' in url
                    if is_html:
                        reason = 'ä»¥.htmlç»“å°¾' if url.endswith('.html') else ('ä»¥.htmç»“å°¾' if url.endswith('.htm') else 'javascripté“¾æ¥')
                        info['debug']['rejectedLinks'].append({
                            'href': url[:100],
                            'reason': reason
                        })
                    elif url:
                        info['debug']['linksFound'].append({
                            'href': url[:100],
                            'source': 'dtæ ‡ç­¾çš„ddå…„å¼ŸèŠ‚ç‚¹'
                        })
                        info['download_url'] = url
            
            # 2. å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•æ›´å®½æ³›çš„åŒ¹é…ï¼šæŸ¥æ‰¾dtæ ‡ç­¾ï¼Œç„¶ååœ¨é™„è¿‘æŸ¥æ‰¾aæ ‡ç­¾
            if not info['download_url']:
                # æŸ¥æ‰¾åŒ…å«"æœ¬åœ°ä¸‹è½½åœ°å€"çš„dtæ ‡ç­¾ä½ç½®
                start_pos = response.text.find('æœ¬åœ°ä¸‹è½½åœ°å€')
                if start_pos != -1:
                    # å‘å‰æŸ¥æ‰¾dtæ ‡ç­¾çš„å¼€å§‹
                    dt_start = response.text.rfind('<dt', 0, start_pos)
                    if dt_start != -1:
                        # åœ¨dtæ ‡ç­¾åæŸ¥æ‰¾aæ ‡ç­¾ï¼ˆæœ€å¤š1000å­—ç¬¦ï¼‰
                        search_end = min(start_pos + 1000, len(response.text))
                        search_text = response.text[dt_start:search_end]
                        link_pattern = r'<a[^>]+href=["\']([^"\']+)["\']'
                        link_matches = re.findall(link_pattern, search_text, re.IGNORECASE)
                        if link_matches:
                            for url in link_matches:
                                if not url.startswith('http'):
                                    base_url = '/'.join(page_url.split('/')[:3])
                                    if url.startswith('/'):
                                        url = base_url + url
                                    else:
                                        url = base_url + '/' + url
                                
                                # åˆ¤æ–­æ˜¯å¦ä¸ºHTMLé¡µé¢
                                is_html = url.endswith('.html') or url.endswith('.htm') or 'javascript:' in url or 'kxdw.com/android/' in url
                                if is_html:
                                    reason = 'ä»¥.htmlç»“å°¾' if url.endswith('.html') else ('ä»¥.htmç»“å°¾' if url.endswith('.htm') else ('åŒ…å«è¯¦æƒ…é¡µè·¯å¾„' if 'kxdw.com/android/' in url else 'javascripté“¾æ¥'))
                                    info['debug']['rejectedLinks'].append({
                                        'href': url[:100],
                                        'reason': reason
                                    })
                                    continue
                                
                                info['debug']['linksFound'].append({
                                    'href': url[:100],
                                    'source': 'dtæ ‡ç­¾é™„è¿‘'
                                })
                                info['download_url'] = url
                                break
            
            # 3. å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾åŒ…å«ä¸‹è½½ç›¸å…³å…³é”®è¯çš„é“¾æ¥ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
            if not info['download_url']:
                # æŸ¥æ‰¾åŒ…å«ä¸‹è½½ã€downã€apkç­‰å…³é”®è¯çš„é“¾æ¥
                download_link_pattern = r'<a[^>]+href=["\']([^"\']*(?:download|down|apk)[^"\']*)["\'][^>]*>'
                matches = re.findall(download_link_pattern, response.text, re.IGNORECASE)
                if matches:
                    for url in matches:
                        if not url.startswith('http'):
                            base_url = '/'.join(page_url.split('/')[:3])
                            if url.startswith('/'):
                                url = base_url + url
                            else:
                                url = base_url + '/' + url
                        
                        # åˆ¤æ–­æ˜¯å¦ä¸ºHTMLé¡µé¢
                        is_html = (url.endswith('.html') or url.endswith('.htm') or 
                                  'kxdw.com/android/' in url or 'javascript:' in url)
                        if is_html:
                            reason = 'ä»¥.htmlç»“å°¾' if url.endswith('.html') else ('ä»¥.htmç»“å°¾' if url.endswith('.htm') else ('åŒ…å«è¯¦æƒ…é¡µè·¯å¾„' if 'kxdw.com/android/' in url else 'javascripté“¾æ¥'))
                            info['debug']['rejectedLinks'].append({
                                'href': url[:100],
                                'reason': reason
                            })
                            continue
                        
                        info['debug']['linksFound'].append({
                            'href': url[:100],
                            'source': 'åŒ…å«ä¸‹è½½å…³é”®è¯çš„é“¾æ¥'
                        })
                        info['download_url'] = url
                        break
            
            # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
            debug_info = info.get('debug', {})
            if debug_info:
                print(f"   ğŸ“Š è°ƒè¯•ä¿¡æ¯ (requestsæ¨¡å¼):")
                print(f"      - æ‰¾åˆ° {debug_info.get('dtTagsFound', 0)} ä¸ªdtæ ‡ç­¾")
                print(f"      - æ‰¾åˆ°çš„å€™é€‰é“¾æ¥: {len(debug_info.get('linksFound', []))} ä¸ª")
                if debug_info.get('linksFound'):
                    for i, link in enumerate(debug_info['linksFound'], 1):
                        print(f"        {i}. {link.get('href', '')[:80]}...")
                        print(f"           æ¥æº: {link.get('source', '')}")
                print(f"      - è¢«æ‹’ç»çš„é“¾æ¥: {len(debug_info.get('rejectedLinks', []))} ä¸ª")
                if debug_info.get('rejectedLinks'):
                    for i, link in enumerate(debug_info['rejectedLinks'], 1):
                        print(f"        {i}. {link.get('href', '')[:80]}...")
                        print(f"           åŸå› : {link.get('reason', 'æœªçŸ¥')}")
            
            return info
            
        except Exception as e:
            print(f"   âš ï¸  requestsè§£æå¤±è´¥: {e}")
            return None
    
    def _download_with_chrome(self, download_url: str, save_path: Path, expected_size_mb: float = 0.0) -> bool:
        """ä½¿ç”¨Chromeç›´æ¥ä¸‹è½½æ–‡ä»¶ï¼ˆæ›´ç¨³å®šï¼Œé¿å…è¿æ¥ä¸­æ–­ï¼‰
        Args:
            download_url: ä¸‹è½½URL
            save_path: ä¿å­˜è·¯å¾„
            expected_size_mb: é¢„æœŸæ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œç”¨äºåˆ¤æ–­ä¸‹è½½æ˜¯å¦å®Œæˆ
        Returns:
            bool: ä¸‹è½½æ˜¯å¦æˆåŠŸ
        """
        if not pychrome or not self.use_chrome:
            return False
        
        # å¦‚æœæ˜¯api.kxdw.com/adown/é“¾æ¥ï¼Œå…ˆè·å–çœŸå®ä¸‹è½½URL
        # ä½†ä¸è¦å–æ¶ˆä¸‹è½½ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨çœŸå®URLè®©Chromeä¸‹è½½
        real_url = None
        if 'api.kxdw.com/adown/' in download_url:
            print(f"   ğŸ” æ£€æµ‹åˆ°api.kxdw.com/adown/é“¾æ¥ï¼Œå…ˆè·å–çœŸå®ä¸‹è½½åœ°å€...")
            real_url = self._get_real_download_url_with_chrome(download_url)
            if real_url:
                print(f"   âœ… å·²è·å–çœŸå®ä¸‹è½½åœ°å€ï¼Œä½¿ç”¨Chromeç›´æ¥ä¸‹è½½")
                download_url = real_url
                # ä¿å­˜çœŸå®ä¸‹è½½åœ°å€ï¼Œä¾›åç»­requestsä¸‹è½½ä½¿ç”¨
                self._last_real_download_url = real_url
            else:
                print(f"   âš ï¸  æ— æ³•è·å–çœŸå®ä¸‹è½½åœ°å€ï¼Œä½¿ç”¨åŸå§‹URLå°è¯•ä¸‹è½½")
                self._last_real_download_url = None
        
        try:
            # Chromeæœ¬åœ°è¿æ¥ä¸ä½¿ç”¨ä»£ç†ï¼ˆä¸´æ—¶å–æ¶ˆä»£ç†ç¯å¢ƒå˜é‡ï¼‰
            import os
            old_proxy_env = {}
            proxy_env_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']
            for var in proxy_env_vars:
                if var in os.environ:
                    old_proxy_env[var] = os.environ[var]
                    del os.environ[var]
            
            # è®¾ç½®NO_PROXYï¼Œæ’é™¤æœ¬åœ°åœ°å€
            old_no_proxy = os.environ.get('NO_PROXY', '')
            os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0'
            
            browser = None
            tab = None
            download_start_time = time.time()
            
            try:
                browser = pychrome.Browser(url="http://127.0.0.1:9222")
                tab = browser.new_tab()
                tab.start()
                
                # è®¾ç½®ä¸‹è½½è·¯å¾„åˆ°ç›®æ ‡æ–‡ä»¶å¤¹
                download_dir = str(save_path.parent.absolute())  # ä½¿ç”¨ç»å¯¹è·¯å¾„
                print(f"   ğŸ“ ç›®æ ‡ä¸‹è½½ç›®å½•: {download_dir}")
                print(f"   ğŸ“ ç›®æ ‡æ–‡ä»¶è·¯å¾„: {save_path.absolute()}")
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                save_path.parent.mkdir(parents=True, exist_ok=True)
                
                try:
                    tab.Browser.setDownloadBehavior(
                        behavior="allow",
                        downloadPath=download_dir
                    )
                    print(f"   âœ… å·²è®¾ç½®Chromeä¸‹è½½è·¯å¾„: {download_dir}")
                except AttributeError:
                    # å¦‚æœBrowseråŸŸä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨PageåŸŸ
                    try:
                        tab.Page.setDownloadBehavior(
                            behavior="allow",
                            downloadPath=download_dir
                        )
                        print(f"   âœ… å·²è®¾ç½®Chromeä¸‹è½½è·¯å¾„: {download_dir}")
                    except Exception as e:
                        print(f"   âš ï¸  æ— æ³•è®¾ç½®ä¸‹è½½è·¯å¾„: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤ä¸‹è½½ç›®å½•")
                        print(f"   ğŸ’¡ æç¤º: Chromeå¯èƒ½ä¸‹è½½åˆ°é»˜è®¤ç›®å½•: {Path.home() / 'Downloads'}")
                
                # ç›‘å¬ä¸‹è½½äº‹ä»¶
                download_completed = False
                download_guid = None
                downloaded_file_path = None
                
                # è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥æ˜¯å¦å­˜åœ¨.crdownloadæ–‡ä»¶
                def has_crdownload_files() -> Tuple[bool, List[Path]]:
                    """æ£€æŸ¥æŒ‡å®šç›®å½•å’Œé»˜è®¤ä¸‹è½½ç›®å½•ä¸­æ˜¯å¦å­˜åœ¨.crdownloadæ–‡ä»¶
                    Returns:
                        (has_crdownload, crdownload_files_list)
                    """
                    crdownload_files = []
                    # æ£€æŸ¥æŒ‡å®šç›®å½•
                    if save_path.parent.exists():
                        files = list(save_path.parent.glob('*.crdownload'))
                        if files:
                            crdownload_files.extend(files)
                            return True, crdownload_files
                    # æ£€æŸ¥é»˜è®¤ä¸‹è½½ç›®å½•
                    default_download_dir = Path.home() / 'Downloads'
                    if default_download_dir.exists():
                        files = list(default_download_dir.glob('*.crdownload'))
                        if files:
                            crdownload_files.extend(files)
                            return True, crdownload_files
                    return False, []
                
                # è¾…åŠ©å‡½æ•°ï¼šåˆ¤æ–­ä¸‹è½½æ˜¯å¦å®Œæˆï¼ˆåŸºäºæ–‡ä»¶å¤§å°å’Œ.crdownloadæ–‡ä»¶ï¼‰
                def check_download_complete(file_path: Path, expected_size_bytes: int = 0) -> bool:
                    """æ£€æŸ¥ä¸‹è½½æ˜¯å¦å®Œæˆ
                    Args:
                        file_path: ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„ï¼ˆå¯èƒ½æ˜¯.apkæˆ–.crdownloadï¼‰
                        expected_size_bytes: é¢„æœŸæ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰ï¼Œ0è¡¨ç¤ºä¸æ£€æŸ¥å¤§å°
                    Returns:
                        bool: æ˜¯å¦å®Œæˆ
                    """
                    if not file_path or not file_path.exists():
                        return False
                    
                    # å¦‚æœæŒ‡å®šäº†é¢„æœŸå¤§å°ï¼Œæ£€æŸ¥æ–‡ä»¶å¤§å°
                    if expected_size_bytes > 0:
                        current_size = file_path.stat().st_size
                        if current_size < expected_size_bytes:
                            return False
                    
                    # å…³é”®ï¼šæ‰«æç›®å½•ä¸­æ˜¯å¦è¿˜æœ‰.crdownloadæ–‡ä»¶ï¼ˆè€Œä¸æ˜¯åªæ£€æŸ¥ä¼ å…¥çš„file_pathï¼‰
                    # å› ä¸ºChromeå¯èƒ½å·²ç»å°†file_pathä».crdownloadé‡å‘½åä¸º.apk
                    # ä½†å¦‚æœè¿˜æœ‰å…¶ä»–.crdownloadæ–‡ä»¶å­˜åœ¨ï¼Œè¯´æ˜ä¸‹è½½å¯èƒ½è¿˜åœ¨è¿›è¡Œä¸­
                    has_crdownload, crdownload_files = has_crdownload_files()
                    
                    # å¦‚æœè¿˜æœ‰.crdownloadæ–‡ä»¶ï¼Œæ£€æŸ¥æ˜¯å¦ä¸å½“å‰æ–‡ä»¶ç›¸å…³ï¼ˆå¯èƒ½æ˜¯åŒä¸€ä¸ªæ–‡ä»¶çš„ä¸åŒé˜¶æ®µï¼‰
                    if has_crdownload:
                        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸file_pathç›¸å…³çš„.crdownloadæ–‡ä»¶ï¼ˆç›¸åŒæ–‡ä»¶åä½†åç¼€ä¸åŒï¼‰
                        file_stem = file_path.stem  # æ–‡ä»¶åï¼ˆä¸å«åç¼€ï¼‰
                        file_dir = file_path.parent
                        
                        # åœ¨å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•æŸ¥æ‰¾ç›¸å…³çš„.crdownloadæ–‡ä»¶
                        related_crdownload = file_dir / f"{file_stem}.crdownload"
                        if related_crdownload.exists():
                            # å¦‚æœæ‰¾åˆ°ç›¸å…³çš„.crdownloadæ–‡ä»¶ï¼Œè¯´æ˜å½“å‰æ–‡ä»¶å¯èƒ½è¿˜åœ¨ä¸‹è½½ä¸­
                            return False
                        
                        # æ£€æŸ¥é»˜è®¤ä¸‹è½½ç›®å½•
                        default_download_dir = Path.home() / 'Downloads'
                        if default_download_dir.exists():
                            related_crdownload = default_download_dir / f"{file_stem}.crdownload"
                            if related_crdownload.exists():
                                return False
                    
                    # æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„.crdownloadæ–‡ä»¶ï¼Œä¸”æ–‡ä»¶å¤§å°æ»¡è¶³è¦æ±‚ï¼Œè®¤ä¸ºä¸‹è½½å®Œæˆ
                    return True
                
                def on_download_will_begin(**kwargs):
                    nonlocal download_guid
                    download_guid = kwargs.get('guid', None)
                    suggested_filename = kwargs.get('suggestedFilename', '')
                    print(f"   ğŸ“¥ Chromeå¼€å§‹ä¸‹è½½: {suggested_filename or 'æ–‡ä»¶'}...")
                
                progress_event_available = False  # æ ‡è®°æ˜¯å¦æ”¶åˆ°è¿‡è¿›åº¦äº‹ä»¶
                last_progress_percent = 0.0  # è®°å½•æœ€åä¸€æ¬¡è¿›åº¦ç™¾åˆ†æ¯”
                last_progress_check_time = 0.0  # è®°å½•æœ€åä¸€æ¬¡æ£€æŸ¥è¿›åº¦çš„æ—¶é—´
                
                def on_download_progress(**kwargs):
                    """ä¸‹è½½è¿›åº¦äº‹ä»¶ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
                    nonlocal download_completed, downloaded_file_path, download_guid, progress_event_available, last_progress_time, last_progress_percent, last_progress_check_time
                    try:
                        # å…¼å®¹BrowseråŸŸå’ŒPageåŸŸçš„ä¸‹è½½è¿›åº¦äº‹ä»¶ï¼ˆä¸åŒç‰ˆæœ¬çš„APIå¯èƒ½ä½¿ç”¨ä¸åŒçš„å­—æ®µåï¼‰
                        guid = kwargs.get('guid', '') or kwargs.get('downloadId', '')
                        state = kwargs.get('state', '') or kwargs.get('status', '')
                        received_bytes = kwargs.get('receivedBytes', 0) or kwargs.get('bytesReceived', 0)
                        # ä¿®å¤ï¼šæ­£ç¡®è·å–totalBytesï¼ˆå¯èƒ½å­—æ®µåä¸åŒï¼Œæˆ–è€…ä¸å­˜åœ¨ï¼‰
                        total_bytes_from_event = kwargs.get('totalBytes', 0) or kwargs.get('totalSize', 0)
                        
                        # åªå¤„ç†å½“å‰ä¸‹è½½çš„äº‹ä»¶ï¼ˆå¦‚æœguidåŒ¹é…ï¼Œæˆ–è€…æ²¡æœ‰guidåˆ™å¤„ç†æ‰€æœ‰äº‹ä»¶ï¼‰
                        if not download_guid or guid == download_guid or guid == str(download_guid):
                            progress_event_available = True  # æ ‡è®°å·²æ”¶åˆ°è¿›åº¦äº‹ä»¶
                            
                            # æ›´æ–°æœ€åæ”¶åˆ°è¿›åº¦çš„æ—¶é—´ï¼ˆç”¨äºåŠ¨æ€å»¶é•¿è¶…æ—¶æ—¶é—´ï¼‰
                            last_progress_time = time.time()
                            last_progress_check_time = time.time()
                            
                            # å¦‚æœäº‹ä»¶ä¸­æ²¡æœ‰æä¾›totalBytesï¼Œä½¿ç”¨expected_size_mbä½œä¸ºå¤‡é€‰
                            if total_bytes_from_event == 0 and expected_size_mb > 0:
                                total_bytes = int(expected_size_mb * 1024 * 1024)
                                # åªåœ¨ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶æ‰“å°è°ƒè¯•ä¿¡æ¯
                                if not hasattr(on_download_progress, '_debug_printed'):
                                    print(f"\n   ğŸ’¡ äº‹ä»¶ä¸­æœªæä¾›totalBytesï¼Œä½¿ç”¨é¢„æœŸå¤§å°: {expected_size_mb:.2f}MB", flush=True)
                                    on_download_progress._debug_printed = True
                            else:
                                total_bytes = total_bytes_from_event
                            
                            # æ˜¾ç¤ºä¸‹è½½è¿›åº¦ï¼ˆä¼˜å…ˆä½¿ç”¨äº‹ä»¶çš„è¿›åº¦ä¿¡æ¯ï¼‰
                            # ä½¿ç”¨sys.stderrç¡®ä¿è¿›åº¦æ˜¾ç¤ºä¸ä¼šè¢«å…¶ä»–è¾“å‡ºå¹²æ‰°
                            if total_bytes > 0:
                                progress = min((received_bytes / total_bytes) * 100, 100.0)  # é™åˆ¶æœ€å¤§100%
                                # æ›´æ–°æœ€åè¿›åº¦ç™¾åˆ†æ¯”å’Œæ—¶é—´
                                last_progress_percent = progress
                                last_progress_check_time = time.time()
                                sys.stderr.write(f"\r   ä¸‹è½½è¿›åº¦:1 {progress:.1f}% ({received_bytes / 1024 / 1024:.2f}MB / {total_bytes / 1024 / 1024:.2f}MB)")
                                sys.stderr.flush()
                                
                                # Debug: è¿›åº¦100%æ—¶æ‰“å°
                                if progress >= 99.9 and not hasattr(on_download_progress, '_debug_100_printed'):
                                    print(f"\n   ğŸ” [DEBUG] äº‹ä»¶å›è°ƒï¼šæ”¶åˆ°è¿›åº¦100%äº‹ä»¶ï¼ˆæ—¶é—´: {time.strftime('%H:%M:%S')}ï¼‰")
                                    on_download_progress._debug_100_printed = True
                                
                                # å¦‚æœè¿›åº¦è¾¾åˆ°100%ï¼Œæ£€æŸ¥æ˜¯å¦è¿˜æœ‰.crdownloadæ–‡ä»¶
                                # Chromeä¸‹è½½å®Œæˆåä¼šè‡ªåŠ¨å°†.crdownloadæ–‡ä»¶é‡å‘½åä¸ºçœŸå®æ–‡ä»¶æ‰©å±•å
                                # å¦‚æœæ²¡æœ‰.crdownloadæ–‡ä»¶ï¼Œè¯´æ˜Chromeå·²ç»å®Œæˆé‡å‘½åï¼Œä¸‹è½½å®Œæˆ
                                if progress >= 99.9:
                                    # ä½¿ç”¨ä¸€ä¸ªæ ‡è®°æ¥è®°å½•æ˜¯å¦å·²ç»æ£€æŸ¥è¿‡100%è¿›åº¦
                                    if not hasattr(on_download_progress, '_checked_100_percent'):
                                        on_download_progress._checked_100_percent = True
                                        on_download_progress._100_percent_time = time.time()
                                        print(f"\n   ğŸ” [DEBUG] è¿›åº¦è¾¾åˆ°100%ï¼Œå¼€å§‹æ£€æŸ¥å®ŒæˆçŠ¶æ€ï¼ˆæ—¶é—´: {time.strftime('%H:%M:%S')}ï¼‰")
                                    
                                    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿Chromeå®Œæˆæ–‡ä»¶å†™å…¥å’Œé‡å‘½å
                                    time_since_100 = time.time() - on_download_progress._100_percent_time
                                    if time_since_100 >= 2:  # ç­‰å¾…2ç§’åå¼€å§‹æ£€æŸ¥
                                        print(f"   ğŸ” [DEBUG] è¿›åº¦100%åå·²ç­‰å¾…{time_since_100:.1f}ç§’ï¼Œå¼€å§‹æ£€æŸ¥.crdownloadæ–‡ä»¶...")
                                        nonlocal download_completed
                                        has_crdownload, crdownload_files = has_crdownload_files()
                                        
                                        if has_crdownload:
                                            print(f"   ğŸ” [DEBUG] æ‰¾åˆ°.crdownloadæ–‡ä»¶: {[f.name for f in crdownload_files]}")
                                        else:
                                            print(f"   ğŸ” [DEBUG] æ— .crdownloadæ–‡ä»¶")
                                        
                                        # å¦‚æœæ²¡æœ‰.crdownloadæ–‡ä»¶ï¼Œè¯´æ˜Chromeå·²ç»å®Œæˆé‡å‘½åï¼Œä¸‹è½½å®Œæˆ
                                        if not has_crdownload:
                                            download_completed = True
                                            print(f"   ğŸ” [DEBUG] è®¾ç½®download_completed = Trueï¼ˆæ— .crdownloadæ–‡ä»¶ï¼‰")
                                            sys.stderr.write(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆè¿›åº¦100%ä¸”æ— .crdownloadæ–‡ä»¶ï¼Œå·²é‡å‘½åå®Œæˆï¼‰\n")
                                            sys.stderr.flush()
                                        # å¦‚æœè¿˜æœ‰.crdownloadæ–‡ä»¶ï¼Œä½†å·²ç»ç­‰å¾…è¶…è¿‡10ç§’ï¼Œä¹Ÿè®¤ä¸ºå®Œæˆï¼ˆå¯èƒ½Chromeé‡å‘½åæœ‰é—®é¢˜ï¼‰
                                        elif time_since_100 > 10:
                                            download_completed = True
                                            print(f"   ğŸ” [DEBUG] è®¾ç½®download_completed = Trueï¼ˆå·²ç­‰å¾…{int(time_since_100)}ç§’ï¼Œè¶…æ—¶ï¼‰")
                                            sys.stderr.write(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆè¿›åº¦100%ä¸”å·²ç­‰å¾…{int(time_since_100)}ç§’ï¼Œå¯èƒ½é‡å‘½åå»¶è¿Ÿï¼‰\n")
                                            sys.stderr.flush()
                                        else:
                                            print(f"   ğŸ” [DEBUG] ä»æœ‰.crdownloadæ–‡ä»¶ï¼Œç»§ç»­ç­‰å¾…ï¼ˆå·²ç­‰å¾…{time_since_100:.1f}ç§’ï¼‰")
                                    else:
                                        if not hasattr(on_download_progress, '_debug_printed_100'):
                                            print(f"   ğŸ” [DEBUG] è¿›åº¦100%ï¼Œç­‰å¾…2ç§’åæ£€æŸ¥ï¼ˆå½“å‰ç­‰å¾…{time_since_100:.1f}ç§’ï¼‰")
                                            on_download_progress._debug_printed_100 = True
                            elif received_bytes > 0:
                                # å¦‚æœåªæœ‰received_bytesï¼Œæ²¡æœ‰total_bytesï¼Œåªæ˜¾ç¤ºå·²ä¸‹è½½å¤§å°
                                sys.stderr.write(f"\r   ä¸‹è½½è¿›åº¦:1 ä¸‹è½½ä¸­... å·²ä¸‹è½½: {received_bytes / 1024 / 1024:.2f}MB")
                                sys.stderr.flush()
                            
                            # ã€å…³é”®ä¿®æ”¹ã€‘æ— è®ºè¿›åº¦å¤šå°‘ï¼Œåªè¦.crdownloadæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°±å®Œæˆä¸‹è½½
                            # å› ä¸ºç½‘é¡µè¯¦æƒ…ä¸­çš„APKå¤§å°å¯èƒ½ä¸å‡†ç¡®ï¼Œæ‰€ä»¥ä¸ä¾èµ–è¿›åº¦100%
                            has_crdownload, crdownload_files = has_crdownload_files()
                            if not has_crdownload:
                                # æ²¡æœ‰.crdownloadæ–‡ä»¶ï¼Œè¯´æ˜Chromeå·²ç»å®Œæˆé‡å‘½åï¼Œä¸‹è½½å®Œæˆ
                                download_completed = True
                                sys.stderr.write(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆ.crdownloadæ–‡ä»¶å·²æ¶ˆå¤±ï¼Œå·²ä¸‹è½½: {received_bytes / 1024 / 1024:.2f}MBï¼‰\n")
                                sys.stderr.flush()
                            
                            # ä¸‹è½½å®Œæˆï¼ˆå…¼å®¹ä¸åŒçš„çŠ¶æ€å€¼ï¼‰
                            # è¿™æ˜¯æœ€å¯é çš„åˆ¤æ–­æ–¹å¼ï¼Œä¼˜å…ˆä½¿ç”¨
                            # æ³¨æ„ï¼šå³ä½¿æ”¶åˆ°completedçŠ¶æ€ï¼Œä¹Ÿè¦éªŒè¯.crdownloadæ–‡ä»¶æ˜¯å¦å·²æ¶ˆå¤±
                            if state in ['completed', 'finished', 'success']:
                                print(f"\n   ğŸ” [DEBUG] äº‹ä»¶å›è°ƒï¼šæ”¶åˆ°å®ŒæˆçŠ¶æ€ '{state}'ï¼ˆæ—¶é—´: {time.strftime('%H:%M:%S')}ï¼‰")
                                # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿Chromeå®Œæˆæ–‡ä»¶é‡å‘½åï¼ˆä».crdownloadåˆ°.apkï¼‰
                                time.sleep(1)
                                
                                # éªŒè¯æ˜¯å¦è¿˜æœ‰.crdownloadæ–‡ä»¶å­˜åœ¨
                                has_crdownload, _ = has_crdownload_files()
                                
                                # åªæœ‰åœ¨æ²¡æœ‰.crdownloadæ–‡ä»¶æ—¶ï¼Œæ‰è®¤ä¸ºä¸‹è½½çœŸæ­£å®Œæˆ
                                if not has_crdownload:
                                    download_completed = True
                                    sys.stderr.write(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆé€šè¿‡äº‹ä»¶ï¼ŒçŠ¶æ€: {state}ï¼‰\n")
                                    sys.stderr.flush()
                                else:
                                    # è¿˜æœ‰.crdownloadæ–‡ä»¶ï¼Œè¯´æ˜ä¸‹è½½å¯èƒ½è¿˜åœ¨è¿›è¡Œä¸­ï¼Œç»§ç»­ç­‰å¾…
                                    sys.stderr.write(f"\n   â³ Chromeäº‹ä»¶æ˜¾ç¤ºå®Œæˆï¼Œä½†æ£€æµ‹åˆ°.crdownloadæ–‡ä»¶ä»å­˜åœ¨ï¼Œç»§ç»­ç­‰å¾…...\n")
                                    sys.stderr.flush()
                    except Exception as e:
                        # å¿½ç•¥äº‹ä»¶å¤„ç†ä¸­çš„å¼‚å¸¸ï¼Œé¿å…å½±å“ä¸‹è½½
                        pass
                
                tab.Page.downloadWillBegin = on_download_will_begin
                # å°è¯•ç›‘å¬ä¸‹è½½è¿›åº¦ï¼ˆBrowseråŸŸå¯èƒ½ä¸å¯ç”¨ï¼Œä½¿ç”¨PageåŸŸä½œä¸ºå¤‡é€‰ï¼‰
                try:
                    # å°è¯•ä½¿ç”¨BrowseråŸŸç›‘å¬ä¸‹è½½è¿›åº¦
                    if hasattr(tab, 'Browser') and hasattr(tab.Browser, 'downloadProgress'):
                        tab.Browser.downloadProgress = on_download_progress
                        print(f"   âœ… å·²å¯ç”¨BrowseråŸŸä¸‹è½½è¿›åº¦ç›‘å¬")
                    elif hasattr(tab, 'Page') and hasattr(tab.Page, 'downloadProgress'):
                        # ä½¿ç”¨PageåŸŸç›‘å¬ä¸‹è½½è¿›åº¦ï¼ˆå¦‚æœBrowseråŸŸä¸å¯ç”¨ï¼‰
                        tab.Page.downloadProgress = on_download_progress
                        print(f"   âœ… å·²å¯ç”¨PageåŸŸä¸‹è½½è¿›åº¦ç›‘å¬")
                    else:
                        print(f"   âš ï¸  æ— æ³•å¯ç”¨ä¸‹è½½è¿›åº¦ç›‘å¬ï¼Œå°†åªæ˜¾ç¤ºä¸‹è½½å¼€å§‹å’Œå®ŒæˆçŠ¶æ€")
                except Exception as e:
                    # å¦‚æœå¯ç”¨å¤±è´¥ï¼Œåªè®°å½•è­¦å‘Šï¼Œä¸å½±å“ä¸‹è½½
                    print(f"   âš ï¸  å¯ç”¨ä¸‹è½½è¿›åº¦ç›‘å¬å¤±è´¥: {e}ï¼Œå°†åªæ˜¾ç¤ºä¸‹è½½å¼€å§‹å’Œå®ŒæˆçŠ¶æ€")
                tab.Page.enable()
                
                # ç¡®ä¿Chromeä¸ä½¿ç”¨ä»£ç†ï¼ˆé€šè¿‡NetworkåŸŸè®¾ç½®ï¼‰
                try:
                    if hasattr(tab, 'Network'):
                        tab.Network.enable()
                        # æ³¨æ„ï¼šChrome DevTools Protocolæ— æ³•ç›´æ¥ç¦ç”¨ä»£ç†
                        # ä½†æˆ‘ä»¬å·²ç»å–æ¶ˆäº†ä»£ç†ç¯å¢ƒå˜é‡ï¼ŒChromeåº”è¯¥ä¸ä¼šä½¿ç”¨ä»£ç†
                        # å¦‚æœChromeå¯åŠ¨æ—¶ä½¿ç”¨äº†--proxy-serverå‚æ•°ï¼Œä»ä¼šä½¿ç”¨ä»£ç†
                        # å»ºè®®å¯åŠ¨Chromeæ—¶ä½¿ç”¨: --no-proxy-server å‚æ•°
                except Exception as e:
                    pass
                
                print(f"   ğŸŒ ä½¿ç”¨Chromeç›´æ¥ä¸‹è½½ï¼ˆä¸ä½¿ç”¨ä»£ç†ï¼Œç›´è¿ï¼‰...")
                print(f"   ğŸ’¡ æç¤º: å¦‚æœChromeä»ä½¿ç”¨ä»£ç†ï¼Œè¯·åœ¨å¯åŠ¨Chromeæ—¶æ·»åŠ  --no-proxy-server å‚æ•°")
                tab.Page.navigate(url=download_url)
                
                # ç­‰å¾…ä¸‹è½½äº‹ä»¶è§¦å‘ï¼ˆæœ€å¤š30ç§’ï¼‰
                wait_count = 0
                while wait_count < 60 and not download_guid:
                    time.sleep(0.5)
                    wait_count += 1
                
                if not download_guid:
                    print(f"   âš ï¸  æœªæ£€æµ‹åˆ°ä¸‹è½½äº‹ä»¶ï¼ŒChromeä¸‹è½½å¯èƒ½å¤±è´¥")
                    return False
                
                # ç­‰å¾…ä¸‹è½½å®Œæˆï¼ˆåŠ¨æ€è¶…æ—¶æ—¶é—´ï¼‰
                # ä¼˜å…ˆä½¿ç”¨downloadProgressäº‹ä»¶åˆ¤æ–­å®Œæˆï¼Œæ–‡ä»¶å¤§å°ç›‘æ§ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
                # åŸºç¡€è¶…æ—¶æ—¶é—´ï¼š10åˆ†é’Ÿ
                base_timeout = 600
                # å¦‚æœæ£€æµ‹åˆ°è¿›åº¦æ›´æ–°ï¼ŒåŠ¨æ€å»¶é•¿è¶…æ—¶æ—¶é—´
                # æ ¹æ®æ–‡ä»¶å¤§å°ä¼°ç®—ï¼šå‡è®¾æœ€å°ä¸‹è½½é€Ÿåº¦0.1MB/s
                if expected_size_mb > 0:
                    # ä¼°ç®—ä¸‹è½½æ—¶é—´ï¼ˆç§’ï¼‰ï¼šæ–‡ä»¶å¤§å°(MB) / æœ€å°é€Ÿåº¦(0.1MB/s) * 1.5å€å®‰å…¨ç³»æ•°
                    estimated_time = (expected_size_mb / 0.1) * 1.5
                    # è‡³å°‘30åˆ†é’Ÿï¼Œæœ€å¤š2å°æ—¶
                    max_wait_time = max(base_timeout, min(int(estimated_time), 7200))
                else:
                    # å¦‚æœæ²¡æœ‰é¢„æœŸå¤§å°ï¼Œä½¿ç”¨è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´ï¼ˆ30åˆ†é’Ÿï¼‰
                    max_wait_time = 1800
                
                wait_count = 0
                last_file_size = 0
                last_progress_time = time.time()  # è®°å½•æœ€åä¸€æ¬¡æ”¶åˆ°è¿›åº¦æ›´æ–°çš„æ—¶é—´
                check_interval = 2  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡æ–‡ä»¶å¤§å°
                last_check_time = time.time()
                stable_size_count = 0  # è®°å½•æ–‡ä»¶å¤§å°ç¨³å®šçš„æ¬¡æ•°ï¼ˆè¿ç»­5æ¬¡æ£€æŸ¥å¤§å°ç›¸åŒï¼Œå³10ç§’ï¼‰
                
                while wait_count < max_wait_time and not download_completed:
                    # çŸ­æš‚ä¼‘çœ ï¼Œè®©äº‹ä»¶å›è°ƒæœ‰æœºä¼šæ‰§è¡Œ
                    # å¦‚æœChromeçš„downloadProgressäº‹ä»¶å¯ç”¨ï¼Œä¸»å¾ªç¯ä¸»è¦ç­‰å¾…äº‹ä»¶å›è°ƒ
                    time.sleep(0.5)
                    wait_count += 1
                    
                    # æ¯10ç§’æ‰“å°ä¸€æ¬¡debugä¿¡æ¯ï¼ˆå¦‚æœè¿›åº¦100%ï¼‰
                    if wait_count % 20 == 0 and progress_event_available and last_progress_percent >= 99.9:
                        time_since_last_progress = time.time() - last_progress_check_time
                        print(f"\n   ğŸ” [DEBUG] ä¸»å¾ªç¯ï¼šç­‰å¾…{wait_count * 0.5:.0f}ç§’ï¼Œè¿›åº¦100%ï¼Œæœ€åè¿›åº¦æ›´æ–°{time_since_last_progress:.1f}ç§’å‰ï¼Œdownload_completed={download_completed}")
                    
                    # ã€å…³é”®ä¿®æ”¹ã€‘æ— è®ºè¿›åº¦å¤šå°‘ï¼Œåªè¦.crdownloadæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°±å®Œæˆä¸‹è½½
                    # æ¯æ¬¡å¾ªç¯éƒ½æ£€æŸ¥ï¼Œä¸ç­‰å¾…è¿›åº¦100%
                    has_crdownload, crdownload_files = has_crdownload_files()
                    if not has_crdownload:
                        # æ²¡æœ‰.crdownloadæ–‡ä»¶ï¼Œè¯´æ˜Chromeå·²ç»å®Œæˆé‡å‘½åï¼Œä¸‹è½½å®Œæˆ
                        download_completed = True
                        if progress_event_available:
                            print(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆ.crdownloadæ–‡ä»¶å·²æ¶ˆå¤±ï¼Œä¸»å¾ªç¯æ£€æŸ¥ï¼Œè¿›åº¦: {last_progress_percent:.1f}%ï¼‰")
                        else:
                            print(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆ.crdownloadæ–‡ä»¶å·²æ¶ˆå¤±ï¼Œä¸»å¾ªç¯æ£€æŸ¥ï¼‰")
                        break
                    
                    # å¦‚æœè¿›åº¦äº‹ä»¶å¯ç”¨ä¸”æœ€åè¿›åº¦æ˜¯100%ï¼Œæ£€æŸ¥æ˜¯å¦å®Œæˆ
                    # è¿™å¯ä»¥å¤„ç†è¿›åº¦100%åäº‹ä»¶å›è°ƒä¸å†è§¦å‘çš„æƒ…å†µ
                    if progress_event_available and last_progress_percent >= 99.9:
                        # å¦‚æœæœ€åè¿›åº¦æ˜¯100%ä¸”å·²ç»ç­‰å¾…è¶…è¿‡2ç§’ï¼Œæ£€æŸ¥.crdownloadæ–‡ä»¶
                        time_since_last_progress = time.time() - last_progress_check_time
                        if time_since_last_progress >= 2:
                            # åªåœ¨ç¬¬ä¸€æ¬¡æ£€æŸ¥æ—¶æ‰“å°debug
                            if not hasattr(on_download_progress, '_main_loop_checked'):
                                print(f"\n   ğŸ” [DEBUG] ä¸»å¾ªç¯æ£€æŸ¥ï¼šè¿›åº¦100%ï¼Œæœ€åè¿›åº¦æ›´æ–°{time_since_last_progress:.1f}ç§’å‰")
                                on_download_progress._main_loop_checked = True
                            
                            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰.crdownloadæ–‡ä»¶ï¼ˆè™½ç„¶ä¸Šé¢å·²ç»æ£€æŸ¥è¿‡ï¼Œä½†è¿™é‡Œå†æ¬¡ç¡®è®¤ï¼‰
                            if has_crdownload and wait_count % 20 == 0:  # æ¯10ç§’æ‰“å°ä¸€æ¬¡
                                print(f"   ğŸ” [DEBUG] ä¸»å¾ªç¯ï¼šæ‰¾åˆ°.crdownloadæ–‡ä»¶: {[f.name for f in crdownload_files]}")
                            
                            # å¦‚æœè¿˜æœ‰.crdownloadæ–‡ä»¶ä½†å·²ç­‰å¾…è¶…è¿‡10ç§’ï¼Œä¹Ÿè®¤ä¸ºå®Œæˆ
                            if time_since_last_progress > 10:
                                download_completed = True
                                print(f"\n   ğŸ” [DEBUG] ä¸»å¾ªç¯ï¼šè®¾ç½®download_completed = Trueï¼ˆå·²ç­‰å¾…{int(time_since_last_progress)}ç§’ï¼Œè¶…æ—¶ï¼‰")
                                print(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆè¿›åº¦100%ä¸”å·²ç­‰å¾…{int(time_since_last_progress)}ç§’ï¼Œä¸»å¾ªç¯æ£€æŸ¥ï¼‰")
                                break
                    
                    # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡æ–‡ä»¶å¤§å°ï¼Œæ˜¾ç¤ºä¸‹è½½è¿›åº¦ï¼ˆä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼‰
                    # å¦‚æœChromeçš„downloadProgressäº‹ä»¶å¯ç”¨ï¼Œå‡å°‘æ–‡ä»¶å¤§å°æ£€æŸ¥çš„é¢‘ç‡
                    current_time = time.time()
                    check_file_size = (current_time - last_check_time >= check_interval)
                    # å¦‚æœäº‹ä»¶å¯ç”¨ï¼Œå»¶é•¿æ£€æŸ¥é—´éš”åˆ°5ç§’ï¼ˆå‡å°‘å¹²æ‰°ï¼‰
                    if progress_event_available:
                        check_file_size = (current_time - last_check_time >= 5.0)
                    
                    if check_file_size:
                        # ä¼˜å…ˆæ£€æŸ¥æŒ‡å®šä¸‹è½½ç›®å½•ï¼ˆsave_path.parentï¼‰ä¸­çš„æ–‡ä»¶
                        # è¿™æ˜¯Chromeåº”è¯¥ä¸‹è½½åˆ°çš„ç›®å½•
                        downloaded_file = None
                        crdownload_file = None
                        
                        # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å°æŸ¥æ‰¾çš„ç›®å½•
                        if wait_count == 1:  # åªåœ¨ç¬¬ä¸€æ¬¡æ£€æŸ¥æ—¶æ‰“å°
                            print(f"\n   ğŸ” å¼€å§‹ç›‘å¬æ–‡ä»¶ä¸‹è½½è¿›åº¦...")
                            print(f"   ğŸ“ æŒ‡å®šä¸‹è½½ç›®å½•: {save_path.parent.absolute()}")
                            print(f"   ğŸ“ ç›®å½•æ˜¯å¦å­˜åœ¨: {save_path.parent.exists()}")
                            if save_path.parent.exists():
                                all_files = list(save_path.parent.iterdir())
                                print(f"   ğŸ“„ ç›®å½•ä¸­çš„æ–‡ä»¶: {[f.name for f in all_files]}")
                        
                        # 1. é¦–å…ˆæ£€æŸ¥æŒ‡å®šç›®å½•ä¸­çš„.crdownloadæ–‡ä»¶ï¼ˆä¸‹è½½è¿›è¡Œä¸­ï¼‰
                        if save_path.parent.exists():
                            crdownload_files = list(save_path.parent.glob('*.crdownload'))
                            if crdownload_files:
                                crdownload_files.sort(key=lambda p: p.stat().st_mtime, reverse=True)
                                crdownload_file = crdownload_files[0]
                                if crdownload_file and crdownload_file.exists():
                                    downloaded_file = crdownload_file
                                    if wait_count == 1:
                                        print(f"   âœ… æ‰¾åˆ°ä¸´æ—¶æ–‡ä»¶: {crdownload_file.name}")
                        
                        # 2. å¦‚æœæŒ‡å®šç›®å½•æ²¡æœ‰.crdownloadæ–‡ä»¶ï¼Œæ£€æŸ¥æŒ‡å®šç›®å½•ä¸­çš„.apkæ–‡ä»¶ï¼ˆä¸‹è½½å®Œæˆï¼‰
                        if not downloaded_file and save_path.parent.exists():
                            apk_files = list(save_path.parent.glob('*.apk'))
                            if apk_files:
                                apk_files.sort(key=lambda p: p.stat().st_mtime, reverse=True)
                                # åªé€‰æ‹©æœ€è¿‘ä¿®æ”¹çš„.apkæ–‡ä»¶ï¼Œä¸”ä¿®æ”¹æ—¶é—´åœ¨ä¸‹è½½å¼€å§‹ä¹‹å
                                for apk_file in apk_files:
                                    if apk_file.stat().st_mtime >= download_start_time - 10:  # å…è®¸10ç§’è¯¯å·®
                                        downloaded_file = apk_file
                                        if wait_count == 1:
                                            print(f"   âœ… æ‰¾åˆ°å·²ä¸‹è½½æ–‡ä»¶: {apk_file.name}")
                                        break
                        
                        # 3. å¦‚æœæŒ‡å®šç›®å½•éƒ½æ²¡æœ‰æ–‡ä»¶ï¼Œæ‰æ£€æŸ¥é»˜è®¤ä¸‹è½½ç›®å½•ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
                        # è¿™é€šå¸¸å‘ç”Ÿåœ¨Chromeçš„setDownloadBehavioræ²¡æœ‰ç”Ÿæ•ˆæ—¶
                        if not downloaded_file:
                            default_download_dir = Path.home() / 'Downloads'
                            if default_download_dir.exists():
                                # å…ˆæ£€æŸ¥.crdownloadæ–‡ä»¶
                                crdownload_files = list(default_download_dir.glob('*.crdownload'))
                                if crdownload_files:
                                    crdownload_files.sort(key=lambda p: p.stat().st_mtime, reverse=True)
                                    crdownload_file = crdownload_files[0]
                                    if crdownload_file and crdownload_file.exists():
                                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨ä¸‹è½½å¼€å§‹ååˆ›å»º
                                        if crdownload_file.stat().st_mtime >= download_start_time - 10:
                                            downloaded_file = crdownload_file
                                            # å¦‚æœæ–‡ä»¶åœ¨é»˜è®¤ç›®å½•ï¼Œæ‰“å°è­¦å‘Š
                                            if wait_count % 20 == 0:  # æ¯10ç§’æ‰“å°ä¸€æ¬¡ï¼ˆ20æ¬¡ * 0.5ç§’ï¼‰
                                                print(f"\n   âš ï¸  æ£€æµ‹åˆ°æ–‡ä»¶ä¸‹è½½åˆ°é»˜è®¤ç›®å½•è€ŒéæŒ‡å®šç›®å½•")
                                                print(f"   ğŸ“ é»˜è®¤ç›®å½•: {default_download_dir}")
                                                print(f"   ğŸ“ æŒ‡å®šç›®å½•: {save_path.parent.absolute()}")
                                                print(f"   ğŸ“„ ä¸´æ—¶æ–‡ä»¶: {crdownload_file.name}")
                                
                                # å¦‚æœè¿˜æ²¡æœ‰æ‰¾åˆ°ï¼Œæ£€æŸ¥.apkæ–‡ä»¶
                                if not downloaded_file:
                                    apk_files = list(default_download_dir.glob('*.apk'))
                                    if apk_files:
                                        apk_files.sort(key=lambda p: p.stat().st_mtime, reverse=True)
                                        for apk_file in apk_files:
                                            if apk_file.stat().st_mtime >= download_start_time - 10:
                                                downloaded_file = apk_file
                                                if wait_count % 20 == 0:
                                                    print(f"\n   âš ï¸  æ£€æµ‹åˆ°æ–‡ä»¶ä¸‹è½½åˆ°é»˜è®¤ç›®å½•è€ŒéæŒ‡å®šç›®å½•")
                                                    print(f"   ğŸ“ é»˜è®¤ç›®å½•: {default_download_dir}")
                                                    print(f"   ğŸ“ æŒ‡å®šç›®å½•: {save_path.parent.absolute()}")
                                                    print(f"   ğŸ“„ æ–‡ä»¶: {apk_file.name}")
                                                break
                        
                        # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œæ‰“å°è°ƒè¯•ä¿¡æ¯
                        if not downloaded_file and wait_count % 40 == 0:  # æ¯20ç§’æ‰“å°ä¸€æ¬¡
                            print(f"\n   âš ï¸  æœªæ‰¾åˆ°ä¸‹è½½æ–‡ä»¶ï¼ˆå·²ç­‰å¾… {wait_count * 0.5:.0f} ç§’ï¼‰")
                            print(f"   ğŸ“ æ£€æŸ¥çš„ç›®å½•:")
                            print(f"      - æŒ‡å®šç›®å½•: {save_path.parent.absolute()} (å­˜åœ¨: {save_path.parent.exists()})")
                            if save_path.parent.exists():
                                all_files = list(save_path.parent.iterdir())
                                print(f"        æ–‡ä»¶åˆ—è¡¨: {[f.name for f in all_files]}")
                            default_download_dir = Path.home() / 'Downloads'
                            print(f"      - é»˜è®¤ç›®å½•: {default_download_dir} (å­˜åœ¨: {default_download_dir.exists()})")
                            if default_download_dir.exists():
                                crdownload_files = list(default_download_dir.glob('*.crdownload'))
                                apk_files = list(default_download_dir.glob('*.apk'))
                                print(f"        ä¸´æ—¶æ–‡ä»¶: {[f.name for f in crdownload_files[:3]]}")
                                print(f"        APKæ–‡ä»¶: {[f.name for f in apk_files[:3]]}")
                        
                        if downloaded_file and downloaded_file.exists():
                            current_file_size = downloaded_file.stat().st_size
                            current_file_size_mb = current_file_size / 1024 / 1024
                            
                            # ã€å…³é”®ä¿®æ”¹ã€‘ä¼˜å…ˆæ£€æŸ¥ï¼šå¦‚æœ.crdownloadæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç«‹å³å®Œæˆä¸‹è½½
                            # ä¸ç®¡è¿›åº¦æ˜¯å¦100%ï¼Œåªè¦.crdownloadæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°±è®¤ä¸ºChromeå·²ç»å®Œæˆé‡å‘½åï¼Œä¸‹è½½å®Œæˆ
                            has_crdownload, crdownload_files = has_crdownload_files()
                            if not has_crdownload:
                                # æ²¡æœ‰.crdownloadæ–‡ä»¶ï¼Œè¯´æ˜Chromeå·²ç»å®Œæˆé‡å‘½åï¼Œä¸‹è½½å®Œæˆ
                                download_completed = True
                                print(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆ.crdownloadæ–‡ä»¶å·²æ¶ˆå¤±ï¼ŒChromeå·²å®Œæˆé‡å‘½åï¼Œæ–‡ä»¶å¤§å°: {current_file_size_mb:.2f}MBï¼‰")
                                break
                            
                            # åªæœ‰åœ¨æ–‡ä»¶å¤§å° > 0 æ—¶ï¼Œæ‰è¿›è¡Œè¿›åº¦æ˜¾ç¤ºå’Œå®Œæˆåˆ¤æ–­
                            # ä¸‹è½½åˆšå¼€å§‹æ—¶ï¼Œæ–‡ä»¶å¯èƒ½è¿˜ä¸å­˜åœ¨æˆ–å¤§å°ä¸º0ï¼Œè¿™æ˜¯æ­£å¸¸çŠ¶æ€
                            if current_file_size > 0:
                                # æ›´æ–°æœ€åæ”¶åˆ°è¿›åº¦çš„æ—¶é—´ï¼ˆæ–‡ä»¶å¤§å°åœ¨å¢é•¿ï¼Œè¯´æ˜ä¸‹è½½åœ¨è¿›è¡Œä¸­ï¼‰
                                if current_file_size > last_file_size:
                                    last_progress_time = time.time()
                                
                                # æ˜¾ç¤ºè¿›åº¦ï¼ˆåªæœ‰åœ¨Chromeçš„downloadProgressäº‹ä»¶ä¸å¯ç”¨æ—¶æ‰æ˜¾ç¤ºæ–‡ä»¶å¤§å°ç›‘æ§çš„è¿›åº¦ï¼‰
                                # å¦‚æœäº‹ä»¶å¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨äº‹ä»¶çš„è¿›åº¦æ˜¾ç¤ºï¼ˆåœ¨on_download_progressä¸­å¤„ç†ï¼‰
                                if not progress_event_available:
                                    # Chromeçš„downloadProgressäº‹ä»¶ä¸å¯ç”¨ï¼Œä½¿ç”¨æ–‡ä»¶å¤§å°ç›‘æ§æ˜¾ç¤ºè¿›åº¦
                                    if expected_size_mb > 0:
                                        progress = min((current_file_size_mb / expected_size_mb) * 100, 100.0)  # é™åˆ¶æœ€å¤§100%
                                        # ä½¿ç”¨sys.stderrç¡®ä¿è¿›åº¦æ˜¾ç¤ºä¸ä¼šè¢«å…¶ä»–è¾“å‡ºå¹²æ‰°
                                        sys.stderr.write(f"\r   ä¸‹è½½è¿›åº¦:2 {progress:.1f}% ({current_file_size_mb:.2f}MB / {expected_size_mb:.2f}MB)")
                                        sys.stderr.flush()
                                        
                                        # å¦‚æœè¿›åº¦è¾¾åˆ°100%ï¼Œæ£€æŸ¥Chromeæ˜¯å¦å·²å®Œæˆé‡å‘½å
                                        if progress >= 99.9:
                                            # æ£€æŸ¥å½“å‰æ–‡ä»¶æ˜¯å¦è¿˜æ˜¯.crdownloadæ–‡ä»¶
                                            is_crdownload = downloaded_file.suffix == '.crdownload' or str(downloaded_file).endswith('.crdownload')
                                            
                                            if is_crdownload:
                                                # å¦‚æœè¿˜æ˜¯.crdownloadï¼Œæ£€æŸ¥Chromeæ˜¯å¦å·²ç»å°†å…¶é‡å‘½åä¸º.apk
                                                # æŸ¥æ‰¾ç›¸åŒæ–‡ä»¶åï¼ˆä¸å«åç¼€ï¼‰çš„.apkæ–‡ä»¶
                                                file_stem = downloaded_file.stem
                                                file_dir = downloaded_file.parent
                                                
                                                # åœ¨å½“å‰ç›®å½•æŸ¥æ‰¾å¯¹åº”çš„.apkæ–‡ä»¶
                                                apk_file = file_dir / f"{file_stem}.apk"
                                                if apk_file.exists() and apk_file.stat().st_size >= current_file_size:
                                                    # Chromeå·²ç»å®Œæˆé‡å‘½åï¼Œä¸‹è½½å®Œæˆ
                                                    download_completed = True
                                                    print(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆæ–‡ä»¶å·²é‡å‘½åä¸º: {apk_file.name}ï¼Œå¤§å°: {current_file_size_mb:.2f}MBï¼‰")
                                                    break
                                                else:
                                                    # è¿˜åœ¨ç­‰å¾…Chromeé‡å‘½å
                                                    if wait_count % 20 == 0:  # æ¯10ç§’æ‰“å°ä¸€æ¬¡
                                                        print(f"\n   ğŸ” [DEBUG] ä¸‹è½½è¿›åº¦:2 è¿›åº¦100%ï¼Œç­‰å¾…Chromeé‡å‘½å.crdownloadæ–‡ä»¶...")
                                            else:
                                                # æ–‡ä»¶å·²ç»ä¸æ˜¯.crdownloadäº†ï¼Œè¯´æ˜Chromeå·²ç»å®Œæˆé‡å‘½åï¼Œä¸‹è½½å®Œæˆ
                                                download_completed = True
                                                print(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆé€šè¿‡æ–‡ä»¶å¤§å°ç›‘æ§ï¼Œæ–‡ä»¶å¤§å°: {current_file_size_mb:.2f}MB >= é¢„æœŸ: {expected_size_mb:.2f}MBï¼‰")
                                                break
                                    else:
                                        sys.stderr.write(f"\r   ä¸‹è½½è¿›åº¦:2 ä¸‹è½½ä¸­... å½“å‰å¤§å°: {current_file_size_mb:.2f}MB")
                                        sys.stderr.flush()
                                
                                # åˆ¤æ–­ä¸‹è½½æ˜¯å¦å®Œæˆï¼ˆå¦‚æœè¿›åº¦è¿˜æ²¡è¾¾åˆ°100%ï¼Œç»§ç»­æ£€æŸ¥ï¼‰
                                # æ³¨æ„ï¼šè¿›åº¦100%çš„åˆ¤æ–­å·²ç»åœ¨ä¸Šé¢å¤„ç†äº†ï¼Œè¿™é‡Œåªå¤„ç†è¿›åº¦æœªè¾¾åˆ°100%çš„æƒ…å†µ
                                if expected_size_mb > 0:
                                    # æœ‰é¢„æœŸå¤§å°ï¼Œæ£€æŸ¥æ˜¯å¦è¾¾åˆ°é¢„æœŸå¤§å°
                                    expected_size_bytes = int(expected_size_mb * 1024 * 1024)
                                    # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦è¾¾åˆ°é¢„æœŸï¼ˆå¿…é¡» >= é¢„æœŸå¤§å°ï¼Œä¸å…è®¸è¯¯å·®ï¼‰
                                    if current_file_size >= expected_size_bytes:
                                        # æ–‡ä»¶å¤§å°å·²è¾¾åˆ°é¢„æœŸï¼Œæ£€æŸ¥æ˜¯å¦å®Œæˆ
                                        if check_download_complete(downloaded_file, expected_size_bytes):
                                            # ä¸‹è½½å®Œæˆ
                                            download_completed = True
                                            print(f"\n   ğŸ” [DEBUG] ä¸‹è½½è¿›åº¦:2 æ–‡ä»¶å¤§å°è¾¾åˆ°é¢„æœŸä¸”æ— .crdownloadæ–‡ä»¶ï¼Œç›´æ¥å®Œæˆ")
                                            if progress_event_available:
                                                print(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆé€šè¿‡æ–‡ä»¶å¤§å°ç›‘æ§ï¼Œæ–‡ä»¶å¤§å°: {current_file_size_mb:.2f}MB >= é¢„æœŸ: {expected_size_mb:.2f}MBï¼‰")
                                            else:
                                                print(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆæ–‡ä»¶å¤§å°: {current_file_size_mb:.2f}MB >= é¢„æœŸ: {expected_size_mb:.2f}MBï¼‰")
                                            break
                                        else:
                                            # è¿˜æœ‰.crdownloadæ–‡ä»¶ï¼Œç»§ç»­ç­‰å¾…
                                            if wait_count % 20 == 0:  # æ¯10ç§’æ‰“å°ä¸€æ¬¡
                                                print(f"\n   ğŸ” [DEBUG] ä¸‹è½½è¿›åº¦:2 æ–‡ä»¶å¤§å°è¾¾åˆ°é¢„æœŸï¼Œä½†ä»æœ‰.crdownloadæ–‡ä»¶ï¼Œç»§ç»­ç­‰å¾…...")
                                    else:
                                        # æ–‡ä»¶å¤§å°è¿˜æœªè¾¾åˆ°é¢„æœŸï¼Œæ›´æ–°last_file_size
                                        if current_file_size > last_file_size:
                                            last_file_size = current_file_size
                                else:
                                    # æ²¡æœ‰é¢„æœŸå¤§å°ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆï¼šæ–‡ä»¶å¤§å°è¿ç»­5æ¬¡æ£€æŸ¥ï¼ˆ10ç§’ï¼‰æ²¡æœ‰å˜åŒ–
                                    # ä¸”è‡³å°‘ç­‰å¾…äº†30ç§’ï¼Œä¸”downloadProgressäº‹ä»¶ä¸å¯ç”¨
                                    
                                    # æ£€æŸ¥æ˜¯å¦ä¸º.crdownloadæ–‡ä»¶
                                    is_crdownload = downloaded_file.suffix == '.crdownload' or str(downloaded_file).endswith('.crdownload')
                                    
                                    if current_file_size > last_file_size:
                                        # æ–‡ä»¶å¤§å°åœ¨å¢é•¿ï¼Œé‡ç½®ç¨³å®šè®¡æ•°ï¼Œæ›´æ–°last_file_size
                                        stable_size_count = 0
                                        last_file_size = current_file_size
                                    elif current_file_size == last_file_size and last_file_size > 0:
                                        # æ–‡ä»¶å¤§å°æ²¡æœ‰å˜åŒ–ï¼Œä¸”ä¹‹å‰å·²ç»æœ‰æ–‡ä»¶å¤§å°è®°å½•ï¼Œå¢åŠ ç¨³å®šè®¡æ•°
                                        stable_size_count += 1
                                        # å¦‚æœè¿ç»­5æ¬¡æ£€æŸ¥ï¼ˆ10ç§’ï¼‰å¤§å°éƒ½æ²¡æœ‰å˜åŒ–ï¼Œä¸”è‡³å°‘ç­‰å¾…äº†30ç§’ï¼Œè®¤ä¸ºä¸‹è½½å®Œæˆ
                                        # è¿™æ˜¯å¤‡é€‰æ–¹æ¡ˆï¼šå³ä½¿downloadProgressäº‹ä»¶å¯ç”¨ï¼Œå¦‚æœäº‹ä»¶æ²¡æœ‰è§¦å‘å®ŒæˆçŠ¶æ€ï¼Œä¹Ÿè¦æœ‰å¤‡é€‰åˆ¤æ–­
                                        # é‡è¦ï¼šå¿…é¡»ç¡®ä¿æ²¡æœ‰.crdownloadæ–‡ä»¶å­˜åœ¨ï¼Œæ‰è®¤ä¸ºä¸‹è½½å®Œæˆ
                                        if stable_size_count >= 5 and wait_count > 30:
                                            # å†æ¬¡æ£€æŸ¥æ˜¯å¦å®Œæˆï¼ˆç¡®ä¿æ²¡æœ‰.crdownloadæ–‡ä»¶ï¼‰
                                            if check_download_complete(downloaded_file, 0):
                                                # å¦‚æœäº‹ä»¶ä¸å¯ç”¨ï¼Œæˆ–è€…äº‹ä»¶å¯ç”¨ä½†ç­‰å¾…è¶…è¿‡60ç§’ä»æœªå®Œæˆï¼Œä½¿ç”¨æ–‡ä»¶å¤§å°ç›‘æ§åˆ¤æ–­
                                                if not progress_event_available or (progress_event_available and wait_count > 60):
                                                    download_completed = True
                                                    if progress_event_available:
                                                        print(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆé€šè¿‡æ–‡ä»¶å¤§å°ç›‘æ§å¤‡é€‰æ–¹æ¡ˆï¼Œå½“å‰å¤§å°: {current_file_size_mb:.2f}MBï¼Œä¸”å¤§å°å·²ç¨³å®š10ç§’ï¼‰")
                                                    else:
                                                        print(f"\n   âœ… Chromeä¸‹è½½å®Œæˆï¼ˆé€šè¿‡æ–‡ä»¶å¤§å°ç›‘æ§ï¼Œå½“å‰å¤§å°: {current_file_size_mb:.2f}MBï¼Œä¸”å¤§å°å·²ç¨³å®š10ç§’ï¼‰")
                                                    break
                                        elif is_crdownload:
                                            # å¦‚æœè¿˜æœ‰.crdownloadæ–‡ä»¶ï¼Œé‡ç½®ç¨³å®šè®¡æ•°ï¼Œç»§ç»­ç­‰å¾…
                                            stable_size_count = 0
                                    else:
                                        # æ–‡ä»¶å¤§å°ä¸º0æˆ–å¼‚å¸¸ï¼Œé‡ç½®ç¨³å®šè®¡æ•°ï¼Œä½†æ›´æ–°last_file_sizeï¼ˆå¦‚æœæ–‡ä»¶å¤§å° > 0ï¼‰
                                        stable_size_count = 0
                                        if current_file_size > 0:
                                            last_file_size = current_file_size
                            else:
                                # æ–‡ä»¶å¤§å°ä¸º0ï¼Œè¯´æ˜ä¸‹è½½è¿˜æ²¡å¼€å§‹æˆ–æ–‡ä»¶è¿˜ä¸å­˜åœ¨ï¼Œé‡ç½®ç¨³å®šè®¡æ•°
                                stable_size_count = 0
                                # ä¸æ›´æ–°last_file_sizeï¼Œä¿æŒä¸º0æˆ–ä¹‹å‰çš„å€¼
                        
                        last_check_time = current_time
                    
                    # å¦‚æœChromeçš„downloadProgressäº‹ä»¶å¯ç”¨ï¼Œä¸»å¾ªç¯åªéœ€è¦ç­‰å¾…äº‹ä»¶å›è°ƒè®¾ç½®download_completed
                    # ä¸éœ€è¦åšå¤ªå¤šå¤„ç†ï¼Œé¿å…é˜»å¡äº‹ä»¶å›è°ƒ
                    
                    # åŠ¨æ€å»¶é•¿è¶…æ—¶æ—¶é—´ï¼šå¦‚æœæ£€æµ‹åˆ°æœ‰è¿›åº¦æ›´æ–°ï¼Œå»¶é•¿è¶…æ—¶æ—¶é—´
                    # æ£€æŸ¥æ˜¯å¦æœ‰è¿›åº¦æ›´æ–°ï¼ˆé€šè¿‡äº‹ä»¶æˆ–æ–‡ä»¶å¤§å°å¢é•¿ï¼‰
                    time_since_last_progress = time.time() - last_progress_time
                    if time_since_last_progress < 60:  # å¦‚æœæœ€è¿‘60ç§’å†…æœ‰è¿›åº¦æ›´æ–°
                        # ä¸‹è½½åœ¨è¿›è¡Œä¸­ï¼ŒåŠ¨æ€å»¶é•¿è¶…æ—¶æ—¶é—´ï¼ˆæ¯æ¬¡å»¶é•¿5åˆ†é’Ÿï¼Œæœ€å¤šå»¶é•¿åˆ°2å°æ—¶ï¼‰
                        if wait_count >= max_wait_time - 60:  # åœ¨è¶…æ—¶å‰1åˆ†é’Ÿæ£€æŸ¥
                            old_max_wait_time = max_wait_time
                            max_wait_time = min(max_wait_time + 300, 7200)  # å»¶é•¿5åˆ†é’Ÿï¼Œæœ€å¤š2å°æ—¶
                            if max_wait_time > old_max_wait_time:
                                print(f"\n   ğŸ’¡ æ£€æµ‹åˆ°ä¸‹è½½è¿›åº¦ï¼ˆ{int(time_since_last_progress)}ç§’å‰æœ‰æ›´æ–°ï¼‰ï¼Œå»¶é•¿è¶…æ—¶æ—¶é—´è‡³ {max_wait_time // 60} åˆ†é’Ÿ", flush=True)
                
                # å¦‚æœè¶…æ—¶ä»æœªå®Œæˆï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å› ä¸ºäº‹ä»¶å›è°ƒæ²¡æœ‰è§¦å‘å®ŒæˆçŠ¶æ€
                if not download_completed and wait_count >= max_wait_time:
                    print(f"\n   âš ï¸  ä¸‹è½½è¶…æ—¶ï¼ˆç­‰å¾…{max_wait_time // 60}åˆ†é’Ÿï¼‰")
                    if progress_event_available:
                        time_since_last_progress = time.time() - last_progress_time
                        print(f"   ğŸ’¡ Chromeçš„downloadProgressäº‹ä»¶å¯ç”¨ï¼Œä½†æœªæ”¶åˆ°å®ŒæˆçŠ¶æ€")
                        print(f"   ğŸ’¡ æœ€åæ”¶åˆ°è¿›åº¦æ›´æ–°: {int(time_since_last_progress)}ç§’å‰")
                        if time_since_last_progress < 60:
                            print(f"   ğŸ’¡ ä¸‹è½½å¯èƒ½ä»åœ¨è¿›è¡Œä¸­ï¼Œå»ºè®®ç­‰å¾…æ›´é•¿æ—¶é—´æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥")
                        else:
                            print(f"   ğŸ’¡ å¯èƒ½åŸå› ï¼šä¸‹è½½å·²åœæ­¢ï¼Œæˆ–äº‹ä»¶å›è°ƒæœªæ­£ç¡®è§¦å‘")
                
                if download_completed:
                    # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ–‡ä»¶å·²å†™å…¥ç£ç›˜å¹¶å®Œæˆé‡å‘½åï¼ˆä».crdownloadåˆ°.apkï¼‰
                    time.sleep(2)
                    
                    # å†æ¬¡éªŒè¯ï¼šç¡®ä¿æ²¡æœ‰.crdownloadæ–‡ä»¶å­˜åœ¨
                    has_crdownload, crdownload_files = has_crdownload_files()
                    if has_crdownload:
                        print(f"   âš ï¸  æ£€æµ‹åˆ°.crdownloadæ–‡ä»¶ä»å­˜åœ¨: {crdownload_files[0].name}ï¼Œä¸‹è½½å¯èƒ½æœªå®Œæˆ")
                    
                    if has_crdownload:
                        # å¦‚æœè¿˜æœ‰.crdownloadæ–‡ä»¶ï¼Œè¯´æ˜ä¸‹è½½æœªå®Œæˆï¼Œè¿”å›False
                        print(f"   âŒ ä¸‹è½½æœªå®Œæˆï¼Œ.crdownloadæ–‡ä»¶ä»å­˜åœ¨")
                        return False
                    
                    # æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶ï¼ˆåªæŸ¥æ‰¾.apkæ–‡ä»¶ï¼Œä¸æŸ¥æ‰¾.crdownloadï¼‰
                    downloaded_file = None
                    try:
                        # æ£€æŸ¥ç›®æ ‡ç›®å½•ï¼ˆæŸ¥æ‰¾æ‰€æœ‰APKæ–‡ä»¶ï¼Œä¸é™åˆ¶æ–‡ä»¶åï¼‰
                        if save_path.parent.exists():
                            # æŸ¥æ‰¾æœ€è¿‘120ç§’å†…ä¿®æ”¹çš„APKæ–‡ä»¶ï¼ˆå¢åŠ æ—¶é—´çª—å£ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°æ–‡ä»¶ï¼‰
                            current_time = time.time()
                            apk_files = [
                                f for f in save_path.parent.glob('*.apk')
                                if f.exists() and (current_time - f.stat().st_mtime) < 120
                            ]
                            if apk_files:
                                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
                                apk_files.sort(key=lambda p: p.stat().st_mtime, reverse=True)
                                downloaded_file = apk_files[0]
                                print(f"   ğŸ“„ åœ¨ç›®æ ‡ç›®å½•æ‰¾åˆ°æ–‡ä»¶: {downloaded_file.name} ({downloaded_file.stat().st_size / 1024 / 1024:.2f}MB)")
                        
                        # å¦‚æœç›®æ ‡ç›®å½•æ²¡æ‰¾åˆ°ï¼Œæ£€æŸ¥Chromeé»˜è®¤ä¸‹è½½ç›®å½•
                        if not downloaded_file:
                            default_download_dir = Path.home() / 'Downloads'
                            if default_download_dir.exists():
                                current_time = time.time()
                                apk_files = [
                                    f for f in default_download_dir.glob('*.apk')
                                    if f.exists() and (current_time - f.stat().st_mtime) < 120
                                ]
                                if apk_files:
                                    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
                                    apk_files.sort(key=lambda p: p.stat().st_mtime, reverse=True)
                                    downloaded_file = apk_files[0]
                                    print(f"   ğŸ“„ åœ¨é»˜è®¤ä¸‹è½½ç›®å½•æ‰¾åˆ°æ–‡ä»¶: {downloaded_file.name} ({downloaded_file.stat().st_size / 1024 / 1024:.2f}MB)")
                        
                        # ç§»åŠ¨æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
                        if downloaded_file and downloaded_file.exists():
                            import shutil
                            if save_path.exists():
                                save_path.unlink()  # åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶
                            
                            if downloaded_file.parent == save_path.parent:
                                # å¦‚æœå·²ç»åœ¨ç›®æ ‡ç›®å½•ï¼Œç›´æ¥é‡å‘½å
                                downloaded_file.rename(save_path)
                            else:
                                # å¦åˆ™ç§»åŠ¨æ–‡ä»¶
                                shutil.move(str(downloaded_file), str(save_path))
                            
                            # éªŒè¯æ–‡ä»¶
                            file_size = save_path.stat().st_size
                            with open(save_path, 'rb') as f:
                                file_header = f.read(4)
                                if file_header[:2] == b'PK':
                                    # è®¡ç®—ä¸‹è½½è€—æ—¶
                                    download_end_time = time.time()
                                    download_duration = download_end_time - download_start_time
                                    download_minutes = int(download_duration // 60)
                                    download_seconds = int(download_duration % 60)
                                    if download_minutes > 0:
                                        print(f"   âœ… Chromeä¸‹è½½å®Œæˆ: {save_path.name} ({file_size / 1024 / 1024:.2f}MB) è€—æ—¶: {download_minutes}åˆ†{download_seconds}ç§’")
                                    else:
                                        print(f"   âœ… Chromeä¸‹è½½å®Œæˆ: {save_path.name} ({file_size / 1024 / 1024:.2f}MB) è€—æ—¶: {download_seconds}ç§’")
                                    self._create_zip_for_apk(save_path)
                                    return True
                                else:
                                    print(f"   âš ï¸  æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼Œåˆ é™¤æ–‡ä»¶")
                                    save_path.unlink()
                                    return False
                        else:
                            print(f"   âš ï¸  ä¸‹è½½å®Œæˆä½†æœªæ‰¾åˆ°æ–‡ä»¶ï¼ŒChromeä¸‹è½½å¯èƒ½å¤±è´¥")
                            return False
                    except Exception as e:
                        print(f"   âš ï¸  å¤„ç†ä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                        return False
                else:
                    print(f"   âš ï¸  Chromeä¸‹è½½è¶…æ—¶ï¼ˆç­‰å¾…{max_wait_time}ç§’ï¼‰")
                    return False
                
            except Exception as e:
                print(f"   âš ï¸  Chromeä¸‹è½½æ—¶å‡ºé”™: {e}")
                return False
            finally:
                # ç¡®ä¿èµ„æºè¢«æ­£ç¡®æ¸…ç†
                if tab:
                    try:
                        # ç§»é™¤äº‹ä»¶ç›‘å¬å™¨
                        try:
                            tab.Page.downloadWillBegin = None
                            # å°è¯•ç§»é™¤BrowseråŸŸçš„ç›‘å¬å™¨
                            if hasattr(tab, 'Browser') and hasattr(tab.Browser, 'downloadProgress'):
                                tab.Browser.downloadProgress = None
                            # å°è¯•ç§»é™¤PageåŸŸçš„ç›‘å¬å™¨
                            if hasattr(tab, 'Page') and hasattr(tab.Page, 'downloadProgress'):
                                tab.Page.downloadProgress = None
                        except:
                            pass
                        # ç­‰å¾…æ¥æ”¶å¾ªç¯å¤„ç†å®Œ
                        time.sleep(0.2)
                        # åœæ­¢tab
                        try:
                            tab.stop()
                        except:
                            pass
                    except:
                        pass
                
                if browser and tab:
                    try:
                        browser.close_tab(tab)
                    except:
                        pass
                
                # æ¢å¤ä»£ç†ç¯å¢ƒå˜é‡
                for var, value in old_proxy_env.items():
                    os.environ[var] = value
                # æ¢å¤NO_PROXY
                if old_no_proxy:
                    os.environ['NO_PROXY'] = old_no_proxy
                elif 'NO_PROXY' in os.environ:
                    del os.environ['NO_PROXY']
                    
        except Exception as e:
            print(f"   âš ï¸  Chromeä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def _get_real_download_url_with_chrome(self, download_url: str) -> Optional[str]:
        """ä½¿ç”¨Chromeè·å–çœŸå®çš„ä¸‹è½½URLï¼ˆç”¨äºapi.kxdw.com/adown/è¿™ç±»éœ€è¦JSæ‰§è¡Œçš„é“¾æ¥ï¼‰
        æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•åªè·å–URLï¼Œä¸ä¼šå®é™…ä¸‹è½½æ–‡ä»¶
        """
        if not pychrome or 'api.kxdw.com/adown/' not in download_url:
            return None
        
        try:
            # Chromeæœ¬åœ°è¿æ¥ä¸ä½¿ç”¨ä»£ç†ï¼ˆä¸´æ—¶å–æ¶ˆä»£ç†ç¯å¢ƒå˜é‡ï¼‰
            import os
            old_proxy_env = {}
            proxy_env_vars = ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy', 'ALL_PROXY', 'all_proxy']
            for var in proxy_env_vars:
                if var in os.environ:
                    old_proxy_env[var] = os.environ[var]
                    del os.environ[var]
            
            # è®¾ç½®NO_PROXYï¼Œæ’é™¤æœ¬åœ°åœ°å€
            old_no_proxy = os.environ.get('NO_PROXY', '')
            os.environ['NO_PROXY'] = '127.0.0.1,localhost,0.0.0.0'
            
            browser = None
            tab = None
            try:
                browser = pychrome.Browser(url="http://127.0.0.1:9222")
                tab = browser.new_tab()
                tab.start()
                
                # ç¡®ä¿ä¸ä½¿ç”¨ä»£ç†ï¼ˆé€šè¿‡NetworkåŸŸï¼‰
                try:
                    if hasattr(tab, 'Network'):
                        tab.Network.enable()
                except:
                    pass
                
                # è®¾ç½®ä¸‹è½½è¡Œä¸ºä¸ºæ‹’ç»ï¼Œè¿™æ ·Chromeä¸ä¼šå®é™…ä¸‹è½½ï¼Œä½†æˆ‘ä»¬ä»èƒ½é€šè¿‡Page.downloadWillBeginäº‹ä»¶ç›‘å¬åˆ°ä¸‹è½½URL
                try:
                    tab.Page.setDownloadBehavior(behavior="deny")
                except:
                    pass
                
                # ç›‘å¬ä¸‹è½½äº‹ä»¶
                real_download_url = None
                download_guid = None
                
                def on_download_will_begin(**kwargs):
                    nonlocal real_download_url, download_guid
                    real_download_url = kwargs.get('url', None)
                    download_guid = kwargs.get('guid', None)
                    print(f"   ğŸ“¥ æ£€æµ‹åˆ°ä¸‹è½½äº‹ä»¶ï¼Œè·å–çœŸå®ä¸‹è½½åœ°å€...")
                
                tab.Page.downloadWillBegin = on_download_will_begin
                tab.Page.enable()
                
                print(f"   ğŸŒ ä½¿ç”¨Chromeè·å–çœŸå®ä¸‹è½½åœ°å€ï¼ˆä¸ä¼šå®é™…ä¸‹è½½ï¼‰...")
                # æ³¨æ„ï¼šChromeä¼šä½¿ç”¨ç³»ç»Ÿä»£ç†è®¾ç½®ï¼ˆå¦‚æœShadowrocketé…ç½®äº†ç³»ç»Ÿä»£ç†ï¼‰
                tab.Page.navigate(url=download_url)
                
                # ç­‰å¾…ä¸‹è½½äº‹ä»¶ï¼ˆæœ€å¤š10ç§’ï¼‰
                for i in range(20):
                    time.sleep(0.5)
                    if real_download_url:
                        break
                
                # è·å–åˆ°çœŸå®ä¸‹è½½URLåï¼Œå–æ¶ˆä¸‹è½½ï¼ˆå› ä¸ºè¿™åªæ˜¯ä¸ºäº†è·å–URLï¼‰
                if real_download_url:
                    print(f"   âœ… å·²è·å–çœŸå®ä¸‹è½½åœ°å€ï¼Œå–æ¶ˆä¸´æ—¶ä¸‹è½½ä»»åŠ¡...")
                    # å°è¯•å–æ¶ˆä¸‹è½½ä»»åŠ¡
                    try:
                        if download_guid:
                            try:
                                tab.Browser.cancelDownload(guid=download_guid)
                            except:
                                pass
                    except:
                        pass
                    # å¯¼èˆªåˆ°ç©ºç™½é¡µï¼Œåœæ­¢å½“å‰é¡µé¢çš„ä¸‹è½½æ´»åŠ¨
                    try:
                        tab.Page.navigate(url="about:blank")
                        time.sleep(0.2)  # ç­‰å¾…å¯¼èˆªå®Œæˆ
                    except:
                        pass
                
                # åœ¨åœæ­¢å‰ï¼Œç§»é™¤äº‹ä»¶ç›‘å¬å™¨ï¼Œé¿å…åå°çº¿ç¨‹ç»§ç»­å¤„ç†
                try:
                    tab.Page.downloadWillBegin = None
                except:
                    pass
                
            except Exception as e:
                print(f"   âš ï¸  Chromeè·å–ä¸‹è½½åœ°å€æ—¶å‡ºé”™: {e}")
            finally:
                # ç¡®ä¿èµ„æºè¢«æ­£ç¡®æ¸…ç†ï¼Œé¿å…åå°çº¿ç¨‹JSONè§£æé”™è¯¯
                if tab:
                    try:
                        # å…ˆç§»é™¤æ‰€æœ‰äº‹ä»¶ç›‘å¬å™¨
                        try:
                            tab.Page.downloadWillBegin = None
                        except:
                            pass
                        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œè®©æ¥æ”¶å¾ªç¯å¤„ç†å®Œå½“å‰æ¶ˆæ¯
                        time.sleep(0.2)
                        # åœæ­¢tabï¼ˆè¿™ä¼šåœæ­¢æ¥æ”¶å¾ªç¯ï¼Œé¿å…åå°çº¿ç¨‹ç»§ç»­è¯»å–å¯¼è‡´JSONé”™è¯¯ï¼‰
                        try:
                            tab.stop()
                        except:
                            # å¦‚æœstopå¤±è´¥ï¼Œå¯èƒ½æ˜¯è¿æ¥å·²æ–­å¼€ï¼Œå¿½ç•¥é”™è¯¯
                            pass
                    except Exception as e:
                        # å¿½ç•¥åœæ­¢æ—¶çš„é”™è¯¯ï¼ˆå¯èƒ½æ˜¯è¿æ¥å·²æ–­å¼€ï¼‰
                        pass
                
                if browser and tab:
                    try:
                        # å…³é—­æ ‡ç­¾é¡µ
                        browser.close_tab(tab)
                    except Exception as e:
                        # å¿½ç•¥å…³é—­æ—¶çš„é”™è¯¯
                        pass
                
                # æ¢å¤ä»£ç†ç¯å¢ƒå˜é‡
                for var, value in old_proxy_env.items():
                    os.environ[var] = value
                # æ¢å¤NO_PROXY
                if old_no_proxy:
                    os.environ['NO_PROXY'] = old_no_proxy
                elif 'NO_PROXY' in os.environ:
                    del os.environ['NO_PROXY']
            
            if real_download_url:
                print(f"   âœ… è·å–åˆ°çœŸå®ä¸‹è½½åœ°å€: {real_download_url[:100]}...")
                return real_download_url
            else:
                print(f"   âš ï¸  æœªæ£€æµ‹åˆ°ä¸‹è½½äº‹ä»¶ï¼Œä½¿ç”¨åŸå§‹URL")
                return None
                
        except Exception as e:
            print(f"   âš ï¸  Chromeè·å–ä¸‹è½½åœ°å€å¤±è´¥: {e}")
            return None
    
    def _download_file(self, download_url: str, save_path: Path, use_proxy: bool = None) -> bool:
        """ä¸‹è½½æ–‡ä»¶
        Args:
            download_url: ä¸‹è½½URL
            save_path: ä¿å­˜è·¯å¾„
            use_proxy: æ˜¯å¦ä½¿ç”¨ä»£ç†ï¼ˆNoneè¡¨ç¤ºè‡ªåŠ¨åˆ¤æ–­ï¼‰
        """
        if not requests:
            print("âŒ è¯·å®‰è£… requests: pip3 install requests")
            return False
        
        try:
            # æ ‡è®°æ˜¯å¦è·å–åˆ°çœŸå®ä¸‹è½½åœ°å€
            has_real_url = False
            
            # æ³¨æ„ï¼šå¦‚æœæ˜¯api.kxdw.com/adown/é“¾æ¥ä¸”å¯ç”¨äº†Chromeï¼Œ
            # åº”è¯¥åœ¨è°ƒç”¨_download_fileä¹‹å‰å°±ä½¿ç”¨_download_with_chromeä¸‹è½½
            # è¿™é‡Œåªå¤„ç†éChromeæ¨¡å¼æˆ–Chromeä¸‹è½½å¤±è´¥åçš„æƒ…å†µ
            # å¦‚æœuse_proxy=Trueï¼Œè¯´æ˜æ˜¯é‡è¯•ï¼ˆå·²ç»è·å–è¿‡çœŸå®URLï¼‰ï¼Œè·³è¿‡è·å–æ­¥éª¤
            if use_proxy is True:
                # å¦‚æœæ˜¯é‡è¯•ï¼ˆå¼ºåˆ¶ä½¿ç”¨ä»£ç†ï¼‰ï¼Œè¯´æ˜å·²ç»è·å–è¿‡çœŸå®URL
                has_real_url = True
                print(f"   ğŸ”„ ä½¿ç”¨ä»£ç†é‡æ–°ä¸‹è½½ï¼ˆå·²è·å–çœŸå®ä¸‹è½½åœ°å€ï¼‰")
            
            # ä½¿ç”¨éšæœºUser-Agentå’Œå®Œæ•´è¯·æ±‚å¤´
            headers = self._get_browser_headers(referer='https://www.kxdw.com/', is_download=True)
            
            # ä½¿ç”¨Sessionæ¥è·Ÿè¸ªé‡å®šå‘é“¾
            session = requests.Session()
            session.max_redirects = 10
            
            print(f"   ğŸ” è·Ÿè¸ªé‡å®šå‘é“¾...")
            print(f"      åˆå§‹URL: {download_url[:100]}...")
            
            # å¦‚æœè·å–åˆ°çœŸå®ä¸‹è½½åœ°å€ï¼Œå…ˆå°è¯•ä¸ä½¿ç”¨ä»£ç†
            # å¦‚æœå¤±è´¥ï¼Œå†ä½¿ç”¨ä»£ç†
            # å¦‚æœuse_proxyå‚æ•°å·²æŒ‡å®šï¼Œä½¿ç”¨æŒ‡å®šå€¼ï¼ˆç”¨äºé‡è¯•æ—¶å¼ºåˆ¶ä½¿ç”¨ä»£ç†ï¼‰
            if use_proxy is not None:
                use_proxy_for_download = use_proxy
            else:
                use_proxy_for_download = not has_real_url
            proxy = None
            proxies = {}
            
            if use_proxy_for_download:
                # è·å–ä»£ç†ï¼ˆç”¨äºè§£æé¡µé¢æˆ–åˆå§‹ä¸‹è½½ï¼‰
                proxy = self._get_next_proxy()
                proxies = self._format_proxy_for_requests(proxy)
                if proxies:
                    print(f"   ğŸŒ ä½¿ç”¨ä»£ç†: {list(proxies.values())[0]}")
            else:
                print(f"   ğŸš€ ä¸ä½¿ç”¨ä»£ç†ï¼ˆå·²è·å–çœŸå®ä¸‹è½½åœ°å€ï¼‰")
            
            # éšæœºå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            self._random_delay(0.5, 1.5)
            
            # å…ˆå‘é€HEADè¯·æ±‚æŸ¥çœ‹é‡å®šå‘ï¼ˆå¢åŠ è¶…æ—¶æ—¶é—´ï¼‰
            head_response = session.head(download_url, headers=headers, proxies=proxies, timeout=60, allow_redirects=True)
            redirect_history = head_response.history
            final_url = head_response.url
            
            if redirect_history:
                print(f"   ğŸ“‹ å‘ç° {len(redirect_history)} æ¬¡é‡å®šå‘:")
                for i, resp in enumerate(redirect_history, 1):
                    print(f"      {i}. {resp.status_code} -> {resp.headers.get('Location', 'N/A')[:100]}")
                print(f"      æœ€ç»ˆURL: {final_url[:100]}...")
            else:
                print(f"   âœ… æ— é‡å®šå‘ï¼Œç›´æ¥è®¿é—®: {final_url[:100]}...")
            
            # è·å–æœ€ç»ˆURLçš„Content-Type
            content_type = head_response.headers.get('Content-Type', '').lower()
            content_length = head_response.headers.get('Content-Length', '')
            print(f"   ğŸ“‹ å“åº”å¤´ä¿¡æ¯:")
            print(f"      Content-Type: {content_type}")
            print(f"      Content-Length: {content_length} å­—èŠ‚" if content_length else "      Content-Length: æœªæä¾›")
            
            # éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»ç‚¹å‡»ä¸‹è½½çš„è¡Œä¸º
            self._random_delay(0.3, 1.0)
            
            # ä½¿ç”¨æœ€ç»ˆURLè¿›è¡Œä¸‹è½½ï¼ˆä½¿ç”¨æ–°çš„éšæœºUser-Agentï¼‰
            download_start_time = time.time()  # è®°å½•ä¸‹è½½å¼€å§‹æ—¶é—´
            print(f"   ğŸ“¥ å¼€å§‹ä¸‹è½½...")
            download_headers = self._get_browser_headers(referer=download_url, is_download=True)
            
            # æ·»åŠ è¿æ¥ä¿æ´»æœºåˆ¶
            download_headers['Connection'] = 'keep-alive'
            download_headers['Keep-Alive'] = 'timeout=300, max=1000'
            
            # å…ˆå°è¯•é€šè¿‡HEADè¯·æ±‚è·å–æ–‡ä»¶å¤§å°ï¼ˆç”¨äºè®¡ç®—è¶…æ—¶æ—¶é—´ï¼‰
            # å¦‚æœè·å–åˆ°çœŸå®URLä¸”ä¸ä½¿ç”¨ä»£ç†å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä»£ç†
            total_size = 0
            try:
                head_response = session.head(final_url, headers=download_headers, proxies=proxies, timeout=60, allow_redirects=True)
                total_size = int(head_response.headers.get('content-length', 0))
            except Exception as e:
                # å¦‚æœHEADè¯·æ±‚å¤±è´¥ä¸”ä¸ä½¿ç”¨ä»£ç†ï¼Œå°è¯•ä½¿ç”¨ä»£ç†
                if not use_proxy_for_download:
                    print(f"   âš ï¸  ä¸ä½¿ç”¨ä»£ç†è®¿é—®å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨ä»£ç†...")
                    proxy = self._get_next_proxy()
                    proxies = self._format_proxy_for_requests(proxy)
                    use_proxy_for_download = True
                    if proxies:
                        print(f"   ğŸŒ åˆ‡æ¢åˆ°ä»£ç†: {list(proxies.values())[0]}")
                    try:
                        head_response = session.head(final_url, headers=download_headers, proxies=proxies, timeout=60, allow_redirects=True)
                        total_size = int(head_response.headers.get('content-length', 0))
                    except:
                        total_size = 0
                else:
                    # å¦‚æœHEADè¯·æ±‚å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼Œç¨åä»GETå“åº”ä¸­è·å–
                    total_size = 0
            
            # æ ¹æ®æ–‡ä»¶å¤§å°åŠ¨æ€è°ƒæ•´è¶…æ—¶æ—¶é—´ï¼ˆè‡³å°‘600ç§’ï¼‰
            if total_size > 0:
                estimated_time = (total_size / 1024 / 1024) / 0.1  # å‡è®¾æœ€å°é€Ÿåº¦0.1MB/s
                timeout = max(600, int(estimated_time * 1.5))  # è‡³å°‘600ç§’ï¼Œæˆ–ä¼°ç®—æ—¶é—´çš„1.5å€
            else:
                timeout = 600  # å¦‚æœä¸çŸ¥é“æ–‡ä»¶å¤§å°ï¼Œä½¿ç”¨600ç§’
            
            # å°è¯•ä¸‹è½½ï¼Œå¦‚æœè·å–åˆ°çœŸå®URLä¸”ä¸ä½¿ç”¨ä»£ç†å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä»£ç†
            try:
                response = session.get(final_url, headers=download_headers, proxies=proxies, stream=True, timeout=timeout)
                response.raise_for_status()
            except Exception as e:
                # å¦‚æœä¸‹è½½å¤±è´¥ä¸”ä¸ä½¿ç”¨ä»£ç†ï¼Œå°è¯•ä½¿ç”¨ä»£ç†
                if not use_proxy_for_download:
                    print(f"   âš ï¸  ä¸ä½¿ç”¨ä»£ç†ä¸‹è½½å¤±è´¥: {e}ï¼Œåˆ‡æ¢åˆ°ä»£ç†é‡æ–°ä¸‹è½½...")
                    
                    # åœ¨åˆ‡æ¢ä»£ç†ä¹‹å‰ï¼Œå…ˆåˆ é™¤æœªä¸‹è½½å®Œçš„æ–‡ä»¶
                    if save_path.exists():
                        try:
                            file_size = save_path.stat().st_size
                            save_path.unlink()
                            print(f"   ğŸ—‘ï¸  å·²åˆ é™¤æœªä¸‹è½½å®Œçš„æ–‡ä»¶: {save_path.name} ({file_size / 1024 / 1024:.2f}MB)")
                        except Exception as del_e:
                            print(f"   âš ï¸  åˆ é™¤æ–‡ä»¶å¤±è´¥: {del_e}")
                    
                    # åˆ‡æ¢åˆ°ä»£ç†
                    proxy = self._get_next_proxy()
                    proxies = self._format_proxy_for_requests(proxy)
                    use_proxy_for_download = True
                    if proxies:
                        print(f"   ğŸŒ åˆ‡æ¢åˆ°ä»£ç†: {list(proxies.values())[0]}")
                    
                    # é‡æ–°è·å–å“åº”ï¼ˆä½¿ç”¨ä»£ç†ï¼‰
                    response = session.get(final_url, headers=download_headers, proxies=proxies, stream=True, timeout=timeout)
                    response.raise_for_status()
                else:
                    raise
            
            # å¦‚æœä¹‹å‰æ²¡æœ‰è·å–åˆ°æ–‡ä»¶å¤§å°ï¼Œç°åœ¨ä»å“åº”å¤´è·å–
            if total_size == 0:
                total_size = int(response.headers.get('content-length', 0))
            
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦ä¸º"error"ï¼ˆIPé™åˆ¶çš„æƒ…å†µï¼‰
            # å…ˆè¯»å–ä¸€å°éƒ¨åˆ†å†…å®¹æ£€æŸ¥
            preview = response.raw.read(10) if hasattr(response.raw, 'read') else b''
            if preview == b'error' or (len(preview) > 0 and preview.startswith(b'error')):
                # å¦‚æœä¸ä½¿ç”¨ä»£ç†ä¸”è¿”å›errorï¼Œå°è¯•åˆ‡æ¢åˆ°ä»£ç†
                if not use_proxy_for_download:
                    print(f"\n   âš ï¸  æœåŠ¡å™¨è¿”å›'error'ï¼ˆä¸ä½¿ç”¨ä»£ç†ï¼‰ï¼Œåˆ‡æ¢åˆ°ä»£ç†é‡æ–°ä¸‹è½½...")
                    
                    # åœ¨åˆ‡æ¢ä»£ç†ä¹‹å‰ï¼Œå…ˆåˆ é™¤æœªä¸‹è½½å®Œçš„æ–‡ä»¶
                    if save_path.exists():
                        try:
                            file_size = save_path.stat().st_size
                            save_path.unlink()
                            print(f"   ğŸ—‘ï¸  å·²åˆ é™¤æœªä¸‹è½½å®Œçš„æ–‡ä»¶: {save_path.name} ({file_size / 1024 / 1024:.2f}MB)")
                        except Exception as del_e:
                            print(f"   âš ï¸  åˆ é™¤æ–‡ä»¶å¤±è´¥: {del_e}")
                    
                    # å…³é—­å½“å‰å“åº”
                    try:
                        response.close()
                    except:
                        pass
                    
                    # åˆ‡æ¢åˆ°ä»£ç†
                    proxy = self._get_next_proxy()
                    proxies = self._format_proxy_for_requests(proxy)
                    use_proxy_for_download = True
                    if proxies:
                        print(f"   ğŸŒ åˆ‡æ¢åˆ°ä»£ç†: {list(proxies.values())[0]}")
                    
                    # ä½¿ç”¨ä»£ç†é‡æ–°è·å–å“åº”
                    response = session.get(final_url, headers=download_headers, proxies=proxies, stream=True, timeout=timeout)
                    response.raise_for_status()
                    
                    # é‡æ–°æ£€æŸ¥å“åº”å†…å®¹
                    preview = response.raw.read(10) if hasattr(response.raw, 'read') else b''
                    if preview == b'error' or (len(preview) > 0 and preview.startswith(b'error')):
                        print(f"\nâŒ ä½¿ç”¨ä»£ç†åæœåŠ¡å™¨ä»è¿”å›'error'ï¼Œå¯èƒ½æ˜¯IPåœ°å€è¢«é™åˆ¶")
                        print(f"   ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
                        print(f"      1. åˆ‡æ¢ç½‘ç»œï¼ˆå¦‚ä½¿ç”¨5G/ç§»åŠ¨ç½‘ç»œï¼‰")
                        print(f"      2. æ›´æ¢VPNæˆ–ä»£ç†æœåŠ¡å™¨")
                        print(f"      3. æ›´æ¢ç½‘ç»œç¯å¢ƒåé‡è¯•")
                        return False
                else:
                    print(f"\nâŒ æœåŠ¡å™¨è¿”å›'error'ï¼Œå¯èƒ½æ˜¯IPåœ°å€è¢«é™åˆ¶")
                    print(f"   ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
                    print(f"      1. åˆ‡æ¢ç½‘ç»œï¼ˆå¦‚ä½¿ç”¨5G/ç§»åŠ¨ç½‘ç»œï¼‰")
                    print(f"      2. ä½¿ç”¨VPNæˆ–ä»£ç†æœåŠ¡å™¨")
                    print(f"      3. æ›´æ¢ç½‘ç»œç¯å¢ƒåé‡è¯•")
                    return False
            
            # å¦‚æœå·²ç»è¯»å–äº†é¢„è§ˆï¼Œéœ€è¦é‡æ–°è·å–å“åº”
            if preview:
                try:
                    response.close()
                except:
                    pass
                # ä½¿ç”¨ä¸‹è½½headersé‡æ–°è·å–ï¼ˆä½¿ç”¨åŠ¨æ€è¶…æ—¶æ—¶é—´ï¼‰
                if total_size > 0:
                    estimated_time = (total_size / 1024 / 1024) / 0.1
                    timeout = max(600, int(estimated_time * 1.5))
                else:
                    timeout = 600
                response = session.get(final_url, headers=download_headers, proxies=proxies, stream=True, timeout=timeout)
                response.raise_for_status()
                # æ›´æ–°total_sizeï¼ˆä»¥é˜²å“åº”å¤´ä¸­çš„å€¼ä¸åŒï¼‰
                total_size = int(response.headers.get('content-length', total_size))
            
            # æ£€æŸ¥æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
            supports_range = 'bytes' in response.headers.get('Accept-Ranges', '')
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
            resume_pos = 0
            if save_path.exists() and supports_range:
                resume_pos = save_path.stat().st_size
                if resume_pos > 0 and resume_pos < total_size:
                    print(f"   ğŸ“¥ æ£€æµ‹åˆ°æœªå®Œæˆçš„ä¸‹è½½ï¼Œä» {resume_pos / 1024 / 1024:.2f}MB å¤„ç»§ç»­ä¸‹è½½...")
                    # å…³é—­å½“å‰å“åº”
                    response.close()
                    # ä½¿ç”¨Rangeè¯·æ±‚ç»§ç»­ä¸‹è½½ï¼ˆä½¿ç”¨åŠ¨æ€è¶…æ—¶æ—¶é—´ï¼‰
                    download_headers['Range'] = f'bytes={resume_pos}-'
                    if total_size > 0:
                        remaining_size = total_size - resume_pos
                        estimated_time = (remaining_size / 1024 / 1024) / 0.1
                        timeout = max(600, int(estimated_time * 1.5))
                    else:
                        timeout = 600
                    response = session.get(final_url, headers=download_headers, proxies=proxies, stream=True, timeout=timeout)
                    response.raise_for_status()
            
            # æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆå¢åŠ åˆ°5æ¬¡ï¼Œæé«˜æˆåŠŸç‡ï¼‰
            max_retries = 5
            retry_count = 0
            downloaded = resume_pos
            
            # ä¸‹è½½é€Ÿåº¦ç›‘æ§
            last_check_time = time.time()
            last_downloaded = downloaded
            min_speed_mbps = 0.1  # æœ€å°ä¸‹è½½é€Ÿåº¦ 0.1MB/sï¼Œå¦‚æœä½äºæ­¤é€Ÿåº¦åˆ™é‡è¯•
            speed_check_interval = 30  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡é€Ÿåº¦
            
            # é€Ÿåº¦ä¸‹é™æ£€æµ‹ï¼šè®°å½•åˆå§‹é€Ÿåº¦ï¼Œå¦‚æœé€Ÿåº¦æŒç»­ä¸‹é™åˆ™é‡æ–°å»ºç«‹è¿æ¥
            initial_speed = None
            speed_degradation_threshold = 0.5  # å¦‚æœé€Ÿåº¦ä¸‹é™åˆ°åˆå§‹é€Ÿåº¦çš„50%ä»¥ä¸‹ï¼Œé‡æ–°å»ºç«‹è¿æ¥
            connection_refresh_interval = 120  # æ¯120ç§’ï¼ˆ2åˆ†é’Ÿï¼‰é‡æ–°å»ºç«‹è¿æ¥ï¼Œé¿å…é€Ÿåº¦ä¸‹é™
            last_connection_time = time.time()
            consecutive_slow_checks = 0  # è¿ç»­æ…¢é€Ÿæ£€æŸ¥æ¬¡æ•°
            
            while retry_count < max_retries:
                try:
                    # æ‰“å¼€æ–‡ä»¶ï¼ˆè¿½åŠ æ¨¡å¼ç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
                    mode = 'ab' if resume_pos > 0 else 'wb'
                    with open(save_path, mode) as f:
                        chunk_count = 0
                        for chunk in response.iter_content(chunk_size=8192 * 2):  # å‡å°chunk_sizeåˆ°16KBï¼Œæé«˜ç¨³å®šæ€§
                            if chunk:
                                f.write(chunk)
                                downloaded += len(chunk)
                                chunk_count += 1
                                
                                # æ£€æŸ¥æ˜¯å¦ä¸‹è½½å®Œæˆ
                                if total_size > 0 and downloaded >= total_size:
                                    print(f"\n   ğŸ” [DEBUG] ä¸‹è½½å®Œæˆï¼šdownloaded={downloaded}, total_size={total_size}")
                                    break
                                
                                # ä¸‹è½½é€Ÿåº¦ç›‘æ§
                                current_time = time.time()
                                if current_time - last_check_time >= speed_check_interval:
                                    elapsed = current_time - last_check_time
                                    downloaded_bytes = downloaded - last_downloaded
                                    speed_mbps = (downloaded_bytes / 1024 / 1024) / elapsed if elapsed > 0 else 0
                                    
                                    # è®°å½•åˆå§‹é€Ÿåº¦ï¼ˆå‰ä¸¤æ¬¡æ£€æŸ¥çš„å¹³å‡å€¼ï¼‰
                                    if initial_speed is None:
                                        if speed_mbps > 0:
                                            initial_speed = speed_mbps
                                    else:
                                        # å¦‚æœé€Ÿåº¦æŒç»­ä¸‹é™ï¼Œè€ƒè™‘é‡æ–°å»ºç«‹è¿æ¥
                                        if speed_mbps < initial_speed * speed_degradation_threshold:
                                            consecutive_slow_checks += 1
                                            if consecutive_slow_checks >= 2:  # è¿ç»­2æ¬¡æ£€æŸ¥éƒ½æ…¢
                                                print(f"\n   âš ï¸  æ£€æµ‹åˆ°é€Ÿåº¦æŒç»­ä¸‹é™ï¼ˆå½“å‰: {speed_mbps:.2f}MB/sï¼Œåˆå§‹: {initial_speed:.2f}MB/sï¼‰ï¼Œé‡æ–°å»ºç«‹è¿æ¥...")
                                                # ä¿å­˜å½“å‰è¿›åº¦
                                                current_size = save_path.stat().st_size if save_path.exists() else downloaded
                                                # å…³é—­å½“å‰å“åº”
                                                try:
                                                    response.close()
                                                except:
                                                    pass
                                                # å¦‚æœæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œä»å½“å‰ä½ç½®ç»§ç»­
                                                if supports_range and current_size < total_size:
                                                    resume_pos = current_size
                                                    download_headers['Range'] = f'bytes={resume_pos}-'
                                                    print(f"   ğŸ“¥ ä» {resume_pos / 1024 / 1024:.2f}MB å¤„é‡æ–°è¿æ¥...")
                                                    response = session.get(final_url, headers=download_headers, proxies=proxies, stream=True, timeout=timeout)
                                                    response.raise_for_status()
                                                    downloaded = resume_pos
                                                    last_check_time = time.time()
                                                    last_downloaded = downloaded
                                                    last_connection_time = time.time()
                                                    consecutive_slow_checks = 0
                                                    # é‡ç½®åˆå§‹é€Ÿåº¦
                                                    initial_speed = None
                                                else:
                                                    # ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ŒæŠ›å‡ºå¼‚å¸¸è§¦å‘é‡è¯•
                                                    raise requests.exceptions.ConnectionError("é€Ÿåº¦ä¸‹é™ï¼Œé‡æ–°å»ºç«‹è¿æ¥")
                                        else:
                                            consecutive_slow_checks = 0  # é€Ÿåº¦æ­£å¸¸ï¼Œé‡ç½®è®¡æ•°å™¨
                                    
                                    # å®šæœŸé‡æ–°å»ºç«‹è¿æ¥ï¼ˆæ¯2åˆ†é’Ÿï¼‰ï¼Œé¿å…é•¿æ—¶é—´è¿æ¥å¯¼è‡´é€Ÿåº¦ä¸‹é™
                                    if current_time - last_connection_time >= connection_refresh_interval and downloaded < total_size * 0.95:
                                        print(f"\n   ğŸ”„ å®šæœŸåˆ·æ–°è¿æ¥ï¼ˆå·²è¿æ¥ {int((current_time - last_connection_time) / 60)} åˆ†é’Ÿï¼‰ï¼Œé‡æ–°å»ºç«‹è¿æ¥ä»¥ä¿æŒé€Ÿåº¦...")
                                        current_size = save_path.stat().st_size if save_path.exists() else downloaded
                                        try:
                                            response.close()
                                        except:
                                            pass
                                        # å¦‚æœæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œä»å½“å‰ä½ç½®ç»§ç»­
                                        if supports_range and current_size < total_size:
                                            resume_pos = current_size
                                            download_headers['Range'] = f'bytes={resume_pos}-'
                                            response = session.get(final_url, headers=download_headers, proxies=proxies, stream=True, timeout=timeout)
                                            response.raise_for_status()
                                            downloaded = resume_pos
                                            last_connection_time = time.time()
                                            last_check_time = time.time()
                                            last_downloaded = downloaded
                                            consecutive_slow_checks = 0
                                            # é‡ç½®åˆå§‹é€Ÿåº¦
                                            initial_speed = None
                                    
                                    if speed_mbps < min_speed_mbps and downloaded < total_size * 0.9:
                                        # é€Ÿåº¦è¿‡æ…¢ï¼Œå¯èƒ½æ˜¯è¿æ¥é—®é¢˜ï¼Œä¸»åŠ¨ä¸­æ–­å¹¶é‡è¯•
                                        print(f"\n   âš ï¸  ä¸‹è½½é€Ÿåº¦è¿‡æ…¢ ({speed_mbps:.2f}MB/s < {min_speed_mbps}MB/s)ï¼Œä¸»åŠ¨é‡è¯•...")
                                        raise requests.exceptions.ConnectionError("ä¸‹è½½é€Ÿåº¦è¿‡æ…¢ï¼Œä¸»åŠ¨é‡è¯•")
                                    
                                    last_check_time = current_time
                                    last_downloaded = downloaded
                                
                                # æ¯100ä¸ªchunkæ›´æ–°ä¸€æ¬¡è¿›åº¦ï¼ˆå‡å°‘I/Oï¼Œæé«˜æ€§èƒ½ï¼‰
                                if chunk_count % 100 == 0 or downloaded >= total_size:
                                    if total_size:
                                        percent = (downloaded / total_size) * 100
                                        # è®¡ç®—é€Ÿåº¦ï¼ˆåŸºäºå®é™…ä¸‹è½½æ—¶é—´ï¼‰
                                        elapsed_time = time.time() - download_start_time
                                        if elapsed_time > 0:
                                            speed = (downloaded - resume_pos) / elapsed_time / 1024 / 1024
                                        else:
                                            speed = 0
                                        # ä½¿ç”¨sys.stderrç¡®ä¿è¿›åº¦æ˜¾ç¤ºä¸ä¼šè¢«å…¶ä»–è¾“å‡ºå¹²æ‰°
                                        sys.stderr.write(f"\r   ä¸‹è½½è¿›åº¦:3 {percent:.1f}% ({downloaded / 1024 / 1024:.2f}MB / {total_size / 1024 / 1024:.2f}MB) é€Ÿåº¦: {speed:.2f}MB/s")
                                        sys.stderr.flush()
                                        
                                        # Debug: å¦‚æœè¿›åº¦100%ï¼Œæ‰“å°debugä¿¡æ¯
                                        if percent >= 99.9:
                                            print(f"\n   ğŸ” [DEBUG] requestsä¸‹è½½ï¼šè¿›åº¦{percent:.1f}%ï¼Œdownloaded={downloaded}, total_size={total_size}, chunk_count={chunk_count}")
                                        
                                        # å¦‚æœä¸‹è½½å®Œæˆï¼Œé€€å‡ºå¾ªç¯
                                        if downloaded >= total_size:
                                            print(f"\n   ğŸ” [DEBUG] requestsä¸‹è½½å®Œæˆï¼Œé€€å‡ºchunkå¾ªç¯")
                                            break
                    
                    # ä¸‹è½½æˆåŠŸï¼Œé€€å‡ºå¾ªç¯
                    break
                    
                except (requests.exceptions.ChunkedEncodingError, 
                        requests.exceptions.ConnectionError,
                        ConnectionResetError,
                        IOError,
                        IncompleteRead) as e:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯IncompleteReadé”™è¯¯æˆ–è¿æ¥ä¸­æ–­
                    error_str = str(e)
                    is_incomplete = isinstance(e, IncompleteRead) or 'IncompleteRead' in error_str or 'Connection broken' in error_str
                    
                    if is_incomplete:
                        retry_count += 1
                        current_size = save_path.stat().st_size if save_path.exists() else 0
                        
                        if retry_count < max_retries:
                            print(f"\n   âš ï¸  ä¸‹è½½ä¸­æ–­ï¼ˆå·²ä¸‹è½½ {current_size / 1024 / 1024:.2f}MBï¼‰ï¼Œæ­£åœ¨é‡è¯• ({retry_count}/{max_retries})...")
                            
                            # å…³é—­å½“å‰å“åº”
                            try:
                                response.close()
                            except:
                                pass
                            
                            # æŒ‡æ•°é€€é¿ç­–ç•¥ï¼šç­‰å¾…æ—¶é—´é€æ¸å¢åŠ ï¼ˆ2ç§’ã€4ç§’ã€8ç§’ã€16ç§’ã€32ç§’ï¼‰
                            wait_time = min(2 ** retry_count, 32)
                            print(f"   â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                            time.sleep(wait_time)
                            
                            # å¦‚æœæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œä»å½“å‰ä½ç½®ç»§ç»­
                            if supports_range and current_size < total_size:
                                resume_pos = current_size
                                download_headers['Range'] = f'bytes={resume_pos}-'
                                print(f"   ğŸ“¥ ä» {resume_pos / 1024 / 1024:.2f}MB å¤„ç»§ç»­ä¸‹è½½...")
                                
                                # å¢å¤§è¶…æ—¶æ—¶é—´ï¼ˆæ ¹æ®å‰©ä½™å¤§å°åŠ¨æ€è°ƒæ•´ï¼Œæœ€å°‘600ç§’ï¼‰
                                remaining_size = total_size - resume_pos
                                estimated_time = (remaining_size / 1024 / 1024) / min_speed_mbps  # æ ¹æ®æœ€å°é€Ÿåº¦ä¼°ç®—æ—¶é—´
                                timeout = max(600, int(estimated_time * 1.5))  # è‡³å°‘600ç§’ï¼Œæˆ–ä¼°ç®—æ—¶é—´çš„1.5å€
                                
                                response = session.get(final_url, headers=download_headers, proxies=proxies, stream=True, timeout=timeout)
                                response.raise_for_status()
                                downloaded = resume_pos
                                last_check_time = time.time()
                                last_downloaded = downloaded
                            else:
                                # ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œé‡æ–°å¼€å§‹ä¸‹è½½
                                print(f"   ğŸ“¥ æœåŠ¡å™¨ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œé‡æ–°å¼€å§‹ä¸‹è½½...")
                                if save_path.exists():
                                    save_path.unlink()
                                
                                # æ ¹æ®æ–‡ä»¶å¤§å°åŠ¨æ€è°ƒæ•´è¶…æ—¶æ—¶é—´
                                estimated_time = (total_size / 1024 / 1024) / min_speed_mbps
                                timeout = max(600, int(estimated_time * 1.5))
                                
                                response = session.get(final_url, headers=download_headers, proxies=proxies, stream=True, timeout=timeout)
                                response.raise_for_status()
                                downloaded = 0
                                resume_pos = 0
                                last_check_time = time.time()
                                last_downloaded = 0
                        else:
                            # é‡è¯•æ¬¡æ•°ç”¨å®Œ
                            # å¦‚æœè·å–åˆ°çœŸå®URLä¸”ä¸ä½¿ç”¨ä»£ç†ï¼Œå°è¯•åˆ‡æ¢åˆ°ä»£ç†
                            if has_real_url and not use_proxy_for_download:
                                print(f"\n   âš ï¸  ä¸ä½¿ç”¨ä»£ç†ä¸‹è½½å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰ï¼Œåˆ‡æ¢åˆ°ä»£ç†é‡æ–°ä¸‹è½½...")
                                
                                # åœ¨åˆ‡æ¢ä»£ç†ä¹‹å‰ï¼Œå…ˆåˆ é™¤æœªä¸‹è½½å®Œçš„æ–‡ä»¶
                                if save_path.exists():
                                    try:
                                        file_size = save_path.stat().st_size
                                        save_path.unlink()
                                        print(f"   ğŸ—‘ï¸  å·²åˆ é™¤æœªä¸‹è½½å®Œçš„æ–‡ä»¶: {save_path.name} ({file_size / 1024 / 1024:.2f}MB)")
                                    except Exception as del_e:
                                        print(f"   âš ï¸  åˆ é™¤æ–‡ä»¶å¤±è´¥: {del_e}")
                                
                                # åˆ‡æ¢åˆ°ä»£ç†ï¼Œé‡æ–°å°è¯•ä¸‹è½½ï¼ˆé€’å½’è°ƒç”¨ï¼Œä½†å¼ºåˆ¶ä½¿ç”¨ä»£ç†ï¼‰
                                try:
                                    print(f"   ğŸ”„ ä½¿ç”¨ä»£ç†é‡æ–°ä¸‹è½½...")
                                    return self._download_file(download_url, save_path, use_proxy=True)
                                except Exception as retry_e:
                                    print(f"\nâŒ ä½¿ç”¨ä»£ç†é‡æ–°ä¸‹è½½ä¹Ÿå¤±è´¥: {retry_e}")
                                    return False
                            else:
                                # é‡è¯•æ¬¡æ•°ç”¨å®Œï¼ŒæŠ›å‡ºå¼‚å¸¸
                                print(f"\n   âŒ ä¸‹è½½å¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡")
                                raise
                    else:
                        # å…¶ä»–é”™è¯¯
                        # å¦‚æœè·å–åˆ°çœŸå®URLä¸”ä¸ä½¿ç”¨ä»£ç†ï¼Œå°è¯•åˆ‡æ¢åˆ°ä»£ç†
                        if has_real_url and not use_proxy_for_download:
                            print(f"\n   âš ï¸  ä¸‹è½½å‡ºé”™ï¼ˆä¸ä½¿ç”¨ä»£ç†ï¼‰ï¼Œåˆ‡æ¢åˆ°ä»£ç†é‡æ–°ä¸‹è½½...")
                            
                            # åœ¨åˆ‡æ¢ä»£ç†ä¹‹å‰ï¼Œå…ˆåˆ é™¤æœªä¸‹è½½å®Œçš„æ–‡ä»¶
                            if save_path.exists():
                                try:
                                    file_size = save_path.stat().st_size
                                    save_path.unlink()
                                    print(f"   ğŸ—‘ï¸  å·²åˆ é™¤æœªä¸‹è½½å®Œçš„æ–‡ä»¶: {save_path.name} ({file_size / 1024 / 1024:.2f}MB)")
                                except Exception as del_e:
                                    print(f"   âš ï¸  åˆ é™¤æ–‡ä»¶å¤±è´¥: {del_e}")
                            
                            # åˆ‡æ¢åˆ°ä»£ç†ï¼Œé‡æ–°å°è¯•ä¸‹è½½ï¼ˆé€’å½’è°ƒç”¨ï¼Œä½†å¼ºåˆ¶ä½¿ç”¨ä»£ç†ï¼‰
                            try:
                                print(f"   ğŸ”„ ä½¿ç”¨ä»£ç†é‡æ–°ä¸‹è½½...")
                                return self._download_file(download_url, save_path, use_proxy=True)
                            except Exception as retry_e:
                                print(f"\nâŒ ä½¿ç”¨ä»£ç†é‡æ–°ä¸‹è½½ä¹Ÿå¤±è´¥: {retry_e}")
                                return False
                        else:
                            # å…¶ä»–é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                            raise
                finally:
                    # ç¡®ä¿å“åº”è¢«æ­£ç¡®å…³é—­ï¼Œé¿å…çº¿ç¨‹é”™è¯¯
                    try:
                        if response:
                            response.close()
                    except:
                        pass
            
            # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶ç¡®å®æ˜¯APK
            if save_path.exists():
                file_size = save_path.stat().st_size
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°æ˜¯å¦ä¸é¢„æœŸä¸€è‡´
                if total_size > 0 and file_size < total_size:
                    print(f"\nâš ï¸  æ–‡ä»¶å¤§å°ä¸å®Œæ•´: {file_size / 1024 / 1024:.2f}MB / {total_size / 1024 / 1024:.2f}MB")
                    # å¦‚æœæ–‡ä»¶å¤§å°ä¸å®Œæ•´ï¼Œä½†å¤§äº1MBï¼Œä¿ç•™æ–‡ä»¶ä»¥ä¾¿ä¸‹æ¬¡æ–­ç‚¹ç»­ä¼ 
                    if file_size > 1024 * 1024:  # å¤§äº1MB
                        print(f"   ğŸ’¡ æ–‡ä»¶å·²éƒ¨åˆ†ä¸‹è½½ï¼Œä¸‹æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ç»§ç»­ä¸‹è½½")
                        return False  # è¿”å›Falseï¼Œä½†ä¸åˆ é™¤æ–‡ä»¶
                    else:
                        # æ–‡ä»¶å¤ªå°ï¼Œåˆ é™¤
                        save_path.unlink()
                        return False
                
                if file_size < 1024:  # å°äº1KBå¯èƒ½æ˜¯HTMLé”™è¯¯é¡µé¢
                    # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦ä¸º"error"
                    try:
                        with open(save_path, 'rb') as f:
                            content = f.read(10)
                            if content == b'error' or content.startswith(b'error'):
                                print(f"\nâŒ ä¸‹è½½çš„æ–‡ä»¶å†…å®¹æ˜¯'error'ï¼ŒIPåœ°å€å¯èƒ½è¢«é™åˆ¶")
                                print(f"   ğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
                                print(f"      1. åˆ‡æ¢ç½‘ç»œï¼ˆå¦‚ä½¿ç”¨5G/ç§»åŠ¨ç½‘ç»œï¼‰")
                                print(f"      2. ä½¿ç”¨VPNæˆ–ä»£ç†æœåŠ¡å™¨")
                                print(f"      3. æ›´æ¢ç½‘ç»œç¯å¢ƒåé‡è¯•")
                            else:
                                print(f"\nâš ï¸  ä¸‹è½½çš„æ–‡ä»¶å¤ªå°({file_size}å­—èŠ‚)ï¼Œå¯èƒ½æ˜¯é”™è¯¯é¡µé¢ï¼Œåˆ é™¤æ–‡ä»¶")
                    except:
                        print(f"\nâš ï¸  ä¸‹è½½çš„æ–‡ä»¶å¤ªå°({file_size}å­—èŠ‚)ï¼Œå¯èƒ½æ˜¯é”™è¯¯é¡µé¢ï¼Œåˆ é™¤æ–‡ä»¶")
                    save_path.unlink()
                    return False
                
                # æ£€æŸ¥æ–‡ä»¶å¤´æ˜¯å¦æ˜¯APKæ ¼å¼ï¼ˆAPKæ–‡ä»¶ä»¥ZIPæ ¼å¼å¼€å¤´ï¼‰
                try:
                    with open(save_path, 'rb') as f:
                        file_header = f.read(4)
                        # APKæ–‡ä»¶æ˜¯ZIPæ ¼å¼ï¼ŒZIPæ–‡ä»¶å¤´æ˜¯PK\x03\x04æˆ–PK\x05\x06
                        if file_header[:2] == b'PK':
                            # è®¡ç®—ä¸‹è½½è€—æ—¶
                            download_end_time = time.time()
                            download_duration = download_end_time - download_start_time
                            download_minutes = int(download_duration // 60)
                            download_seconds = int(download_duration % 60)
                            if download_minutes > 0:
                                print(f"\nâœ… ä¸‹è½½å®Œæˆ: {save_path.name} ({file_size / 1024 / 1024:.2f}MB) è€—æ—¶: {download_minutes}åˆ†{download_seconds}ç§’")
                            else:
                                print(f"\nâœ… ä¸‹è½½å®Œæˆ: {save_path.name} ({file_size / 1024 / 1024:.2f}MB) è€—æ—¶: {download_seconds}ç§’")
                            self._create_zip_for_apk(save_path)
                            return True
                        else:
                            print(f"\nâš ï¸  æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®ï¼ˆä¸æ˜¯APK/ZIPæ ¼å¼ï¼‰ï¼Œå¯èƒ½æ˜¯HTMLé¡µé¢ï¼Œåˆ é™¤æ–‡ä»¶")
                            save_path.unlink()
                            return False
                except Exception as e:
                    print(f"\nâš ï¸  éªŒè¯æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½†æ–‡ä»¶å·²ä¸‹è½½")
                    self._create_zip_for_apk(save_path)
                    return True
            
            # è®¡ç®—ä¸‹è½½è€—æ—¶
            download_end_time = time.time()
            download_duration = download_end_time - download_start_time
            download_minutes = int(download_duration // 60)
            download_seconds = int(download_duration % 60)
            if download_minutes > 0:
                print(f"\nâœ… ä¸‹è½½å®Œæˆ: {save_path.name} è€—æ—¶: {download_minutes}åˆ†{download_seconds}ç§’")
            else:
                print(f"\nâœ… ä¸‹è½½å®Œæˆ: {save_path.name} è€—æ—¶: {download_seconds}ç§’")
            self._create_zip_for_apk(save_path)
            return True
            
        except Exception as e:
            # å¦‚æœè·å–åˆ°çœŸå®URLä¸”ä¸ä½¿ç”¨ä»£ç†ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä»£ç†é‡æ–°ä¸‹è½½
            if has_real_url and not use_proxy_for_download:
                print(f"\n   âš ï¸  ä¸ä½¿ç”¨ä»£ç†ä¸‹è½½å¤±è´¥: {e}ï¼Œåˆ‡æ¢åˆ°ä»£ç†é‡æ–°ä¸‹è½½...")
                
                # åœ¨åˆ‡æ¢ä»£ç†ä¹‹å‰ï¼Œå…ˆåˆ é™¤æœªä¸‹è½½å®Œçš„æ–‡ä»¶
                if save_path.exists():
                    try:
                        file_size = save_path.stat().st_size
                        save_path.unlink()
                        print(f"   ğŸ—‘ï¸  å·²åˆ é™¤æœªä¸‹è½½å®Œçš„æ–‡ä»¶: {save_path.name} ({file_size / 1024 / 1024:.2f}MB)")
                    except Exception as del_e:
                        print(f"   âš ï¸  åˆ é™¤æ–‡ä»¶å¤±è´¥: {del_e}")
                
                # åˆ‡æ¢åˆ°ä»£ç†ï¼Œé‡æ–°å°è¯•ä¸‹è½½ï¼ˆé€’å½’è°ƒç”¨ï¼Œä½†å¼ºåˆ¶ä½¿ç”¨ä»£ç†ï¼‰
                try:
                    print(f"   ğŸ”„ ä½¿ç”¨ä»£ç†é‡æ–°ä¸‹è½½...")
                    return self._download_file(download_url, save_path, use_proxy=True)
                except Exception as retry_e:
                    print(f"\nâŒ ä½¿ç”¨ä»£ç†é‡æ–°ä¸‹è½½ä¹Ÿå¤±è´¥: {retry_e}")
                    return False
            else:
                print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")
                return False
    
    def _cleanup_folder_on_failure(self, folder_path: Path):
        """ä¸‹è½½å¤±è´¥æ—¶æ¸…ç†æ–‡ä»¶å¤¹"""
        try:
            if not folder_path.exists():
                return
            
            # æ£€æŸ¥æ–‡ä»¶å¤¹å†…å®¹
            files = list(folder_path.iterdir())
            
            # å¦‚æœæ–‡ä»¶å¤¹ä¸ºç©ºï¼Œç›´æ¥åˆ é™¤
            if not files:
                try:
                    folder_path.rmdir()
                    print(f"   ğŸ—‘ï¸  å·²åˆ é™¤ç©ºæ–‡ä»¶å¤¹: {folder_path.name}")
                    return
                except Exception as e:
                    print(f"   âš ï¸  åˆ é™¤ç©ºæ–‡ä»¶å¤¹å¤±è´¥: {e}")
                    return
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„APKæ–‡ä»¶
            has_valid_apk = False
            for file in files:
                if file.is_file() and file.suffix.lower() == '.apk':
                    try:
                        # æ£€æŸ¥æ–‡ä»¶å¤´æ˜¯å¦æ˜¯APKæ ¼å¼
                        with open(file, 'rb') as f:
                            file_header = f.read(4)
                            if file_header[:2] == b'PK':
                                # æœ‰æœ‰æ•ˆçš„APKæ–‡ä»¶ï¼Œä¸åˆ é™¤æ–‡ä»¶å¤¹
                                has_valid_apk = True
                                break
                    except:
                        pass
            
            # å¦‚æœæœ‰æœ‰æ•ˆçš„APKæ–‡ä»¶ï¼Œä¸åˆ é™¤æ–‡ä»¶å¤¹
            if has_valid_apk:
                print(f"   â„¹ï¸  æ–‡ä»¶å¤¹ä¸­åŒ…å«æœ‰æ•ˆçš„APKæ–‡ä»¶ï¼Œä¿ç•™æ–‡ä»¶å¤¹")
                return
            
            # åˆ é™¤æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å†…å®¹
            for file in files:
                try:
                    if file.is_file():
                        file.unlink()
                        print(f"   ğŸ—‘ï¸  å·²åˆ é™¤æ–‡ä»¶: {file.name}")
                    elif file.is_dir():
                        import shutil
                        shutil.rmtree(file)
                        print(f"   ğŸ—‘ï¸  å·²åˆ é™¤å­æ–‡ä»¶å¤¹: {file.name}")
                except Exception as e:
                    print(f"   âš ï¸  åˆ é™¤å¤±è´¥ {file.name}: {e}")
            
            # åˆ é™¤ç©ºæ–‡ä»¶å¤¹
            try:
                folder_path.rmdir()
                print(f"   ğŸ—‘ï¸  å·²åˆ é™¤æ–‡ä»¶å¤¹: {folder_path.name}")
            except Exception as e:
                # å¦‚æœæ–‡ä»¶å¤¹ä¸ä¸ºç©ºï¼ˆå¯èƒ½è¿˜æœ‰éšè—æ–‡ä»¶ï¼‰ï¼Œå°è¯•å¼ºåˆ¶åˆ é™¤
                try:
                    import shutil
                    shutil.rmtree(folder_path)
                    print(f"   ğŸ—‘ï¸  å·²å¼ºåˆ¶åˆ é™¤æ–‡ä»¶å¤¹: {folder_path.name}")
                except Exception as e2:
                    print(f"   âš ï¸  åˆ é™¤æ–‡ä»¶å¤¹å¤±è´¥: {e2}")
        except Exception as e:
            print(f"   âš ï¸  æ¸…ç†æ–‡ä»¶å¤¹æ—¶å‡ºé”™: {e}")
    
    def _create_info_files(self, folder_path: Path):
        """åˆ›å»ºä¿¡æ¯æ–‡ä»¶"""
        # åˆ›å»º"ä¸å®šæ—¶æ›´æ–°æœ€æ–°ç‰ˆæœ¬.txt"
        file1 = folder_path / "ä¸å®šæ—¶æ›´æ–°æœ€æ–°ç‰ˆæœ¬.txt"
        with open(file1, 'w', encoding='utf-8') as f:
            f.write("æœ¬æ–‡ä»¶å¤¹å†…å®¹ä¼šä¸å®šæ—¶æ›´æ–°æœ€æ–°ç‰ˆæœ¬ï¼Œè¯·å…³æ³¨ã€‚\n")
        
        # åˆ›å»º"å…ˆä¿å­˜å†ä¸‹è½½é¿å…å¤±æ•ˆ.txt"
        file2 = folder_path / "å…ˆä¿å­˜å†ä¸‹è½½é¿å…å¤±æ•ˆ.txt"
        with open(file2, 'w', encoding='utf-8') as f:
            f.write("è¯·å…ˆä¿å­˜åˆ°è‡ªå·±çš„ç½‘ç›˜å†ä¸‹è½½ï¼Œé¿å…é“¾æ¥å¤±æ•ˆã€‚\n")
    
    def process_game(self, game: dict, index: int) -> bool:
        """å¤„ç†å•ä¸ªæ¸¸æˆ"""
        game_name = game.get('æ¸¸æˆåç§°', '')
        page_url = game.get('è¯¦æƒ…é¡µé“¾æ¥', '')
        downloaded = game.get('æ˜¯å¦å·²ä¸‹è½½', 'å¦')
        
        # å¦‚æœå·²ä¸‹è½½ï¼Œè·³è¿‡
        if downloaded == 'æ˜¯':
            return True
        
        print(f"\n{'='*60}")
        print(f"[{index}/{len(self.games)}] å¤„ç†: {game_name}")
        print(f"{'='*60}")
        
        # æå‰è·å–æ–‡ä»¶å¤¹åï¼ˆä¼˜åŒ–ï¼šåœ¨è§£æè¯¦æƒ…é¡µä¹‹å‰ï¼‰
        print(f"ğŸ” è·å–æ–‡ä»¶å¤¹å...")
        folder_name = self._get_folder_name(game_name)
        print(f"ğŸ“ æ–‡ä»¶å¤¹å: {folder_name}")
        
        # å…ˆè§£æè¯¦æƒ…é¡µè·å–æ–‡ä»¶å¤§å°ï¼ˆç”¨äºæ¯”è¾ƒï¼‰
        print(f"ğŸ” è§£æè¯¦æƒ…é¡µ...")
        detail_info = self._parse_game_detail(page_url)
        
        if not detail_info:
            print(f"âŒ æ— æ³•è§£æè¯¦æƒ…é¡µï¼Œè·³è¿‡")
            # æ ‡è®°ä¸ºæ²¡æœ‰ä¸‹è½½é“¾æ¥
            game['æ˜¯å¦æœ‰å®‰å“ä¸‹è½½é“¾æ¥'] = 'å¦'
            self._save_csv()
            return False
        
        # è·å–è¯¦æƒ…é¡µçš„æ–‡ä»¶å¤§å°ï¼ˆç›´æ¥ä½¿ç”¨è¯¦æƒ…é¡µè§£æçš„å¤§å°ï¼‰
        size_str = detail_info.get('size', '')
        if size_str:
            expected_size_mb = self._parse_size_to_mb(size_str)
            print(f"   ğŸ“Š è¯¦æƒ…é¡µæ–‡ä»¶å¤§å°: {size_str} ({expected_size_mb:.2f}MB)")
        else:
            expected_size_mb = 0.0
            print(f"   âš ï¸  è¯¦æƒ…é¡µæœªæä¾›æ–‡ä»¶å¤§å°ä¿¡æ¯")
        
        # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å·²å­˜åœ¨ï¼Œå¹¶æ¯”è¾ƒæ–‡ä»¶å¤§å°
        folder_path = self.download_base_dir / folder_name
        if folder_path.exists() and folder_path.is_dir():
            print(f"ğŸ“‚ æ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ–‡ä»¶...")
            # æ£€æŸ¥æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶
            files = [f for f in folder_path.iterdir() if f.is_file()]
            if files:
                # æŸ¥æ‰¾æœ€å¤§çš„æ–‡ä»¶
                largest_file = max(files, key=lambda f: f.stat().st_size)
                existing_file_size_bytes = largest_file.stat().st_size
                existing_file_size_mb = existing_file_size_bytes / 1024 / 1024
                print(f"   ğŸ“„ æ‰¾åˆ°æ–‡ä»¶: {largest_file.name} ({existing_file_size_mb:.2f}MB)")
                
                # å¦‚æœè¯¦æƒ…é¡µæœ‰æ–‡ä»¶å¤§å°ä¿¡æ¯ï¼Œè¿›è¡Œæ¯”è¾ƒ
                if expected_size_mb > 0:
                    print(f"   ğŸ“Š è¯¦æƒ…é¡µæ–‡ä»¶å¤§å°: {expected_size_mb:.2f}MB")
                    print(f"   ğŸ“Š å·²å­˜åœ¨æ–‡ä»¶å¤§å°: {existing_file_size_mb:.2f}MB")
                    
                    # å¦‚æœå·²å­˜åœ¨æ–‡ä»¶å¤§å° >= è¯¦æƒ…é¡µæ–‡ä»¶å¤§å°ï¼Œè®¤ä¸ºå·²ä¸‹è½½å®Œæˆ
                    # å…è®¸5%çš„è¯¯å·®ï¼ˆå› ä¸ºæ–‡ä»¶å¤§å°å¯èƒ½æœ‰è½»å¾®å·®å¼‚ï¼‰
                    if existing_file_size_mb >= expected_size_mb * 0.95:
                        print(f"âœ… å·²å­˜åœ¨æ–‡ä»¶å¤§å° ({existing_file_size_mb:.2f}MB) >= è¯¦æƒ…é¡µæ–‡ä»¶å¤§å° ({expected_size_mb:.2f}MB)ï¼Œè®¤ä¸ºå·²ä¸‹è½½å®Œæˆï¼Œè·³è¿‡")
                        game['æ˜¯å¦å·²ä¸‹è½½'] = 'æ˜¯'
                        game['æ˜¯å¦æœ‰å®‰å“ä¸‹è½½é“¾æ¥'] = 'æ˜¯'
                        self._save_csv()
                        return True
                    else:
                        print(f"âš ï¸  å·²å­˜åœ¨æ–‡ä»¶å¤§å° ({existing_file_size_mb:.2f}MB) < è¯¦æƒ…é¡µæ–‡ä»¶å¤§å° ({expected_size_mb:.2f}MB)ï¼Œåˆ é™¤æ—§æ–‡ä»¶å¹¶é‡æ–°ä¸‹è½½")
                        # åˆ é™¤æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰APKæ–‡ä»¶ï¼Œå‡†å¤‡é‡æ–°ä¸‹è½½
                        for file in files:
                            if file.suffix.lower() == '.apk':
                                try:
                                    file.unlink()
                                    print(f"   ğŸ—‘ï¸  å·²åˆ é™¤æ—§æ–‡ä»¶: {file.name}")
                                except Exception as e:
                                    print(f"   âš ï¸  åˆ é™¤æ–‡ä»¶å¤±è´¥ {file.name}: {e}")
                else:
                    # å¦‚æœè¯¦æƒ…é¡µæ²¡æœ‰æ–‡ä»¶å¤§å°ä¿¡æ¯ï¼Œä½¿ç”¨åŸæ¥çš„é€»è¾‘ï¼ˆå¤§äº1Mè®¤ä¸ºå·²ä¸‹è½½ï¼‰
                    if existing_file_size_mb > 1.0:
                        print(f"âš ï¸  è¯¦æƒ…é¡µæœªæä¾›æ–‡ä»¶å¤§å°ï¼Œä½†å·²å­˜åœ¨æ–‡ä»¶å¤§äº1M ({existing_file_size_mb:.2f}MB)ï¼Œè®¤ä¸ºå·²ä¸‹è½½å®Œæˆï¼Œè·³è¿‡")
                        game['æ˜¯å¦å·²ä¸‹è½½'] = 'æ˜¯'
                        game['æ˜¯å¦æœ‰å®‰å“ä¸‹è½½é“¾æ¥'] = 'æ˜¯'
                        self._save_csv()
                        return True
                    else:
                        print(f"âš ï¸  æ–‡ä»¶å¤§å° {existing_file_size_mb:.2f}MB å°äº1Mï¼Œå¯èƒ½æ˜¯æ— æ•ˆæ–‡ä»¶ï¼Œç»§ç»­ä¸‹è½½")
        
        # è·å–ä¸‹è½½é“¾æ¥
        download_url = detail_info.get('download_url', '')
        if not download_url:
            print(f"âŒ æ— æ³•è·å–ä¸‹è½½é“¾æ¥ï¼Œè·³è¿‡")
            # æ ‡è®°ä¸ºæ²¡æœ‰ä¸‹è½½é“¾æ¥
            game['æ˜¯å¦æœ‰å®‰å“ä¸‹è½½é“¾æ¥'] = 'å¦'
            self._save_csv()
            return False
        
        # æ ‡è®°ä¸ºæœ‰ä¸‹è½½é“¾æ¥
        game['æ˜¯å¦æœ‰å®‰å“ä¸‹è½½é“¾æ¥'] = 'æ˜¯'
        self._save_csv()
        
        # éªŒè¯ä¸‹è½½é“¾æ¥ï¼ˆä¸å¼ºåˆ¶è¦æ±‚.apkåç¼€ï¼Œå› ä¸ºä¸‹è½½åœ°å€å¯èƒ½å¸¦æŸ¥è¯¢å‚æ•°ï¼‰
        # api.kxdw.com/adown/ è¿™ç±»é“¾æ¥æ˜¯å¯ä¿¡çš„ä¸‹è½½åœ°å€ï¼Œç›´æ¥è·³è¿‡æ ¡éªŒ
        if 'api.kxdw.com/adown/' in download_url:
            print(f"   âœ… æ£€æµ‹åˆ°å¯ä¿¡ä¸‹è½½åœ°å€ (api.kxdw.com/adown/)ï¼Œè·³è¿‡æ ¡éªŒ")
        else:
            # åˆ¤æ–­æ˜¯å¦ä¸ºHTMLé¡µé¢çš„è§„åˆ™ï¼š
            print(f"   ğŸ” æ£€æŸ¥é“¾æ¥æ˜¯å¦ä¸ºHTMLé¡µé¢...")
            is_html = False
            html_reasons = []
            
            if download_url.endswith('.html'):
                is_html = True
                html_reasons.append("URLä»¥.htmlç»“å°¾")
            elif download_url.endswith('.htm'):
                is_html = True
                html_reasons.append("URLä»¥.htmç»“å°¾")
            elif 'kxdw.com/android/' in download_url:
                is_html = True
                html_reasons.append("URLåŒ…å«è¯¦æƒ…é¡µè·¯å¾„(kxdw.com/android/)")
            elif download_url.startswith('javascript:'):
                is_html = True
                html_reasons.append("URLæ˜¯javascripté“¾æ¥")
            elif download_url.startswith('#'):
                is_html = True
                html_reasons.append("URLæ˜¯é”šç‚¹é“¾æ¥")
            
            if is_html:
                print(f"   âŒ é“¾æ¥è¢«åˆ¤æ–­ä¸ºHTMLé¡µé¢ï¼ŒåŸå› : {', '.join(html_reasons)}")
                print(f"   ğŸ“‹ é“¾æ¥: {download_url[:100]}...")
                # é“¾æ¥æ— æ•ˆï¼Œæ›´æ–°æ ‡è®°å¹¶è¿”å›ï¼ˆä¸ä¼šåˆ›å»ºæ–‡ä»¶å¤¹æˆ–ä¸‹è½½ï¼‰
                game['æ˜¯å¦æœ‰å®‰å“ä¸‹è½½é“¾æ¥'] = 'å¦'
                self._save_csv()
                return False
            else:
                print(f"   âœ… é“¾æ¥é€šè¿‡åˆæ­¥æ£€æŸ¥ï¼ˆä¸æ˜¯æ˜æ˜¾çš„HTMLé¡µé¢ï¼‰")
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆä¼˜å…ˆä½¿ç”¨é¡µé¢è§£æçš„å¤§å°ï¼Œå¦‚æœæ— æ³•è§£æåˆ™é€šè¿‡HEADè¯·æ±‚è·å–ï¼‰
        size_mb = 0.0
        size_str = detail_info.get('size', '')
        if size_str:
            size_mb = self._parse_size_to_mb(size_str)
            if size_mb > 1024:
                print(f"â­ï¸  æ–‡ä»¶å¤§å° {size_mb:.2f}MB ({size_mb/1024:.2f}G) è¶…è¿‡1Gï¼Œè·³è¿‡å¹¶æ ‡è®°ä¸ºå·²ä¸‹è½½")
                game['æ˜¯å¦å·²ä¸‹è½½'] = 'æ˜¯'
                self._save_csv()
                return False
        
        # å¦‚æœæ— æ³•ä»é¡µé¢è§£æå¤§å°ï¼Œé€šè¿‡HEADè¯·æ±‚è·å–æ–‡ä»¶å¤§å°
        if size_mb == 0.0:
            print(f"   ğŸ” é¡µé¢æœªæ˜¾ç¤ºæ–‡ä»¶å¤§å°ï¼Œé€šè¿‡HEADè¯·æ±‚æ£€æŸ¥...")
            try:
                # ä½¿ç”¨éšæœºUser-Agentå’Œå®Œæ•´è¯·æ±‚å¤´
                headers = self._get_browser_headers(referer='https://www.kxdw.com/', is_download=True)
                # è·å–ä»£ç†
                proxy = self._get_next_proxy()
                proxies = self._format_proxy_for_requests(proxy)
                
                head_response = requests.head(download_url, headers=headers, proxies=proxies, timeout=10, allow_redirects=True)
                
                # æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘åˆ°æœ¬åœ°åœ°å€
                if '127.0.0.1' in head_response.url or 'localhost' in head_response.url:
                    print(f"   âš ï¸  æ£€æµ‹åˆ°é‡å®šå‘åˆ°æœ¬åœ°åœ°å€: {head_response.url}")
                    return False
                
                content_length = head_response.headers.get('Content-Length')
                if content_length:
                    size_bytes = int(content_length)
                    size_mb = size_bytes / 1024 / 1024
                    print(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {size_mb:.2f}MB")
                    if size_mb > 1024:
                        print(f"â­ï¸  æ–‡ä»¶å¤§å° {size_mb:.2f}MB ({size_mb/1024:.2f}G) è¶…è¿‡1Gï¼Œè·³è¿‡å¹¶æ ‡è®°ä¸ºå·²ä¸‹è½½")
                        game['æ˜¯å¦å·²ä¸‹è½½'] = 'æ˜¯'
                        self._save_csv()
                        return False
                
                # api.kxdw.com/adown/ è¿™ç±»é“¾æ¥æ˜¯å¯ä¿¡çš„ï¼Œè·³è¿‡Content-Typeæ£€æŸ¥
                if 'api.kxdw.com/adown/' not in download_url:
                    # åŒæ—¶æ£€æŸ¥Content-Type
                    content_type = head_response.headers.get('Content-Type', '').lower()
                    if 'html' in content_type or 'text/html' in content_type:
                        print(f"   âŒ é“¾æ¥æŒ‡å‘HTMLé¡µé¢ï¼Œä¸æ˜¯APKæ–‡ä»¶ï¼Œè·³è¿‡")
                        # é“¾æ¥æ— æ•ˆï¼Œæ›´æ–°æ ‡è®°å¹¶è¿”å›ï¼ˆä¸ä¼šåˆ›å»ºæ–‡ä»¶å¤¹æˆ–ä¸‹è½½ï¼‰
                        game['æ˜¯å¦æœ‰å®‰å“ä¸‹è½½é“¾æ¥'] = 'å¦'
                        self._save_csv()
                        return False
                    elif 'application/vnd.android.package-archive' in content_type or 'application/octet-stream' in content_type:
                        print(f"   âœ… éªŒè¯é€šè¿‡ï¼Œæ˜¯APKæ–‡ä»¶")
                    else:
                        print(f"   âš ï¸  æ–‡ä»¶ç±»å‹: {content_type}ï¼Œç»§ç»­å°è¯•ä¸‹è½½")
                else:
                    print(f"   âœ… å¯ä¿¡ä¸‹è½½åœ°å€ï¼Œè·³è¿‡Content-Typeæ£€æŸ¥")
            except Exception as e:
                print(f"   âš ï¸  éªŒè¯é“¾æ¥å¤±è´¥: {e}ï¼Œç»§ç»­å°è¯•ä¸‹è½½")
        else:
            # å¦‚æœå·²ç»ä»é¡µé¢è·å–åˆ°å¤§å°ï¼ŒåªéªŒè¯Content-Type
            # api.kxdw.com/adown/ è¿™ç±»é“¾æ¥æ˜¯å¯ä¿¡çš„ï¼Œè·³è¿‡Content-Typeæ£€æŸ¥
            if 'api.kxdw.com/adown/' in download_url:
                print(f"   âœ… å¯ä¿¡ä¸‹è½½åœ°å€ï¼Œè·³è¿‡Content-Typeæ£€æŸ¥")
            else:
                print(f"   ğŸ” éªŒè¯ä¸‹è½½é“¾æ¥...")
                try:
                    # ä½¿ç”¨éšæœºUser-Agentå’Œå®Œæ•´è¯·æ±‚å¤´
                    headers = self._get_browser_headers(referer='https://www.kxdw.com/', is_download=True)
                    # è·å–ä»£ç†
                    proxy = self._get_next_proxy()
                    proxies = self._format_proxy_for_requests(proxy)
                    
                    head_response = requests.head(download_url, headers=headers, proxies=proxies, timeout=10, allow_redirects=True)
                    
                    # æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘åˆ°æœ¬åœ°åœ°å€
                    if '127.0.0.1' in head_response.url or 'localhost' in head_response.url:
                        print(f"   âš ï¸  æ£€æµ‹åˆ°é‡å®šå‘åˆ°æœ¬åœ°åœ°å€: {head_response.url}")
                        return False
                    content_type = head_response.headers.get('Content-Type', '').lower()
                    content_length = head_response.headers.get('Content-Length', '')
                    final_url = head_response.url  # è·å–é‡å®šå‘åçš„æœ€ç»ˆURL
                    
                    print(f"   ğŸ“‹ å“åº”å¤´ä¿¡æ¯:")
                    print(f"      Content-Type: {content_type}")
                    print(f"      Content-Length: {content_length} å­—èŠ‚" if content_length else "      Content-Length: æœªæä¾›")
                    print(f"      æœ€ç»ˆURL: {final_url[:100]}...")
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºHTMLé¡µé¢
                    if 'html' in content_type or 'text/html' in content_type:
                        print(f"   âŒ é“¾æ¥æŒ‡å‘HTMLé¡µé¢ï¼ˆContent-Type: {content_type}ï¼‰ï¼Œä¸æ˜¯APKæ–‡ä»¶ï¼Œè·³è¿‡")
                        # é“¾æ¥æ— æ•ˆï¼Œæ›´æ–°æ ‡è®°å¹¶è¿”å›ï¼ˆä¸ä¼šåˆ›å»ºæ–‡ä»¶å¤¹æˆ–ä¸‹è½½ï¼‰
                        game['æ˜¯å¦æœ‰å®‰å“ä¸‹è½½é“¾æ¥'] = 'å¦'
                        self._save_csv()
                        return False
                    elif 'application/vnd.android.package-archive' in content_type:
                        print(f"   âœ… éªŒè¯é€šè¿‡ï¼Œæ˜¯APKæ–‡ä»¶ï¼ˆContent-Type: {content_type}ï¼‰")
                    elif 'application/octet-stream' in content_type:
                        print(f"   âœ… éªŒè¯é€šè¿‡ï¼Œæ˜¯äºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆContent-Type: {content_type}ï¼‰ï¼Œå¯èƒ½æ˜¯APK")
                    else:
                        print(f"   âš ï¸  æ–‡ä»¶ç±»å‹: {content_type}ï¼Œç»§ç»­å°è¯•ä¸‹è½½")
                except Exception as e:
                    print(f"   âš ï¸  éªŒè¯é“¾æ¥å¤±è´¥: {e}ï¼Œç»§ç»­å°è¯•ä¸‹è½½")
        
        # åªæœ‰è·å–åˆ°æœ‰æ•ˆçš„ä¸‹è½½é“¾æ¥åï¼Œæ‰ä¼šæ‰§è¡Œåç»­çš„åˆ›å»ºæ–‡ä»¶å¤¹å’Œä¸‹è½½æ“ä½œ
        print(f"ğŸ“¥ ä¸‹è½½é“¾æ¥: {download_url[:80]}...")
        
        # åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼Œç¡®ä¿å·²ç»æœ‰æœ‰æ•ˆçš„ä¸‹è½½é“¾æ¥ï¼‰
        if not folder_path.exists():
            folder_path.mkdir(parents=True, exist_ok=True)
            # è®¾ç½®æ–‡ä»¶å¤¹çš„åˆ›å»ºæ—¶é—´ä¸ºå½“å‰æ—¶é—´
            current_time = time.time()
            try:
                os.utime(folder_path, (current_time, current_time))
            except Exception as e:
                # å¦‚æœè®¾ç½®æ—¶é—´å¤±è´¥ï¼Œä¸å½±å“åç»­æµç¨‹
                pass
            # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
            create_time_str = datetime.fromtimestamp(current_time).strftime('%Y-%m-%d %H:%M:%S')
            print(f"ğŸ“ å·²åˆ›å»ºæ–‡ä»¶å¤¹: {folder_name} (åˆ›å»ºæ—¶é—´: {create_time_str})")
        
        # ç¡®å®šæ–‡ä»¶å
        # ä»URLè·¯å¾„ä¸­æå–æ‰©å±•åï¼Œå¦‚æœURLä¸­æœ‰.apkï¼ˆå¯èƒ½åœ¨æŸ¥è¯¢å‚æ•°å‰ï¼‰ï¼Œä¹Ÿæå–
        parsed_url = urlparse(download_url)
        file_ext = os.path.splitext(parsed_url.path)[1]
        
        # å¦‚æœè·¯å¾„ä¸­æ²¡æœ‰æ‰©å±•åï¼Œæ£€æŸ¥URLä¸­æ˜¯å¦åŒ…å«.apk
        if not file_ext or file_ext not in ['.apk', '.APK']:
            if '.apk' in download_url.lower():
                # URLä¸­åŒ…å«.apkï¼Œä½¿ç”¨.apkæ‰©å±•å
                file_ext = '.apk'
            else:
                # é»˜è®¤ä½¿ç”¨.apkæ‰©å±•åï¼ˆå› ä¸ºè¿™æ˜¯å®‰å“ä¸‹è½½ï¼‰
                file_ext = '.apk'
        
        file_name = f"{folder_name}{file_ext}"
        save_path = folder_path / file_name
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆä¸è¯¦æƒ…é¡µæ–‡ä»¶å¤§å°æ¯”è¾ƒï¼‰
        if save_path.exists():
            file_size_mb = save_path.stat().st_size / 1024 / 1024
            file_size_bytes = save_path.stat().st_size
            
            # å¦‚æœè¯¦æƒ…é¡µæœ‰æ–‡ä»¶å¤§å°ä¿¡æ¯ï¼Œè¿›è¡Œæ¯”è¾ƒ
            if expected_size_mb > 0:
                expected_size_bytes = int(expected_size_mb * 1024 * 1024)
                # å…è®¸5%çš„è¯¯å·®
                if file_size_bytes >= expected_size_bytes * 0.95:
                    print(f"â­ï¸  æ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å° ({file_size_mb:.2f}MB) >= è¯¦æƒ…é¡µæ–‡ä»¶å¤§å° ({expected_size_mb:.2f}MB)ï¼Œè·³è¿‡ä¸‹è½½")
                else:
                    print(f"âš ï¸  æ–‡ä»¶å·²å­˜åœ¨ä½†å¤§å° ({file_size_mb:.2f}MB) < è¯¦æƒ…é¡µæ–‡ä»¶å¤§å° ({expected_size_mb:.2f}MB)ï¼Œåˆ é™¤æ—§æ–‡ä»¶å¹¶é‡æ–°ä¸‹è½½")
                    # åˆ é™¤æ—§æ–‡ä»¶ï¼Œé‡æ–°ä¸‹è½½
                    try:
                        save_path.unlink()
                        print(f"   ğŸ—‘ï¸  å·²åˆ é™¤æ—§æ–‡ä»¶: {file_name}")
                    except Exception as e:
                        print(f"   âš ï¸  åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
                    # ä¸‹è½½æ–‡ä»¶
                    print(f"â¬‡ï¸  å¼€å§‹ä¸‹è½½: {file_name}")
                    # å¦‚æœå¯ç”¨äº†Chromeï¼Œä¼˜å…ˆä½¿ç”¨Chromeä¸‹è½½ï¼ˆæ›´ç¨³å®šï¼Œé¿å…è¿æ¥ä¸­æ–­ï¼‰
                    if self.use_chrome:
                        if not self._download_with_chrome(download_url, save_path, expected_size_mb):
                            # Chromeä¸‹è½½å¤±è´¥ï¼Œå›é€€åˆ°requestsä¸‹è½½
                            print(f"   âš ï¸  Chromeä¸‹è½½å¤±è´¥ï¼Œåˆ‡æ¢åˆ°requestsä¸‹è½½...")
                            # å¦‚æœè·å–åˆ°äº†çœŸå®ä¸‹è½½åœ°å€ï¼Œä½¿ç”¨çœŸå®åœ°å€ä¸‹è½½
                            final_download_url = self._last_real_download_url if self._last_real_download_url else download_url
                            if self._last_real_download_url:
                                print(f"   ğŸ”„ ä½¿ç”¨çœŸå®ä¸‹è½½åœ°å€: {final_download_url[:80]}...")
                            if not self._download_file(final_download_url, save_path):
                                # ä¸‹è½½å¤±è´¥ï¼Œåˆ é™¤æ–‡ä»¶å¤¹
                                self._cleanup_folder_on_failure(folder_path)
                                return False
                    else:
                        if not self._download_file(download_url, save_path):
                            # ä¸‹è½½å¤±è´¥ï¼Œåˆ é™¤æ–‡ä»¶å¤¹
                            self._cleanup_folder_on_failure(folder_path)
                            return False
            else:
                # å¦‚æœè¯¦æƒ…é¡µæ²¡æœ‰æ–‡ä»¶å¤§å°ä¿¡æ¯ï¼Œä½¿ç”¨åŸæ¥çš„é€»è¾‘ï¼ˆå¤§äº1Mè®¤ä¸ºå·²ä¸‹è½½ï¼‰
                if file_size_mb > 1.0:
                    print(f"â­ï¸  æ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å° {file_size_mb:.2f}MB > 1Mï¼ˆè¯¦æƒ…é¡µæœªæä¾›æ–‡ä»¶å¤§å°ï¼‰ï¼Œè·³è¿‡ä¸‹è½½")
                else:
                    print(f"âš ï¸  æ–‡ä»¶å·²å­˜åœ¨ä½†å¤§å° {file_size_mb:.2f}MB <= 1Mï¼Œå¯èƒ½æ˜¯æ— æ•ˆæ–‡ä»¶ï¼Œé‡æ–°ä¸‹è½½")
                    # åˆ é™¤æ—§æ–‡ä»¶ï¼Œé‡æ–°ä¸‹è½½
                    try:
                        save_path.unlink()
                        print(f"   ğŸ—‘ï¸  å·²åˆ é™¤æ—§æ–‡ä»¶: {file_name}")
                    except Exception as e:
                        print(f"   âš ï¸  åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
                    # ä¸‹è½½æ–‡ä»¶
                    print(f"â¬‡ï¸  å¼€å§‹ä¸‹è½½: {file_name}")
                    # å¦‚æœå¯ç”¨äº†Chromeï¼Œä¼˜å…ˆä½¿ç”¨Chromeä¸‹è½½ï¼ˆæ›´ç¨³å®šï¼Œé¿å…è¿æ¥ä¸­æ–­ï¼‰
                    if self.use_chrome:
                        if not self._download_with_chrome(download_url, save_path, expected_size_mb):
                            # Chromeä¸‹è½½å¤±è´¥ï¼Œå›é€€åˆ°requestsä¸‹è½½
                            print(f"   âš ï¸  Chromeä¸‹è½½å¤±è´¥ï¼Œåˆ‡æ¢åˆ°requestsä¸‹è½½...")
                            # å¦‚æœè·å–åˆ°äº†çœŸå®ä¸‹è½½åœ°å€ï¼Œä½¿ç”¨çœŸå®åœ°å€ä¸‹è½½
                            final_download_url = self._last_real_download_url if self._last_real_download_url else download_url
                            if self._last_real_download_url:
                                print(f"   ğŸ”„ ä½¿ç”¨çœŸå®ä¸‹è½½åœ°å€: {final_download_url[:80]}...")
                            if not self._download_file(final_download_url, save_path):
                                # ä¸‹è½½å¤±è´¥ï¼Œåˆ é™¤æ–‡ä»¶å¤¹
                                self._cleanup_folder_on_failure(folder_path)
                                return False
                    else:
                        if not self._download_file(download_url, save_path):
                            # ä¸‹è½½å¤±è´¥ï¼Œåˆ é™¤æ–‡ä»¶å¤¹
                            self._cleanup_folder_on_failure(folder_path)
                            return False
        else:
            # ä¸‹è½½æ–‡ä»¶
            print(f"â¬‡ï¸  å¼€å§‹ä¸‹è½½: {file_name}")
            # å¦‚æœå¯ç”¨äº†Chromeï¼Œä¼˜å…ˆä½¿ç”¨Chromeä¸‹è½½ï¼ˆæ›´ç¨³å®šï¼Œé¿å…è¿æ¥ä¸­æ–­ï¼‰
            if self.use_chrome:
                if not self._download_with_chrome(download_url, save_path, expected_size_mb):
                    # Chromeä¸‹è½½å¤±è´¥ï¼Œå›é€€åˆ°requestsä¸‹è½½
                    print(f"   âš ï¸  Chromeä¸‹è½½å¤±è´¥ï¼Œåˆ‡æ¢åˆ°requestsä¸‹è½½...")
                    # å¦‚æœè·å–åˆ°äº†çœŸå®ä¸‹è½½åœ°å€ï¼Œä½¿ç”¨çœŸå®åœ°å€ä¸‹è½½
                    final_download_url = self._last_real_download_url if self._last_real_download_url else download_url
                    if self._last_real_download_url:
                        print(f"   ğŸ”„ ä½¿ç”¨çœŸå®ä¸‹è½½åœ°å€: {final_download_url[:80]}...")
                    if not self._download_file(final_download_url, save_path):
                        # ä¸‹è½½å¤±è´¥ï¼Œåˆ é™¤æ–‡ä»¶å¤¹
                        self._cleanup_folder_on_failure(folder_path)
                        return False
            else:
                if not self._download_file(download_url, save_path):
                    # ä¸‹è½½å¤±è´¥ï¼Œåˆ é™¤æ–‡ä»¶å¤¹
                    self._cleanup_folder_on_failure(folder_path)
                    return False
        
        # åˆ›å»ºä¿¡æ¯æ–‡ä»¶
        print(f"ğŸ“ åˆ›å»ºä¿¡æ¯æ–‡ä»¶...")
        self._create_info_files(folder_path)
        
        # æ›´æ–°CSV
        game['æ˜¯å¦å·²ä¸‹è½½'] = 'æ˜¯'
        self._save_csv()
        
        print(f"âœ… å®Œæˆ!")
        return True

    def _create_zip_for_apk(self, apk_path: Path):
        """åœ¨APKæ‰€åœ¨ç›®å½•ç”ŸæˆåŒåZIPæ–‡ä»¶"""
        try:
            if not apk_path or not apk_path.exists():
                return
            if apk_path.suffix.lower() != '.apk':
                return

            zip_path = apk_path.with_suffix('.zip')
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                zipf.write(apk_path, apk_path.name)
            zip_size_mb = zip_path.stat().st_size / 1024 / 1024
            print(f"   ğŸ“¦ å·²ç”ŸæˆZIP: {zip_path.name} ({zip_size_mb:.2f}MB)")
        except Exception as e:
            print(f"   âš ï¸  ç”ŸæˆZIPå¤±è´¥: {apk_path.name if apk_path else 'æœªçŸ¥æ–‡ä»¶'} -> {e}")
            try:
                if apk_path:
                    zip_path = apk_path.with_suffix('.zip')
                    if zip_path.exists():
                        zip_path.unlink()
            except:
                pass
    
    def run(self, start_index: int = 0, limit: Optional[int] = None):
        """è¿è¡Œæ‰¹é‡ä¸‹è½½"""
        print(f"\n{'='*60}")
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡ä¸‹è½½")
        print(f"{'='*60}")
        
        if not self.use_chrome:
            print(f"âš ï¸  è­¦å‘Š: æœªå¯ç”¨Chromeæ¨¡å¼ï¼")
            print(f"   å»ºè®®ä½¿ç”¨ --chrome å‚æ•°æ¥æ¨¡æ‹Ÿäººç±»æ“ä½œï¼Œé¿å…è¢«æ‹¦æˆª")
            print(f"   å½“å‰å°†ä½¿ç”¨requestsæ–¹å¼ï¼Œå¯èƒ½è¢«ç½‘ç«™æ‹¦æˆª")
            print(f"{'='*60}\n")
        else:
            print(f"âœ… Chromeæ¨¡å¼å·²å¯ç”¨ - å°†æ¨¡æ‹Ÿäººç±»æ“ä½œ")
            print(f"{'='*60}\n")
        
        print(f"æ€»æ¸¸æˆæ•°: {len(self.games)}")
        print(f"èµ·å§‹ä½ç½®: {start_index}")
        if limit:
            print(f"å¤„ç†æ•°é‡: {limit}")
        print(f"{'='*60}\n")
        
        end_index = len(self.games)
        if limit:
            end_index = min(start_index + limit, len(self.games))
        
        success_count = 0
        skip_count = 0
        fail_count = 0
        
        for i in range(start_index, end_index):
            game = self.games[i]
            
            # å¦‚æœå·²ä¸‹è½½ï¼Œè·³è¿‡
            if game.get('æ˜¯å¦å·²ä¸‹è½½') == 'æ˜¯':
                skip_count += 1
                continue
            
            try:
                if self.process_game(game, i + 1):
                    success_count += 1
                else:
                    fail_count += 1
                
                # é¿å…è¯·æ±‚è¿‡å¿«
                wait_time = 3 if self.use_chrome else 2
                time.sleep(wait_time)
                
            except KeyboardInterrupt:
                print(f"\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
                break
            except Exception as e:
                print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
                fail_count += 1
                continue
        
        # æ¸…ç†Chromeèµ„æºï¼Œé¿å…åå°çº¿ç¨‹JSONè§£æé”™è¯¯
        if self.tab:
            try:
                # å…ˆç§»é™¤æ‰€æœ‰äº‹ä»¶ç›‘å¬å™¨
                try:
                    if hasattr(self.tab, 'Page'):
                        self.tab.Page.downloadWillBegin = None
                except:
                    pass
                # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œè®©æ¥æ”¶å¾ªç¯å¤„ç†å®Œå½“å‰æ¶ˆæ¯
                time.sleep(0.1)
                # åœæ­¢tabï¼ˆè¿™ä¼šåœæ­¢æ¥æ”¶å¾ªç¯ï¼‰
                self.tab.stop()
                if self.browser:
                    self.browser.close_tab(self.tab)
            except:
                pass
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š å¤„ç†å®Œæˆç»Ÿè®¡")
        print(f"{'='*60}")
        print(f"æˆåŠŸ: {success_count}")
        print(f"è·³è¿‡: {skip_count}")
        print(f"å¤±è´¥: {fail_count}")
        print(f"{'='*60}\n")


def test_download_url(url: str):
    """æµ‹è¯•ä¸‹è½½é“¾æ¥ï¼ŒæŸ¥çœ‹é‡å®šå‘å’Œå“åº”ä¿¡æ¯"""
    if not requests:
        print("âŒ è¯·å®‰è£… requests: pip3 install requests")
        return
    
    print(f"\n{'='*60}")
    print(f"ğŸ” æµ‹è¯•ä¸‹è½½é“¾æ¥")
    print(f"{'='*60}")
    print(f"URL: {url}\n")
    
    try:
        # ä½¿ç”¨éšæœºUser-Agentå’Œå®Œæ•´è¯·æ±‚å¤´ï¼ˆæµ‹è¯•å‡½æ•°ï¼Œä½¿ç”¨ç®€å•çš„headersï¼‰
        headers = {
            'User-Agent': random.choice(KXDWDownloader.USER_AGENTS),
            'Referer': 'https://www.kxdw.com/',
            'Accept': '*/*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8'
        }
        
        # ä½¿ç”¨Sessionæ¥è·Ÿè¸ªé‡å®šå‘é“¾
        session = requests.Session()
        session.max_redirects = 10
        
        print("ğŸ“‹ æ­¥éª¤1: å‘é€HEADè¯·æ±‚æŸ¥çœ‹é‡å®šå‘...")
        head_response = session.head(url, headers=headers, timeout=30, allow_redirects=True)
        
        redirect_history = head_response.history
        final_url = head_response.url
        
        print(f"   åˆå§‹URL: {url}")
        if redirect_history:
            print(f"   âœ… å‘ç° {len(redirect_history)} æ¬¡é‡å®šå‘:")
            for i, resp in enumerate(redirect_history, 1):
                redirect_url = resp.headers.get('Location', 'N/A')
                print(f"      {i}. {resp.status_code} {resp.reason}")
                print(f"         -> {redirect_url[:120]}")
            print(f"   æœ€ç»ˆURL: {final_url}")
        else:
            print(f"   â„¹ï¸  æ— é‡å®šå‘ï¼Œç›´æ¥è®¿é—®")
        
        print(f"\nğŸ“‹ æ­¥éª¤2: æŸ¥çœ‹å“åº”å¤´ä¿¡æ¯...")
        print(f"   Status Code: {head_response.status_code}")
        print(f"   Content-Type: {head_response.headers.get('Content-Type', 'N/A')}")
        print(f"   Content-Length: {head_response.headers.get('Content-Length', 'N/A')} å­—èŠ‚")
        print(f"   Content-Disposition: {head_response.headers.get('Content-Disposition', 'N/A')}")
        print(f"   Location: {head_response.headers.get('Location', 'N/A')}")
        
        print(f"\nğŸ“‹ æ­¥éª¤3: å‘é€GETè¯·æ±‚æŸ¥çœ‹å®é™…å“åº”...")
        get_response = session.get(url, headers=headers, timeout=30, allow_redirects=True, stream=True)
        
        print(f"   æœ€ç»ˆURL: {get_response.url}")
        print(f"   Status Code: {get_response.status_code}")
        print(f"   Content-Type: {get_response.headers.get('Content-Type', 'N/A')}")
        print(f"   Content-Length: {get_response.headers.get('Content-Length', 'N/A')} å­—èŠ‚")
        print(f"   Content-Disposition: {get_response.headers.get('Content-Disposition', 'N/A')}")
        
        # è¯»å–å‰å‡ ä¸ªå­—èŠ‚æŸ¥çœ‹æ–‡ä»¶å¤´
        if get_response.status_code == 200:
            content_preview = get_response.content[:20]
            print(f"\nğŸ“‹ æ­¥éª¤4: æŸ¥çœ‹æ–‡ä»¶å¤´ï¼ˆå‰20å­—èŠ‚ï¼‰...")
            print(f"   åå…­è¿›åˆ¶: {content_preview.hex()}")
            print(f"   ASCII: {repr(content_preview)}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯APK/ZIPæ ¼å¼
            if content_preview[:2] == b'PK':
                print(f"   âœ… æ–‡ä»¶å¤´æ˜¯PKï¼ˆZIP/APKæ ¼å¼ï¼‰")
            elif content_preview.startswith(b'<!DOCTYPE') or content_preview.startswith(b'<html'):
                print(f"   âš ï¸  æ–‡ä»¶å¤´æ˜¯HTMLæ ¼å¼")
            else:
                print(f"   â„¹ï¸  æ–‡ä»¶å¤´æ ¼å¼: {content_preview[:4]}")
        
        # å°è¯•ä½¿ç”¨Chromeè®¿é—®
        if pychrome:
            print(f"\nğŸ“‹ æ­¥éª¤5: ä½¿ç”¨Chromeæ¨¡æ‹Ÿè®¿é—®...")
            try:
                browser = pychrome.Browser(url="http://127.0.0.1:9222")
                # åˆ›å»ºæ–°æ ‡ç­¾é¡µ
                tab = browser.new_tab()
                tab.start()
                
                # ç›‘å¬ä¸‹è½½äº‹ä»¶
                download_info = {'triggered': False, 'url': None}
                
                def on_download_will_begin(**kwargs):
                    download_info['triggered'] = True
                    download_info['url'] = kwargs.get('url', 'N/A')
                    print(f"   ğŸ“¥ æ£€æµ‹åˆ°ä¸‹è½½äº‹ä»¶!")
                    print(f"      ä¸‹è½½URL: {kwargs.get('url', 'N/A')[:100]}")
                    print(f"      å»ºè®®æ–‡ä»¶å: {kwargs.get('suggestedFilename', 'N/A')}")
                
                tab.Page.downloadWillBegin = on_download_will_begin
                
                # å¯ç”¨PageåŸŸ
                tab.Page.enable()
                
                print(f"   ğŸŒ å¯¼èˆªåˆ°: {url}")
                tab.Page.navigate(url=url)
                
                # ç­‰å¾…é¡µé¢åŠ è½½å’Œå¯èƒ½çš„ä¸‹è½½
                print(f"   â³ ç­‰å¾…å“åº”ï¼ˆæœ€å¤š10ç§’ï¼‰...")
                for i in range(20):  # ç­‰å¾…æœ€å¤š10ç§’
                    time.sleep(0.5)
                    if download_info['triggered']:
                        break
                    
                    # æ£€æŸ¥å½“å‰é¡µé¢çŠ¶æ€
                    try:
                        result = tab.Runtime.evaluate(expression="""
                            (function() {
                                return {
                                    url: window.location.href,
                                    readyState: document.readyState
                                };
                            })();
                        """, returnByValue=True)
                        current_url = result.get("result", {}).get("value", {}).get("url", "")
                        if current_url and current_url != "about:blank" and url not in current_url:
                            print(f"   ğŸ”„ æ£€æµ‹åˆ°é‡å®šå‘: {current_url[:100]}")
                    except:
                        pass
                
                if download_info['triggered']:
                    print(f"   âœ… ç¡®è®¤ï¼šChromeä¼šè§¦å‘ä¸‹è½½")
                else:
                    # æ£€æŸ¥æœ€ç»ˆé¡µé¢çŠ¶æ€
                    try:
                        result = tab.Runtime.evaluate(expression="""
                            (function() {
                                return {
                                    url: window.location.href,
                                    title: document.title,
                                    bodyText: document.body ? document.body.innerText.substring(0, 200) : 'No body',
                                    hasIframe: document.querySelectorAll('iframe').length > 0
                                };
                            })();
                        """, returnByValue=True)
                        page_info = result.get("result", {}).get("value", {})
                        print(f"   æœ€ç»ˆé¡µé¢URL: {page_info.get('url', 'N/A')[:100]}")
                        print(f"   é¡µé¢æ ‡é¢˜: {page_info.get('title', 'N/A')}")
                        print(f"   é¡µé¢å†…å®¹é¢„è§ˆ: {page_info.get('bodyText', 'N/A')[:100]}")
                        if page_info.get('hasIframe'):
                            print(f"   âš ï¸  é¡µé¢åŒ…å«iframeï¼Œå¯èƒ½éœ€è¦JavaScriptè§¦å‘ä¸‹è½½")
                    except Exception as e:
                        print(f"   âš ï¸  æ— æ³•è·å–é¡µé¢ä¿¡æ¯: {e}")
                
                # æ¸…ç†èµ„æºï¼Œé¿å…åå°çº¿ç¨‹JSONè§£æé”™è¯¯
                try:
                    # ç§»é™¤äº‹ä»¶ç›‘å¬å™¨
                    tab.Page.downloadWillBegin = None
                except:
                    pass
                # ç­‰å¾…æ¥æ”¶å¾ªç¯å¤„ç†å®Œ
                time.sleep(0.1)
                # åœæ­¢tab
                tab.stop()
                browser.close_tab(tab)
                print(f"   âœ… Chromeæµ‹è¯•å®Œæˆ")
            except Exception as e:
                print(f"   âš ï¸  Chromeè®¿é—®å¤±è´¥: {e}")
                print(f"   ğŸ’¡ æç¤º: è¯·ç¡®ä¿Chromeå·²å¯åŠ¨å¹¶å¼€å¯è¿œç¨‹è°ƒè¯•ç«¯å£9222")
                import traceback
                traceback.print_exc()
        else:
            print(f"\nğŸ“‹ æ­¥éª¤5: è·³è¿‡Chromeæµ‹è¯•ï¼ˆæœªå®‰è£…pychromeï¼‰")
        
        print(f"\n{'='*60}\n")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def main():
    parser = argparse.ArgumentParser(
        description="å¼€å¿ƒç”µç©æ¸¸æˆä¸‹è½½å·¥å…· - æ ¹æ®CSVæ–‡ä»¶ä¸‹è½½æ¸¸æˆ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³•ï¼ˆæ¨èä½¿ç”¨Chromeæ¨¡å¼ï¼‰
  python3 kxdw_downloader.py games_50_pages.csv --chrome
  
  # æŒ‡å®šChromeç«¯å£
  python3 kxdw_downloader.py games_50_pages.csv --chrome -p 9222
  
  # å…¶ä»–å‚æ•°
  python3 kxdw_downloader.py games_50_pages.csv --chrome --start 10 --limit 5
  
  # æµ‹è¯•ä¸‹è½½é“¾æ¥
  python3 kxdw_downloader.py --test-url "https://api.kxdw.com/adown/154551/"
  
  # ä½¿ç”¨ä»£ç†ï¼ˆä»æ–‡ä»¶ï¼‰
  python3 kxdw_downloader.py games_50_pages.csv --chrome --proxy-file proxies.txt
  
  # ä½¿ç”¨å•ä¸ªä»£ç†
  python3 kxdw_downloader.py games_50_pages.csv --chrome --proxy http://127.0.0.1:7890
        """
    )
    
    parser.add_argument("csv_file", nargs="?", help="CSVæ–‡ä»¶è·¯å¾„")
    parser.add_argument("-d", "--dir", default="./downloads", help="ä¸‹è½½ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤: ./downloadsï¼‰")
    parser.add_argument("--start", type=int, default=0, help="èµ·å§‹è¡Œå·ï¼ˆä»0å¼€å§‹ï¼Œé»˜è®¤0ï¼‰")
    parser.add_argument("--limit", type=int, help="å¤„ç†æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤å¤„ç†å…¨éƒ¨ï¼‰")
    parser.add_argument("--chrome", action="store_true", help="ä½¿ç”¨Chrome DevTools Protocolï¼ˆé¿å…éªŒè¯ç ï¼‰")
    parser.add_argument("-p", "--port", default="9222", help="Chromeè°ƒè¯•ç«¯å£ï¼ˆé»˜è®¤9222ï¼‰")
    parser.add_argument("--test-url", help="æµ‹è¯•ä¸‹è½½é“¾æ¥ï¼ŒæŸ¥çœ‹é‡å®šå‘å’Œå“åº”ä¿¡æ¯")
    parser.add_argument("--proxy-file", help="ä»£ç†æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªä»£ç†åœ°å€ï¼‰")
    parser.add_argument("--proxy", help="å•ä¸ªä»£ç†åœ°å€ï¼ˆå¦‚: http://127.0.0.1:7890ï¼‰")
    
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šäº†--test-urlï¼Œç›´æ¥æµ‹è¯•é“¾æ¥
    if args.test_url:
        test_download_url(args.test_url)
        return 0
    
    if not args.csv_file:
        parser.error("éœ€è¦æä¾›CSVæ–‡ä»¶è·¯å¾„ï¼Œæˆ–ä½¿ç”¨ --test-url æµ‹è¯•é“¾æ¥")
    
    try:
        downloader = KXDWDownloader(
            args.csv_file,
            args.dir,
            use_chrome=args.chrome,
            chrome_debug_url=f"http://127.0.0.1:{args.port}",
            proxy_file=args.proxy_file,
            proxy=args.proxy
        )
        downloader.run(start_index=args.start, limit=args.limit)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())

