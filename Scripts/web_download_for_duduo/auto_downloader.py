#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç½‘é¡µè‡ªåŠ¨ä¸‹è½½å·¥å…· - åŸºäº Chrome DevTools Protocol (CDP)
ç›´æ¥ä½¿ç”¨ Chrome è°ƒè¯•åè®®æ§åˆ¶æµè§ˆå™¨ï¼Œè§£æç½‘é¡µå¹¶è‡ªåŠ¨ä¸‹è½½æ–‡ä»¶

ä½¿ç”¨å‰å‡†å¤‡:
    1. å®‰è£…ä¾èµ–: pip3 install pychrome requests websocket-client
    2. å¯åŠ¨ Chrome (å¼€å¯è°ƒè¯•ç«¯å£):
       Mac: /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222
       Windows: chrome.exe --remote-debugging-port=9222
       
ç”¨æ³•:
    python3 auto_downloader.py <ç½‘é¡µURL>
    python3 auto_downloader.py https://www.ddooo.com/softdown/12345.html
    python3 auto_downloader.py -a https://www.ddooo.com/  # ä»…åˆ†æé¡µé¢
"""

import argparse
import json
import os
import re
import time
import base64
import subprocess
import platform
import csv
from pathlib import Path
from urllib.parse import urlparse, unquote, urljoin

try:
    import pychrome
except ImportError:
    pychrome = None

try:
    import requests
except ImportError:
    requests = None


class CDPDownloader:
    """åŸºäº Chrome DevTools Protocol çš„ç½‘é¡µä¸‹è½½å·¥å…·"""
    
    def __init__(self, debug_url: str = "http://127.0.0.1:9222", download_dir: str = "./downloads"):
        self.debug_url = debug_url
        self.download_dir = Path(download_dir).absolute()
        self.download_dir.mkdir(parents=True, exist_ok=True)
        
        self.browser = None
        self.tab = None
        self.downloaded_files = []
        self.download_urls = []  # æ”¶é›†åˆ°çš„ä¸‹è½½é“¾æ¥
        
    def connect(self) -> bool:
        """è¿æ¥åˆ° Chrome è°ƒè¯•ç«¯å£"""
        if not pychrome:
            print("âŒ è¯·å…ˆå®‰è£… pychrome: pip3 install pychrome")
            return False
            
        try:
            self.browser = pychrome.Browser(url=self.debug_url)
            print(f"âœ… å·²è¿æ¥åˆ° Chrome: {self.debug_url}")
            return True
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ° Chrome è°ƒè¯•ç«¯å£: {e}")
            print("\nè¯·å…ˆå¯åŠ¨ Chrome å¹¶å¼€å¯è°ƒè¯•ç«¯å£:")
            self._print_chrome_launch_command()
            return False
    
    def _print_chrome_launch_command(self):
        """æ‰“å°å¯åŠ¨ Chrome çš„å‘½ä»¤"""
        system = platform.system()
        if system == "Darwin":  # macOS
            print('   /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222')
        elif system == "Windows":
            print('   chrome.exe --remote-debugging-port=9222')
        else:  # Linux
            print('   google-chrome --remote-debugging-port=9222')
    
    def new_tab(self, url: str = None):
        """åˆ›å»ºæˆ–è·å–æ ‡ç­¾é¡µ"""
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                # å°è¯•è·å–ç°æœ‰æ ‡ç­¾é¡µï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºæ–°çš„
                tabs = self.browser.list_tab()
                if tabs:
                    self.tab = tabs[0]
                    print(f"ğŸ“‘ ä½¿ç”¨ç°æœ‰æ ‡ç­¾é¡µ")
                else:
                    self.tab = self.browser.new_tab()
                    print(f"ğŸ“‘ åˆ›å»ºæ–°æ ‡ç­¾é¡µ")
                break
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"â³ é‡è¯•è¿æ¥... ({attempt + 1}/{max_retries})")
                    time.sleep(2)
                else:
                    raise e
        
        # å¯ç”¨å¿…è¦çš„åŸŸ
        self.tab.start()
        self.tab.Network.enable()
        self.tab.Page.enable()
        self.tab.DOM.enable()
        self.tab.Runtime.enable()
        
        # è®¾ç½®ä¸‹è½½è¡Œä¸º
        try:
            self.tab.Page.setDownloadBehavior(
                behavior="allow",
                downloadPath=str(self.download_dir)
            )
        except Exception as e:
            print(f"âš ï¸  è®¾ç½®ä¸‹è½½è¡Œä¸ºå¤±è´¥: {e}")
        
        # ç›‘å¬ç½‘ç»œè¯·æ±‚
        self.tab.Network.responseReceived = self._on_response_received
        self.tab.Network.requestWillBeSent = self._on_request_will_be_sent
        self.tab.Page.downloadWillBegin = self._on_download_will_begin
        self.tab.Page.downloadProgress = self._on_download_progress
        
        if url:
            self.navigate(url)
    
    def _on_request_will_be_sent(self, **kwargs):
        """ç›‘å¬è¯·æ±‚å‘é€äº‹ä»¶"""
        request = kwargs.get("request", {})
        url = request.get("url", "")
        
        # æ£€æµ‹ä¸‹è½½é“¾æ¥
        if self._is_download_url(url):
            self.download_urls.append(url)
    
    def _on_response_received(self, **kwargs):
        """ç›‘å¬å“åº”æ¥æ”¶äº‹ä»¶"""
        response = kwargs.get("response", {})
        url = response.get("url", "")
        headers = response.get("headers", {})
        
        # æ£€æŸ¥ Content-Disposition å¤´ï¼ˆè¡¨æ˜æ˜¯ä¸‹è½½ï¼‰
        content_disposition = headers.get("Content-Disposition", "")
        if "attachment" in content_disposition.lower():
            print(f"ğŸ“¥ æ£€æµ‹åˆ°ä¸‹è½½: {url}")
            self.download_urls.append(url)
    
    def _on_download_will_begin(self, **kwargs):
        """ä¸‹è½½å¼€å§‹äº‹ä»¶"""
        url = kwargs.get("url", "")
        suggested_filename = kwargs.get("suggestedFilename", "")
        print(f"â¬‡ï¸  å¼€å§‹ä¸‹è½½: {suggested_filename}")
        print(f"   URL: {url[:80]}...")
    
    def _on_download_progress(self, **kwargs):
        """ä¸‹è½½è¿›åº¦äº‹ä»¶"""
        state = kwargs.get("state", "")
        guid = kwargs.get("guid", "")
        
        if state == "completed":
            print(f"âœ… ä¸‹è½½å®Œæˆ!")
            self.downloaded_files.append(guid)
        elif state == "canceled":
            print(f"âŒ ä¸‹è½½å–æ¶ˆ")
    
    def _is_download_url(self, url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºä¸‹è½½é“¾æ¥"""
        url_lower = url.lower()
        
        # æ’é™¤çš„URLæ¨¡å¼ï¼ˆç»Ÿè®¡ã€å¹¿å‘Šç­‰ï¼‰
        exclude_patterns = [
            r'cnzz\.com', r'baidu\.com/s\?', r'stat\.', r'analytics',
            r'google-analytics', r'\.js$', r'\.css$', r'\.png$', r'\.jpg$',
            r'\.gif$', r'qrcode', r'favicon'
        ]
        if any(re.search(p, url_lower) for p in exclude_patterns):
            return False
        
        # çœŸå®ä¸‹è½½é“¾æ¥æ¨¡å¼
        download_patterns = [
            r'\.exe$', r'\.zip$', r'\.rar$', r'\.7z$',
            r'\.dmg$', r'\.pkg$', r'\.apk$', r'\.msi$',
            r'\.tar\.gz$', r'\.deb$', r'\.rpm$',
            r'api\.ddooo\.com/down/',  # å¤šå¤šè½¯ä»¶ç«™çš„çœŸå®ä¸‹è½½é“¾æ¥
            r'/down/\d+',  # é€šç”¨ä¸‹è½½é“¾æ¥æ ¼å¼
            r'downfile',
        ]
        return any(re.search(p, url_lower) for p in download_patterns)
    
    def navigate(self, url: str, wait_time: float = 3.0):
        """å¯¼èˆªåˆ°æŒ‡å®šURL"""
        print(f"ğŸŒ æ­£åœ¨è®¿é—®: {url}")
        self.tab.Page.navigate(url=url)
        
        # ç­‰å¾…é¡µé¢åŠ è½½
        time.sleep(wait_time)
        
        # ç­‰å¾… load äº‹ä»¶
        try:
            self.tab.wait(timeout=10)
        except:
            pass
    
    def get_page_info(self) -> dict:
        """è·å–é¡µé¢åŸºæœ¬ä¿¡æ¯"""
        # è·å–æ ‡é¢˜
        title_result = self.tab.Runtime.evaluate(expression="document.title")
        title = title_result.get("result", {}).get("value", "")
        
        # è·å–URL
        url_result = self.tab.Runtime.evaluate(expression="window.location.href")
        current_url = url_result.get("result", {}).get("value", "")
        
        return {
            "title": title,
            "url": current_url
        }
    
    def find_download_links(self) -> list:
        """æŸ¥æ‰¾é¡µé¢ä¸­çš„æ‰€æœ‰ä¸‹è½½é“¾æ¥"""
        # JavaScript ä»£ç ï¼šæŸ¥æ‰¾æ‰€æœ‰å¯èƒ½çš„ä¸‹è½½é“¾æ¥
        js_code = """
        (function() {
            const links = [];
            const allLinks = document.querySelectorAll('a');
            
            // æ’é™¤çš„é“¾æ¥æ¨¡å¼
            const excludePatterns = [
                /cnzz\\.com/i, /baidu\\.com\\/s\\?/i, /stat\\./i, 
                /analytics/i, /\\.js$/i, /\\.css$/i, /qrcode/i
            ];
            
            // æ’é™¤çš„æ–‡å­—ï¼ˆå¯¼èˆªé“¾æ¥ï¼‰
            const excludeTexts = ['MACä¸‹è½½', 'è‹¹æœä¸‹è½½', 'å®‰å“ä¸‹è½½', 'iPhone', 'iPad', 'ä¸‹è½½å¸®åŠ©'];
            
            allLinks.forEach(link => {
                const href = link.href || '';
                const text = (link.innerText || link.textContent || '').trim();
                const className = link.className || '';
                
                // æ’é™¤å¯¼èˆªé“¾æ¥å’Œç»Ÿè®¡é“¾æ¥
                if (excludePatterns.some(p => p.test(href))) return;
                if (excludeTexts.some(t => text === t || text === t + '/')) return;
                
                // æ£€æŸ¥æ˜¯å¦ä¸ºçœŸå®ä¸‹è½½é“¾æ¥
                const isRealDownload = 
                    href.match(/\\.(exe|zip|rar|7z|dmg|pkg|apk|msi)$/i) ||
                    href.match(/api\\.ddooo\\.com\\/down\\//i) ||
                    href.match(/\\/down\\/\\d+/i) ||
                    href.includes('downfile') ||
                    (text.includes('ä¸‹è½½') && href.match(/down/i) && !href.match(/softdown\\.htm/i));
                
                if (isRealDownload && href) {
                    links.push({
                        href: href,
                        text: text.substring(0, 50),
                        className: className,
                        priority: href.match(/api\\.ddooo\\.com\\/down\\//i) ? 1 : 
                                  href.match(/\\.(exe|zip|rar|apk)$/i) ? 2 : 3
                    });
                }
            });
            
            // æŒ‰ä¼˜å…ˆçº§æ’åº
            links.sort((a, b) => a.priority - b.priority);
            
            return links;
        })();
        """
        
        result = self.tab.Runtime.evaluate(expression=js_code, returnByValue=True)
        links = result.get("result", {}).get("value", [])
        
        return links
    
    def find_software_info(self) -> dict:
        """æå–è½¯ä»¶ä¿¡æ¯ï¼ˆé’ˆå¯¹è½¯ä»¶ä¸‹è½½ç«™ï¼‰"""
        js_code = """
        (function() {
            const info = {};
            
            // å°è¯•è·å–è½¯ä»¶åç§°
            const h1 = document.querySelector('h1');
            if (h1) info.name = h1.innerText.trim();
            
            // å°è¯•è·å–ç‰ˆæœ¬
            const versionEl = document.querySelector('[class*="version"], .ver, .soft-version');
            if (versionEl) info.version = versionEl.innerText.trim();
            
            // å°è¯•è·å–æ–‡ä»¶å¤§å°
            const sizeEl = document.querySelector('[class*="size"], .filesize');
            if (sizeEl) info.size = sizeEl.innerText.trim();
            
            // å°è¯•è·å–æ›´æ–°æ—¶é—´
            const dateEl = document.querySelector('[class*="date"], [class*="time"], .update-time');
            if (dateEl) info.date = dateEl.innerText.trim();
            
            return info;
        })();
        """
        
        result = self.tab.Runtime.evaluate(expression=js_code, returnByValue=True)
        info = result.get("result", {}).get("value", {})
        
        return info
    
    def click_element(self, selector: str):
        """ç‚¹å‡»æŒ‡å®šå…ƒç´ """
        js_code = f"""
        (function() {{
            const el = document.querySelector('{selector}');
            if (el) {{
                el.click();
                return true;
            }}
            return false;
        }})();
        """
        
        result = self.tab.Runtime.evaluate(expression=js_code)
        return result.get("result", {}).get("value", False)
    
    def click_first_download_button(self) -> bool:
        """ç‚¹å‡»ç¬¬ä¸€ä¸ªä¸‹è½½æŒ‰é’®"""
        # å¸¸è§çš„ä¸‹è½½æŒ‰é’®é€‰æ‹©å™¨
        selectors = [
            'a[href*="download"]',
            '.download-btn',
            '.down-btn',
            '.downurllist a',
            'a.btn-download',
            'a[class*="download"]',
            'a:contains("ä¸‹è½½")',
        ]
        
        # ä½¿ç”¨ JavaScript æŸ¥æ‰¾å¹¶ç‚¹å‡»
        js_code = """
        (function() {
            // æŸ¥æ‰¾åŒ…å«"ä¸‹è½½"æ–‡å­—çš„é“¾æ¥
            const links = document.querySelectorAll('a');
            for (const link of links) {
                const text = link.innerText || '';
                const href = link.href || '';
                if ((text.includes('ä¸‹è½½') || text.includes('Download')) && 
                    !text.includes('æ‰‹æœº') && !text.includes('å®‰å“')) {
                    link.click();
                    return {success: true, text: text.trim(), href: href};
                }
            }
            
            // æŸ¥æ‰¾ä¸‹è½½æŒ‰é’®ç±»
            const downloadBtns = document.querySelectorAll('.download-btn, .down-btn, [class*="download"] a');
            if (downloadBtns.length > 0) {
                downloadBtns[0].click();
                return {success: true, text: downloadBtns[0].innerText, href: downloadBtns[0].href};
            }
            
            return {success: false};
        })();
        """
        
        result = self.tab.Runtime.evaluate(expression=js_code, returnByValue=True)
        click_result = result.get("result", {}).get("value", {})
        
        if click_result.get("success"):
            print(f"ğŸ–±ï¸  ç‚¹å‡»ä¸‹è½½æŒ‰é’®: {click_result.get('text', '')}")
            return True
        return False
    
    def download_file(self, url: str, filename: str = None):
        """ç›´æ¥ä¸‹è½½æ–‡ä»¶"""
        if not requests:
            print("âŒ è¯·å®‰è£… requests: pip3 install requests")
            return None
        
        if not filename:
            # ä»URLæå–æ–‡ä»¶å
            parsed = urlparse(url)
            filename = unquote(os.path.basename(parsed.path))
            if not filename:
                filename = "download_file"
        
        save_path = self.download_dir / filename
        
        print(f"â¬‡ï¸  ä¸‹è½½æ–‡ä»¶: {filename}")
        print(f"   URL: {url[:80]}...")
        
        try:
            # è·å– cookies
            cookies_result = self.tab.Network.getCookies()
            cookies = {c['name']: c['value'] for c in cookies_result.get('cookies', [])}
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
                'Referer': self.tab.Runtime.evaluate(expression="window.location.href").get("result", {}).get("value", ""),
            }
            
            response = requests.get(url, headers=headers, cookies=cookies, stream=True, timeout=60)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(save_path, 'wb') as f:
                downloaded = 0
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size:
                            percent = (downloaded / total_size) * 100
                            print(f"\r   è¿›åº¦: {percent:.1f}%", end="", flush=True)
            
            print(f"\nâœ… ä¸‹è½½å®Œæˆ: {save_path}")
            self.downloaded_files.append(str(save_path))
            return str(save_path)
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    def analyze_page(self, url: str):
        """åˆ†æé¡µé¢ç»“æ„"""
        if not self.connect():
            return
        
        self.new_tab(url)
        
        print("\n" + "=" * 50)
        print("ğŸ“Š é¡µé¢åˆ†æç»“æœ")
        print("=" * 50)
        
        # é¡µé¢ä¿¡æ¯
        page_info = self.get_page_info()
        print(f"\nğŸ“„ æ ‡é¢˜: {page_info['title']}")
        print(f"ğŸ”— URL: {page_info['url']}")
        
        # è½¯ä»¶ä¿¡æ¯
        soft_info = self.find_software_info()
        if soft_info:
            print(f"\nğŸ“¦ è½¯ä»¶ä¿¡æ¯:")
            for key, value in soft_info.items():
                print(f"   {key}: {value}")
        
        # ä¸‹è½½é“¾æ¥
        links = self.find_download_links()
        print(f"\nğŸ” æ‰¾åˆ° {len(links)} ä¸ªä¸‹è½½é“¾æ¥:")
        for i, link in enumerate(links[:10], 1):
            print(f"   {i}. [{link['text']}]")
            print(f"      -> {link['href'][:80]}...")
        
        # ç½‘ç»œè¯·æ±‚ä¸­æ£€æµ‹åˆ°çš„ä¸‹è½½
        if self.download_urls:
            print(f"\nğŸ“¡ ç½‘ç»œè¯·æ±‚ä¸­æ£€æµ‹åˆ°çš„ä¸‹è½½é“¾æ¥:")
            for url in self.download_urls[:5]:
                print(f"   â€¢ {url[:80]}...")
        
        self.close()
    
    def auto_download(self, url: str):
        """è‡ªåŠ¨ä¸‹è½½"""
        if not self.connect():
            return
        
        self.new_tab(url)
        
        print("\n" + "=" * 50)
        print("ğŸš€ å¼€å§‹è‡ªåŠ¨ä¸‹è½½")
        print("=" * 50)
        
        # è·å–é¡µé¢ä¿¡æ¯
        page_info = self.get_page_info()
        soft_info = self.find_software_info()
        
        print(f"\nğŸ“„ é¡µé¢: {page_info['title']}")
        if soft_info.get('name'):
            print(f"ğŸ“¦ è½¯ä»¶: {soft_info['name']}")
        
        # æŸ¥æ‰¾ä¸‹è½½é“¾æ¥
        links = self.find_download_links()
        print(f"\nğŸ” æ‰¾åˆ° {len(links)} ä¸ªä¸‹è½½é“¾æ¥")
        
        if links:
            # æ˜¾ç¤ºæ‰¾åˆ°çš„ä¸‹è½½é“¾æ¥
            for i, link in enumerate(links[:3], 1):
                print(f"   {i}. [{link['text']}] -> {link['href'][:60]}...")
            
            # é€‰æ‹©ç¬¬ä¸€ä¸ªä¸‹è½½é“¾æ¥ï¼ˆå·²æŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
            best_link = links[0]
            href = best_link['href']
            
            # ç”Ÿæˆæ–‡ä»¶å
            filename = None
            if soft_info.get('name'):
                # ä»URLæ¨æ–­æ‰©å±•å
                ext = os.path.splitext(urlparse(href).path)[1]
                if not ext:
                    # æ ¹æ®é“¾æ¥æ–‡å­—æ¨æ–­
                    text = best_link.get('text', '').lower()
                    if 'apk' in text or 'å®‰å“' in text:
                        ext = '.apk'
                    elif 'exe' in text or 'windows' in text:
                        ext = '.exe'
                    elif 'dmg' in text or 'mac' in text:
                        ext = '.dmg'
                    else:
                        ext = '.apk'  # é»˜è®¤
                
                safe_name = re.sub(r'[<>:"/\\|?*]', '_', soft_info['name'])
                filename = f"{safe_name}{ext}"
            
            print(f"\nğŸ“¥ å‡†å¤‡ä¸‹è½½: {best_link['text']}")
            self.download_file(href, filename)
        else:
            # æ²¡æœ‰æ‰¾åˆ°ä¸‹è½½é“¾æ¥ï¼Œå°è¯•ç‚¹å‡»ä¸‹è½½æŒ‰é’®
            print("\nğŸ–±ï¸  å°è¯•ç‚¹å‡»ä¸‹è½½æŒ‰é’®...")
            if self.click_first_download_button():
                time.sleep(3)  # ç­‰å¾…ä¸‹è½½å¼€å§‹æˆ–é¡µé¢è·³è½¬
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„ä¸‹è½½é“¾æ¥
                if self.download_urls:
                    # è¿‡æ»¤æ‰ç»Ÿè®¡é“¾æ¥
                    valid_urls = [u for u in self.download_urls if self._is_download_url(u)]
                    if valid_urls:
                        self.download_file(valid_urls[-1])
                    else:
                        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ä¸‹è½½é“¾æ¥")
            else:
                print("âŒ æœªæ‰¾åˆ°ä¸‹è½½é“¾æ¥")
        
        print(f"\nâœ… å®Œæˆ! ä¸‹è½½ç›®å½•: {self.download_dir}")
        self.close()
    
    def parse_game_list_from_api(self, key: str = "4_14_1", type_param: int = 3) -> list:
        """é€šè¿‡APIæ¥å£è§£ææ¸¸æˆåˆ—è¡¨ï¼Œæå–æ¸¸æˆåç§°ã€å¤§å°å’Œé“¾æ¥"""
        if not requests:
            print("âŒ è¯·å®‰è£… requests: pip3 install requests")
            return []
        
        print("\n" + "=" * 50)
        print("ğŸ“‹ é€šè¿‡APIè§£ææ¸¸æˆåˆ—è¡¨")
        print("=" * 50)
        
        api_url = "https://api.ddooo.com/api/sort.html"
        headers = {
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Connection': 'keep-alive',
            'Origin': 'https://www.ddooo.com',
            'Referer': 'https://www.ddooo.com/',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site',
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/18.5 Safari/605.1.15'
        }
        
        all_games = []
        # ä»ç¬¬2é¡µå¼€å§‹ï¼ˆç¬¬1é¡µé€šå¸¸æ— æ•°æ®ï¼‰
        page = 2
        start_page = 2
        max_pages = 500  # é˜²æ­¢æ— é™å¾ªç¯ï¼Œ15082ä¸ªæ¸¸æˆå¤§çº¦éœ€è¦378é¡µï¼ˆæ¯é¡µ40ä¸ªï¼‰
        
        print(f"ğŸ” å¼€å§‹è·å–æ•°æ® (key={key}, type={type_param})...")
        
        while page < max_pages:
            params = {
                'p': page,
                'key': key,
                'type': type_param
            }
            
            try:
                response = requests.get(api_url, params=params, headers=headers, timeout=30)
                response.raise_for_status()
                
                # è§£æJSONï¼ˆè‡ªåŠ¨å¤„ç†unicodeç¼–ç ï¼‰
                data = response.json()
                
                code = data.get('code')
                msg = data.get('msg', '')
                
                # å¦‚æœè¿”å›é”™è¯¯æˆ–"æ— æ•°æ®"
                if code != 200:
                    if msg == 'æ— æ•°æ®':
                        print(f"âœ… ç¬¬ {page} é¡µæ— æ•°æ®ï¼Œå·²è·å–å…¨éƒ¨")
                        break
                    else:
                        print(f"âš ï¸  ç¬¬ {page} é¡µè¿”å›é”™è¯¯: {msg}")
                        break
                
                games_data = data.get('data', [])
                
                if not games_data or len(games_data) == 0:
                    print(f"âœ… ç¬¬ {page} é¡µæ— æ•°æ®ï¼Œå·²è·å–å…¨éƒ¨")
                    break
                
                # å¤„ç†æ¯é¡µçš„æ¸¸æˆæ•°æ®
                for game in games_data:
                    game_name = game.get('name', '')
                    game_size = game.get('size', '')
                    game_url = game.get('url', '')
                    
                    # è½¬æ¢ä¸ºå®Œæ•´URL
                    if game_url and not game_url.startswith('http'):
                        if game_url.startswith('/'):
                            full_url = f"https://www.ddooo.com{game_url}"
                        else:
                            full_url = f"https://www.ddooo.com/{game_url}"
                    else:
                        full_url = game_url
                    
                    all_games.append({
                        'name': game_name,
                        'size': game_size,
                        'url': full_url,
                        'id': game.get('id', '')
                    })
                
                print(f"ğŸ“„ ç¬¬ {page} é¡µ: è·å–åˆ° {len(games_data)} ä¸ªæ¸¸æˆ (ç´¯è®¡: {len(all_games)})")
                page += 1
                
                # é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(0.5)
                
            except requests.RequestException as e:
                print(f"âŒ ç¬¬ {page} é¡µè¯·æ±‚å¤±è´¥: {e}")
                break
            except json.JSONDecodeError as e:
                print(f"âŒ ç¬¬ {page} é¡µJSONè§£æå¤±è´¥: {e}")
                break
            except Exception as e:
                print(f"âŒ ç¬¬ {page} é¡µå¤„ç†å¤±è´¥: {e}")
                break
        
        print(f"\nâœ… å…±è·å– {len(all_games)} ä¸ªæ¸¸æˆ")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªæ¸¸æˆä½œä¸ºé¢„è§ˆ
        if all_games:
            print("\nğŸ“‹ å‰5ä¸ªæ¸¸æˆé¢„è§ˆ:")
            for i, game in enumerate(all_games[:5], 1):
                print(f"   {i}. {game['name']} - {game['size']}")
        
        return all_games
    
    def parse_game_list(self, url: str = None, key: str = None, type_param: int = 3) -> list:
        """è§£ææ¸¸æˆåˆ—è¡¨ï¼ˆå…¼å®¹æ—§æ¥å£ï¼Œä¼˜å…ˆä½¿ç”¨APIï¼‰"""
        # å¦‚æœæä¾›äº†URLï¼Œå°è¯•ä»URLä¸­æå–key
        if url and not key:
            # ä»URLä¸­æå–åˆ†ç±»IDå’Œå­åˆ†ç±»ï¼Œä¾‹å¦‚:
            # https://www.ddooo.com/az/14_1_1.htm -> 4_14_1 (å®‰å“å•æœº)
            # https://www.ddooo.com/az/14_2_1.htm -> 4_14_2 (å®‰å“ç½‘æ¸¸)
            match = re.search(r'/az/(\d+)_(\d+)_', url)
            if match:
                category_id = match.group(1)
                sub_category = match.group(2)
                key = f"4_{category_id}_{sub_category}"
                print(f"ğŸ” ä»URLæå–åˆ° key: {key}")
            else:
                # å°è¯•åªæå–ç¬¬ä¸€ä¸ªæ•°å­—ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                match = re.search(r'/az/(\d+)_', url)
                if match:
                    category_id = match.group(1)
                    key = f"4_{category_id}_1"
                    print(f"ğŸ” ä»URLæå–åˆ° key: {key}")
                else:
                    # é»˜è®¤ä½¿ç”¨å®‰å“å•æœºåˆ—è¡¨
                    key = "4_14_1"
                    print(f"âš ï¸  æ— æ³•ä»URLæå–keyï¼Œä½¿ç”¨é»˜è®¤å€¼: {key}")
        elif not key:
            # é»˜è®¤ä½¿ç”¨å®‰å“å•æœºåˆ—è¡¨
            key = "4_14_1"
        
        # ä½¿ç”¨APIæ¥å£è·å–æ•°æ®
        return self.parse_game_list_from_api(key=key, type_param=type_param)
    
    def check_downloaded(self, game_url: str) -> bool:
        """æ£€æŸ¥æ¸¸æˆæ˜¯å¦å·²ä¸‹è½½"""
        if not game_url:
            return False
        
        # ä»URLä¸­æå–æ¸¸æˆID
        match = re.search(r'/softdown/(\d+)\.htm', game_url)
        if not match:
            return False
        
        game_id = match.group(1)
        
        # æ£€æŸ¥downloadsç›®å½•ä¸­æ˜¯å¦æœ‰å¯¹åº”çš„æ–‡ä»¶
        # å¯èƒ½çš„æ–‡ä»¶åæ ¼å¼ï¼šæ¸¸æˆåç§°.apk, æ¸¸æˆåç§°.exe, æˆ–åŒ…å«æ¸¸æˆIDçš„æ–‡ä»¶
        download_dir = Path(self.download_dir)
        if not download_dir.exists():
            return False
        
        # æŸ¥æ‰¾åŒ…å«æ¸¸æˆIDçš„æ–‡ä»¶
        for file_path in download_dir.iterdir():
            if file_path.is_file():
                # æ£€æŸ¥æ–‡ä»¶åä¸­æ˜¯å¦åŒ…å«æ¸¸æˆID
                if game_id in file_path.name:
                    return True
        
        return False
    
    def export_game_list_to_csv(self, games: list, output_file: str = None):
        """å°†æ¸¸æˆåˆ—è¡¨å¯¼å‡ºä¸ºCSVæ–‡ä»¶ï¼ŒåŒ…å«æ˜¯å¦å·²ä¸‹è½½åˆ—"""
        if not games:
            print("âŒ æ²¡æœ‰æ¸¸æˆæ•°æ®å¯å¯¼å‡º")
            return
        
        if not output_file:
            # ç”Ÿæˆé»˜è®¤æ–‡ä»¶å
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_file = self.download_dir / f"game_list_{timestamp}.csv"
        else:
            output_file = Path(output_file)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        # è½¬æ¢å¤§å°ä¸ºMBæ ¼å¼
        def convert_to_mb(size_str: str) -> str:
            """å°†å¤§å°å­—ç¬¦ä¸²è½¬æ¢ä¸ºMBæ ¼å¼"""
            if not size_str:
                return ""
            
            # ç§»é™¤ç©ºæ ¼å’Œå•ä½ï¼Œæå–æ•°å­—
            size_str = size_str.strip().upper()
            
            # åŒ¹é…æ•°å­—å’Œå•ä½
            match = re.match(r'(\d+\.?\d*)\s*([MG]B?)?', size_str)
            if not match:
                return size_str
            
            value = float(match.group(1))
            unit = match.group(2) or 'M'
            
            # è½¬æ¢ä¸ºMB
            if 'G' in unit:
                value = value * 1024
            
            return f"{value:.2f}MB"
        
        # æ£€æŸ¥ä¸‹è½½çŠ¶æ€
        print("\nğŸ” æ£€æŸ¥ä¸‹è½½çŠ¶æ€...")
        downloaded_count = 0
        for i, game in enumerate(games, 1):
            if self.check_downloaded(game.get('url', '')):
                game['downloaded'] = 'æ˜¯'
                downloaded_count += 1
            else:
                game['downloaded'] = 'å¦'
            
            if i % 100 == 0:
                print(f"   å·²æ£€æŸ¥ {i}/{len(games)} ä¸ªæ¸¸æˆ...")
        
        print(f"âœ… æ£€æŸ¥å®Œæˆ: {downloaded_count} ä¸ªå·²ä¸‹è½½")
        
        # å†™å…¥CSVæ–‡ä»¶
        try:
            with open(output_file, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                
                # å†™å…¥è¡¨å¤´
                writer.writerow(['æ¸¸æˆåç§°', 'æ¸¸æˆå¤§å°(MB)', 'ç½‘å€é“¾æ¥', 'æ˜¯å¦å·²ä¸‹è½½'])
                
                # å†™å…¥æ•°æ®
                for game in games:
                    size_mb = convert_to_mb(game.get('size', ''))
                    writer.writerow([
                        game.get('name', ''),
                        size_mb,
                        game.get('url', ''),
                        game.get('downloaded', 'å¦')
                    ])
            
            print(f"\nâœ… æ•°æ®å·²å¯¼å‡ºåˆ°: {output_file}")
            print(f"   å…± {len(games)} æ¡è®°å½•")
            print(f"   å·²ä¸‹è½½: {downloaded_count} ä¸ª")
            return str(output_file)
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            return None
    
    def close(self):
        """å…³é—­æ ‡ç­¾é¡µ"""
        if self.tab:
            try:
                self.tab.stop()
                self.browser.close_tab(self.tab)
            except:
                pass


def launch_chrome_with_debugging():
    """å¯åŠ¨å¸¦è°ƒè¯•ç«¯å£çš„ Chrome"""
    import tempfile
    
    system = platform.system()
    
    if system == "Darwin":  # macOS
        chrome_path = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
    elif system == "Windows":
        chrome_path = r"C:\Program Files\Google\Chrome\Application\chrome.exe"
    else:  # Linux
        chrome_path = "google-chrome"
    
    # ä½¿ç”¨ä¸´æ—¶ç›®å½•ä½œä¸ºç”¨æˆ·æ•°æ®ç›®å½•ï¼ˆè¿œç¨‹è°ƒè¯•éœ€è¦ï¼‰
    user_data_dir = "/tmp/chrome-debug-profile"
    os.makedirs(user_data_dir, exist_ok=True)
    
    cmd = [
        chrome_path,
        "--remote-debugging-port=9222",
        f"--user-data-dir={user_data_dir}",
        "--no-first-run"
    ]
    
    print(f"ğŸš€ å¯åŠ¨ Chrome...")
    
    try:
        subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        print("â³ ç­‰å¾… Chrome å¯åŠ¨...")
        time.sleep(5)  # ç­‰å¾… Chrome å¯åŠ¨
        return True
    except Exception as e:
        print(f"âŒ å¯åŠ¨ Chrome å¤±è´¥: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description="ç½‘é¡µè‡ªåŠ¨ä¸‹è½½å·¥å…· - åŸºäº Chrome DevTools Protocol",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨å‰å‡†å¤‡:
  1. pip3 install pychrome requests websocket-client
  2. å¯åŠ¨ Chrome (Mac):
     /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222

ç¤ºä¾‹:
  python3 auto_downloader.py https://www.ddooo.com/softdown/12345.html
  python3 auto_downloader.py -a https://www.ddooo.com/  # ä»…åˆ†æé¡µé¢
  python3 auto_downloader.py -l https://www.ddooo.com/az/14_1_1.htm  # è§£ææ¸¸æˆåˆ—è¡¨ï¼ˆä»URLæå–keyï¼‰
  python3 auto_downloader.py -l -k 4_14_1 -o games.csv  # ç›´æ¥æŒ‡å®škeyè§£ææ¸¸æˆåˆ—è¡¨
  python3 auto_downloader.py -l -o games.csv https://www.ddooo.com/az/14_1_1.htm  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
  python3 auto_downloader.py -d ./my_downloads https://example.com
  python3 auto_downloader.py --launch https://example.com  # è‡ªåŠ¨å¯åŠ¨Chrome
        """
    )
    
    parser.add_argument("url", nargs='?', help="è¦è§£æçš„ç½‘é¡µURLï¼ˆåˆ—è¡¨æ¨¡å¼ä¸‹å¯é€‰ï¼‰")
    parser.add_argument("-d", "--dir", default="./downloads", help="ä¸‹è½½ä¿å­˜ç›®å½•")
    parser.add_argument("-a", "--analyze", action="store_true", help="ä»…åˆ†æé¡µé¢ï¼Œä¸ä¸‹è½½")
    parser.add_argument("-l", "--list", action="store_true", help="è§£ææ¸¸æˆåˆ—è¡¨å¹¶å¯¼å‡ºCSVï¼ˆä½¿ç”¨APIæ¥å£ï¼‰")
    parser.add_argument("-o", "--output", help="CSVè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºåˆ—è¡¨æ¨¡å¼ï¼‰")
    parser.add_argument("-k", "--key", help="API keyå‚æ•°ï¼ˆä¾‹å¦‚ï¼š4_14_1ï¼Œé»˜è®¤ä»URLæå–ï¼‰")
    parser.add_argument("-t", "--type", type=int, default=3, help="API typeå‚æ•°ï¼ˆé»˜è®¤3ï¼‰")
    parser.add_argument("-p", "--port", default="9222", help="Chrome è°ƒè¯•ç«¯å£ (é»˜è®¤ 9222)")
    parser.add_argument("--launch", action="store_true", help="è‡ªåŠ¨å¯åŠ¨ Chrome")
    
    args = parser.parse_args()
    
    # åˆ—è¡¨æ¨¡å¼ä¸éœ€è¦Chromeï¼Œåªéœ€è¦requests
    if args.list:
        if not requests:
            print("âŒ è¯·å…ˆå®‰è£…ä¾èµ–:")
            print("   pip3 install requests")
            return
        
        downloader = CDPDownloader(download_dir=args.dir)
        games = downloader.parse_game_list(url=args.url, key=args.key, type_param=args.type)
        if games:
            downloader.export_game_list_to_csv(games, args.output)
        return
    
    # å…¶ä»–æ¨¡å¼éœ€è¦pychrome
    if not pychrome:
        print("âŒ è¯·å…ˆå®‰è£…ä¾èµ–:")
        print("   pip3 install pychrome requests websocket-client")
        return
    
    if not args.url:
        parser.error("URLå‚æ•°æ˜¯å¿…éœ€çš„ï¼ˆåˆ—è¡¨æ¨¡å¼é™¤å¤–ï¼‰")
    
    # è‡ªåŠ¨å¯åŠ¨ Chrome
    if args.launch:
        launch_chrome_with_debugging()
    
    debug_url = f"http://127.0.0.1:{args.port}"
    downloader = CDPDownloader(debug_url=debug_url, download_dir=args.dir)
    
    if args.analyze:
        downloader.analyze_page(args.url)
    else:
        downloader.auto_download(args.url)


if __name__ == "__main__":
    main()
